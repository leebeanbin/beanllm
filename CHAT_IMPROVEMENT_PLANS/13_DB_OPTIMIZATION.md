# ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹± ë° ìµœì í™” íŒŒì´í”„ë¼ì¸

## ğŸ¯ ëª©í‘œ

ê° DBë³„ë¡œ ì¸ë±ì‹± ì „ëµê³¼ ë°ì´í„° ìµœì í™” íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ

---

## ğŸ“Š í˜„ì¬ ìƒíƒœ

### MongoDB
- âœ… ê¸°ë³¸ ì¸ë±ìŠ¤ ìƒì„±ë¨ (`create_session_indexes()`)
- âš ï¸ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì—†ìŒ
- âš ï¸ ë°ì´í„° ì •ë¦¬/ì••ì¶• ì—†ìŒ

### Vector DB (Chroma)
- âœ… ê¸°ë³¸ ì„ë² ë”© ì¸ë±ìŠ¤
- âš ï¸ ëª…ì‹œì  ì¸ë±ì‹± ì „ëµ ì—†ìŒ
- âš ï¸ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì—†ìŒ

### Redis
- âœ… ê¸°ë³¸ ìºì‹±
- âš ï¸ ì¸ë±ì‹± ì „ëµ ì—†ìŒ
- âš ï¸ ë°ì´í„° ì •ë¦¬ íŒŒì´í”„ë¼ì¸ ì—†ìŒ

---

## âœ… ê°œì„  ë°©ì•ˆ

### 1. MongoDB ì¸ë±ì‹± ë° ìµœì í™”

#### A. í˜„ì¬ ì¸ë±ìŠ¤ ìƒíƒœ

```python
# playground/backend/database.py
async def create_session_indexes():
    """ì„¸ì…˜ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ìƒì„±"""
    # âœ… ì´ë¯¸ êµ¬í˜„ë¨
    - session_id (unique)
    - updated_at
    - feature_mode
    - ë³µí•© ì¸ë±ìŠ¤: feature_mode + updated_at
    - total_tokens, message_count, created_at, title
```

#### B. ì¶”ê°€ ì¸ë±ì‹± ì „ëµ

**1. ë©”ì‹œì§€ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ (ì‹ ê·œ)**
```python
# playground/backend/database.py (ì¶”ê°€)
async def create_message_indexes():
    """ë©”ì‹œì§€ ê´€ë ¨ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ìƒì„±"""
    db = get_mongodb_database()
    if db is None:
        return
    
    # media_cache ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
    await db.media_cache.create_index("hash", unique=True, background=True)
    await db.media_cache.create_index("session_id", background=True)
    await db.media_cache.create_index("created_at", background=True)
    await db.media_cache.create_index([("session_id", 1), ("created_at", -1)], background=True)
    
    # multimodal_context ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
    await db.multimodal_context.create_index("session_id", background=True)
    await db.multimodal_context.create_index("image_hash", background=True)
    await db.multimodal_context.create_index([("session_id", 1), ("created_at", -1)], background=True)
    
    # session_databases ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ (í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì—°ê²°)
    await db.session_databases.create_index("session_id", background=True)
    await db.session_databases.create_index([("session_id", 1), ("service_type", 1)], background=True)
    
    logger.info("âœ… Message-related indexes created")
```

**2. TTL ì¸ë±ìŠ¤ (ìë™ ì •ë¦¬)**
```python
async def create_ttl_indexes():
    """TTL ì¸ë±ìŠ¤ ìƒì„± (ìë™ ë°ì´í„° ì •ë¦¬)"""
    db = get_mongodb_database()
    if db is None:
        return
    
    # media_cache: 30ì¼ í›„ ìë™ ì‚­ì œ
    await db.media_cache.create_index(
        "created_at",
        expireAfterSeconds=30 * 24 * 3600,  # 30ì¼
        background=True
    )
    
    # multimodal_context: 90ì¼ í›„ ìë™ ì‚­ì œ
    await db.multimodal_context.create_index(
        "created_at",
        expireAfterSeconds=90 * 24 * 3600,  # 90ì¼
        background=True
    )
    
    logger.info("âœ… TTL indexes created")
```

**3. í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤**
```python
async def create_text_search_indexes():
    """í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„±"""
    db = get_mongodb_database()
    if db is None:
        return
    
    # ì œëª© ë° ë©”ì‹œì§€ ë‚´ìš© ê²€ìƒ‰
    await db.chat_sessions.create_index(
        [("title", "text"), ("messages.content_preview", "text")],
        background=True
    )
    
    logger.info("âœ… Text search indexes created")
```

#### C. ë°ì´í„° ìµœì í™” íŒŒì´í”„ë¼ì¸

**1. ì£¼ê¸°ì  ë°ì´í„° ì •ë¦¬**
```python
# playground/backend/services/db_optimization_service.py (ì‹ ê·œ)
class DatabaseOptimizationService:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì„œë¹„ìŠ¤
    
    ì£¼ê¸°ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ìµœì í™”
    """
    
    async def optimize_mongodb(self):
        """MongoDB ìµœì í™”"""
        db = get_mongodb_database()
        if db is None:
            return
        
        # 1. ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬ (90ì¼ ì´ìƒ ë¯¸ì‚¬ìš©)
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=90)
        result = await db.chat_sessions.delete_many({
            "updated_at": {"$lt": cutoff_date},
            "message_count": 0  # ë©”ì‹œì§€ê°€ ì—†ëŠ” ì„¸ì…˜ë§Œ
        })
        logger.info(f"âœ… Cleaned up {result.deleted_count} old sessions")
        
        # 2. ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (ì£¼ê¸°ì )
        await db.chat_sessions.reindex()
        
        # 3. í†µê³„ ìˆ˜ì§‘ (ì¿¼ë¦¬ ìµœì í™”)
        await db.command("collStats", "chat_sessions")
    
    async def compact_collections(self):
        """ì»¬ë ‰ì…˜ ì••ì¶• (ë””ìŠ¤í¬ ê³µê°„ ìµœì í™”)"""
        db = get_mongodb_database()
        if db is None:
            return
        
        # compact ëª…ë ¹ ì‹¤í–‰ (ë””ìŠ¤í¬ ê³µê°„ íšŒìˆ˜)
        await db.command({"compact": "chat_sessions"})
        await db.command({"compact": "media_cache"})
        await db.command({"compact": "multimodal_context"})
        
        logger.info("âœ… Collections compacted")
```

**2. ë°°ì¹˜ ìµœì í™” ì‘ì—…**
```python
async def run_optimization_pipeline():
    """ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    from services.db_optimization_service import db_optimization_service
    
    # 1. ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
    await db_optimization_service.rebuild_indexes()
    
    # 2. ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
    await db_optimization_service.cleanup_old_data()
    
    # 3. í†µê³„ ì—…ë°ì´íŠ¸
    await db_optimization_service.update_statistics()
    
    # 4. ì»¬ë ‰ì…˜ ì••ì¶•
    await db_optimization_service.compact_collections()
```

---

### 2. Vector DB (Chroma) ì¸ë±ì‹± ë° ìµœì í™”

#### A. ChromaDB ì¸ë±ì‹± ì „ëµ

**1. ì»¬ë ‰ì…˜ë³„ ì¸ë±ìŠ¤ ê´€ë¦¬**
```python
# playground/backend/services/vector_db_optimization_service.py (ì‹ ê·œ)
class VectorDBOptimizationService:
    """
    Vector DB ìµœì í™” ì„œë¹„ìŠ¤
    
    ChromaDB ì»¬ë ‰ì…˜ ì¸ë±ì‹± ë° ìµœì í™”
    """
    
    async def optimize_collection(self, collection_name: str):
        """ì»¬ë ‰ì…˜ ìµœì í™”"""
        from beanllm.domain.vector_stores.local.chroma import ChromaVectorStore
        
        collection = ChromaVectorStore(
            collection_name=collection_name,
            embedding_function=embedding_func
        )
        
        # 1. ì¤‘ë³µ ë¬¸ì„œ ì œê±°
        await self._remove_duplicates(collection)
        
        # 2. ì„ë² ë”© ì¬ê³„ì‚° (í•„ìš”ì‹œ)
        await self._recompute_embeddings(collection)
        
        # 3. ë©”íƒ€ë°ì´í„° ì •ë¦¬
        await self._cleanup_metadata(collection)
    
    async def _remove_duplicates(self, collection):
        """ì¤‘ë³µ ë¬¸ì„œ ì œê±°"""
        # í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ê°ì§€
        # ë™ì¼í•œ contentë¥¼ ê°€ì§„ ë¬¸ì„œ ì œê±°
        pass
    
    async def _recompute_embeddings(self, collection):
        """ì„ë² ë”© ì¬ê³„ì‚° (ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œ)"""
        # ì˜¤ë˜ëœ ì„ë² ë”© ì¬ê³„ì‚°
        pass
    
    async def _cleanup_metadata(self, collection):
        """ë©”íƒ€ë°ì´í„° ì •ë¦¬"""
        # ë¶ˆí•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì œê±°
        # ë©”íƒ€ë°ì´í„° í¬ê¸° ìµœì í™”
        pass
```

**2. ë°°ì¹˜ ì¸ë±ì‹±**
```python
async def batch_index_messages(messages: List[Dict[str, Any]]):
    """ë©”ì‹œì§€ ë°°ì¹˜ ì¸ë±ì‹± (ì„±ëŠ¥ ìµœì í™”)"""
    from services.message_vector_store import message_vector_store
    
    # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (í•œ ë²ˆì— ì—¬ëŸ¬ ë©”ì‹œì§€)
    texts = [msg["content"] for msg in messages]
    embeddings = await asyncio.to_thread(embedding_func, texts)
    
    # ë°°ì¹˜ë¡œ Vector DBì— ì €ì¥
    await asyncio.to_thread(
        _message_vector_store.collection.upsert,
        ids=[msg["message_id"] for msg in messages],
        embeddings=embeddings,
        documents=texts,
        metadatas=[msg.get("metadata", {}) for msg in messages]
    )
```

#### B. ChromaDB ìµœì í™” íŒŒì´í”„ë¼ì¸

**1. ì£¼ê¸°ì  ìµœì í™”**
```python
async def optimize_vector_db():
    """Vector DB ìµœì í™”"""
    # 1. ì¤‘ë³µ ì œê±°
    await vector_db_optimization_service.remove_duplicates()
    
    # 2. ì˜¤ë˜ëœ ì„ë² ë”© ì¬ê³„ì‚°
    await vector_db_optimization_service.recompute_stale_embeddings()
    
    # 3. ë©”íƒ€ë°ì´í„° ì •ë¦¬
    await vector_db_optimization_service.cleanup_metadata()
    
    # 4. ì»¬ë ‰ì…˜ í†µê³„ ì—…ë°ì´íŠ¸
    await vector_db_optimization_service.update_statistics()
```

**2. ì¸ë±ìŠ¤ ì¬êµ¬ì¶•**
```python
async def rebuild_vector_indexes():
    """Vector ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
    # ChromaDBëŠ” ìë™ìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ê´€ë¦¬í•˜ì§€ë§Œ
    # ëŒ€ëŸ‰ ë°ì´í„° ì¶”ê°€ í›„ ì¬êµ¬ì¶• í•„ìš”í•  ìˆ˜ ìˆìŒ
    pass
```

---

### 3. Redis ì¸ë±ì‹± ë° ìµœì í™”

#### A. Redis ì¸ë±ì‹± ì „ëµ

**1. í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìµœì í™”**
```python
# playground/backend/services/redis_optimization_service.py (ì‹ ê·œ)
class RedisOptimizationService:
    """
    Redis ìµœì í™” ì„œë¹„ìŠ¤
    
    í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë° ì¸ë±ì‹± ìµœì í™”
    """
    
    def __init__(self):
        from services.session_cache import get_redis_client
        self.redis = get_redis_client()
    
    async def optimize_key_namespaces(self):
        """í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìµœì í™”"""
        # í˜„ì¬ í‚¤ êµ¬ì¡°:
        # - sessions:{session_id}
        # - sessions:list:{user_id}:{filter}
        # - summary:{session_id}
        # - cache:{key}
        
        # ìµœì í™”: í•´ì‹œ ê¸°ë°˜ í‚¤ ë¶„ì‚°
        # sessions:{hash(session_id)[:8]}:{session_id}
        pass
    
    async def create_secondary_indexes(self):
        """ë³´ì¡° ì¸ë±ìŠ¤ ìƒì„± (Sorted Set)"""
        # ì„¸ì…˜ ëª©ë¡ì„ Sorted Setìœ¼ë¡œ ê´€ë¦¬ (ì •ë ¬ ìµœì í™”)
        # sessions:list:sorted:{user_id} -> ZADD score=updated_at
        pass
```

**2. ë©”ëª¨ë¦¬ ìµœì í™”**
```python
async def optimize_redis_memory(self):
    """Redis ë©”ëª¨ë¦¬ ìµœì í™”"""
    # 1. ì˜¤ë˜ëœ í‚¤ ì •ë¦¬
    await self._cleanup_expired_keys()
    
    # 2. í° ê°’ ì••ì¶•
    await self._compress_large_values()
    
    # 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    await self._monitor_memory_usage()
```

#### B. Redis ìµœì í™” íŒŒì´í”„ë¼ì¸

**1. ì£¼ê¸°ì  ì •ë¦¬**
```python
async def cleanup_redis():
    """Redis ì •ë¦¬"""
    # 1. ë§Œë£Œëœ í‚¤ ì •ë¦¬
    # 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    # 3. í° ê°’ ì••ì¶•
    # 4. í†µê³„ ì—…ë°ì´íŠ¸
    pass
```

**2. ìºì‹œ ì›Œë°ì—…**
```python
async def warmup_cache():
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ìºì‹œ ì›Œë°ì—…"""
    # ìµœê·¼ ì„¸ì…˜ ëª©ë¡ ìºì‹œ
    # ìì£¼ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ ì •ë³´ ìºì‹œ
    pass
```

---

### 4. í†µí•© ìµœì í™” íŒŒì´í”„ë¼ì¸

#### A. ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •

```python
# playground/backend/services/optimization_scheduler.py (ì‹ ê·œ)
from apscheduler.schedulers.asyncio import AsyncIOScheduler

class OptimizationScheduler:
    """ìµœì í™” ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self._setup_jobs()
    
    def _setup_jobs(self):
        """ìµœì í™” ì‘ì—… ìŠ¤ì¼€ì¤„ ì„¤ì •"""
        # ë§¤ì¼ ìƒˆë²½ 2ì‹œ: MongoDB ìµœì í™”
        self.scheduler.add_job(
            self._optimize_mongodb,
            trigger="cron",
            hour=2,
            minute=0
        )
        
        # ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ: Vector DB ìµœì í™”
        self.scheduler.add_job(
            self._optimize_vector_db,
            trigger="cron",
            day_of_week="sun",
            hour=3,
            minute=0
        )
        
        # ë§¤ì‹œê°„: Redis ì •ë¦¬
        self.scheduler.add_job(
            self._cleanup_redis,
            trigger="cron",
            minute=0
        )
    
    async def _optimize_mongodb(self):
        """MongoDB ìµœì í™” ì‹¤í–‰"""
        from services.db_optimization_service import db_optimization_service
        await db_optimization_service.optimize_mongodb()
    
    async def _optimize_vector_db(self):
        """Vector DB ìµœì í™” ì‹¤í–‰"""
        from services.vector_db_optimization_service import vector_db_optimization_service
        await vector_db_optimization_service.optimize_all_collections()
    
    async def _cleanup_redis(self):
        """Redis ì •ë¦¬ ì‹¤í–‰"""
        from services.redis_optimization_service import redis_optimization_service
        await redis_optimization_service.cleanup_redis()
    
    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        self.scheduler.start()
    
    def shutdown(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ"""
        self.scheduler.shutdown()
```

#### B. ìˆ˜ë™ ìµœì í™” ì—”ë“œí¬ì¸íŠ¸

```python
# playground/backend/routers/optimization_router.py (ì‹ ê·œ)
@router.post("/optimize/mongodb")
async def optimize_mongodb():
    """MongoDB ìˆ˜ë™ ìµœì í™”"""
    from services.db_optimization_service import db_optimization_service
    await db_optimization_service.optimize_mongodb()
    return {"status": "success", "message": "MongoDB optimized"}

@router.post("/optimize/vector_db")
async def optimize_vector_db():
    """Vector DB ìˆ˜ë™ ìµœì í™”"""
    from services.vector_db_optimization_service import vector_db_optimization_service
    await vector_db_optimization_service.optimize_all_collections()
    return {"status": "success", "message": "Vector DB optimized"}

@router.post("/optimize/redis")
async def optimize_redis():
    """Redis ìˆ˜ë™ ìµœì í™”"""
    from services.redis_optimization_service import redis_optimization_service
    await redis_optimization_service.optimize_redis_memory()
    return {"status": "success", "message": "Redis optimized"}

@router.post("/optimize/all")
async def optimize_all():
    """ëª¨ë“  DB ìµœì í™”"""
    # ìˆœì°¨ ì‹¤í–‰
    await optimize_mongodb()
    await optimize_vector_db()
    await optimize_redis()
    return {"status": "success", "message": "All databases optimized"}
```

---

## ğŸ“‹ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° ìƒíƒœ

### âœ… êµ¬í˜„ë¨
- [x] MongoDB ê¸°ë³¸ ì¸ë±ìŠ¤ (`database.py`ì˜ `create_session_indexes`)
- [x] ì„¸ì…˜ Vector DB ì¸ë±ì‹± (`session_search_service.py`ì˜ `index_session`)

### âŒ ë¯¸êµ¬í˜„
- [ ] **ë©”ì‹œì§€ ê´€ë ¨ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ì¶”ê°€**
  - **í†µí•© ìœ„ì¹˜**: `database.py`ì˜ `create_session_indexes()` í•¨ìˆ˜ í™•ì¥
  - **êµ¬í˜„ ë°©í–¥**: ë¬¸ì„œì˜ "B. ì¶”ê°€ ì¸ë±ì‹± ì „ëµ" ì„¹ì…˜ ì°¸ì¡°
  - **ë°©ë²•**: `create_message_indexes()` í•¨ìˆ˜ ì¶”ê°€
- [ ] **TTL ì¸ë±ìŠ¤ ìƒì„± (ìë™ ì •ë¦¬)**
  - **í†µí•© ìœ„ì¹˜**: `database.py`ì˜ `create_ttl_indexes()` í•¨ìˆ˜
  - **êµ¬í˜„ ë°©í–¥**: ë¬¸ì„œì˜ "C. ë°ì´í„° ìµœì í™” íŒŒì´í”„ë¼ì¸" ì„¹ì…˜ ì°¸ì¡°
  - **ë°©ë²•**: `createIndex({ "created_at": 1 }, { expireAfterSeconds: 7776000 })` (90ì¼)
- [ ] **í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„±**
  - **í†µí•© ìœ„ì¹˜**: `database.py`ì˜ `create_text_search_indexes()` í•¨ìˆ˜
  - **êµ¬í˜„ ë°©í–¥**: MongoDB Text Search ì¸ë±ìŠ¤
  - **ë°©ë²•**: ë¬¸ì„œì˜ "C. í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤" ì„¹ì…˜ ì°¸ì¡°
- [ ] **ë°ì´í„° ìµœì í™” íŒŒì´í”„ë¼ì¸ êµ¬í˜„**
  - **íŒŒì¼**: `playground/backend/services/db_optimization_service.py` (ì‹ ê·œ ìƒì„± í•„ìš”)
  - **êµ¬í˜„ ë°©í–¥**: ë¬¸ì„œì˜ "C. ë°ì´í„° ìµœì í™” íŒŒì´í”„ë¼ì¸" ì„¹ì…˜ ì°¸ì¡°
  - **ë°©ë²•**: ì£¼ê¸°ì ìœ¼ë¡œ ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬, ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
- [ ] **ì£¼ê¸°ì  ì •ë¦¬ ì‘ì—… ìŠ¤ì¼€ì¤„ë§**
  - **í†µí•© ìœ„ì¹˜**: `OptimizationScheduler` ì„œë¹„ìŠ¤
  - **ë°©ë²•**: `asyncio` ë˜ëŠ” `APScheduler` í™œìš©
- [ ] **ì»¬ë ‰ì…˜ë³„ ì¸ë±ìŠ¤ ê´€ë¦¬**
  - **íŒŒì¼**: `playground/backend/services/vector_db_optimization_service.py` (ì‹ ê·œ ìƒì„± í•„ìš”)
  - **êµ¬í˜„ ë°©í–¥**: ë¬¸ì„œì˜ "2. Vector DB ì¸ë±ì‹± ë° ìµœì í™”" ì„¹ì…˜ ì°¸ì¡°
- [ ] **ì¤‘ë³µ ë¬¸ì„œ ì œê±°**
  - **í†µí•© ìœ„ì¹˜**: `vector_db_optimization_service.py`
  - **ë°©ë²•**: ë¬¸ì„œ í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ê°ì§€
- [ ] **ë°°ì¹˜ ì¸ë±ì‹± ìµœì í™”**
  - **í†µí•© ìœ„ì¹˜**: `vector_db_optimization_service.py`
  - **ë°©ë²•**: ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ì„ë² ë”© ìƒì„± í›„ ë°°ì¹˜ ì €ì¥
- [ ] **ì„ë² ë”© ì¬ê³„ì‚° íŒŒì´í”„ë¼ì¸**
  - **í†µí•© ìœ„ì¹˜**: `vector_db_optimization_service.py`
  - **ë°©ë²•**: ì˜¤ë˜ëœ ì„ë² ë”© ì‹ë³„ í›„ ì¬ê³„ì‚°
- [ ] **ë©”íƒ€ë°ì´í„° ì •ë¦¬**
  - **í†µí•© ìœ„ì¹˜**: `vector_db_optimization_service.py`
  - **ë°©ë²•**: ë¶ˆí•„ìš”í•œ ë©”íƒ€ë°ì´í„° í•„ë“œ ì œê±°
- [ ] **í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìµœì í™”**
  - **íŒŒì¼**: `playground/backend/services/redis_optimization_service.py` (ì‹ ê·œ ìƒì„± í•„ìš”)
  - **êµ¬í˜„ ë°©í–¥**: ë¬¸ì„œì˜ "3. Redis ì¸ë±ì‹± ë° ìµœì í™”" ì„¹ì…˜ ì°¸ì¡°
- [ ] **ë³´ì¡° ì¸ë±ìŠ¤ ìƒì„± (Sorted Set)**
  - **í†µí•© ìœ„ì¹˜**: `redis_optimization_service.py`
  - **ë°©ë²•**: Sorted Setìœ¼ë¡œ ì •ë ¬ëœ í‚¤ ê´€ë¦¬
- [ ] **ë©”ëª¨ë¦¬ ìµœì í™”**
  - **í†µí•© ìœ„ì¹˜**: `redis_optimization_service.py`
  - **ë°©ë²•**: í° ê°’ ì••ì¶•, ë§Œë£Œëœ í‚¤ ì •ë¦¬
- [ ] **ì£¼ê¸°ì  ì •ë¦¬ íŒŒì´í”„ë¼ì¸**
  - **í†µí•© ìœ„ì¹˜**: `redis_optimization_service.py`
  - **ë°©ë²•**: ì£¼ê¸°ì ìœ¼ë¡œ ë§Œë£Œëœ í‚¤ ì‚­ì œ
- [ ] **ìºì‹œ ì›Œë°ì—…**
  - **í†µí•© ìœ„ì¹˜**: `redis_optimization_service.py`
  - **ë°©ë²•**: ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ì‚¬ì „ ë¡œë“œ
- [ ] **OptimizationScheduler ìƒì„±**
  - **íŒŒì¼**: `playground/backend/services/optimization_scheduler.py` (ì‹ ê·œ ìƒì„± í•„ìš”)
  - **êµ¬í˜„ ë°©í–¥**: ë¬¸ì„œì˜ "4. í†µí•© ìµœì í™” íŒŒì´í”„ë¼ì¸" ì„¹ì…˜ ì°¸ì¡°
  - **ë°©ë²•**: ëª¨ë“  ìµœì í™” ì‘ì—…ì„ ìŠ¤ì¼€ì¤„ë§
- [ ] **ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—… ì„¤ì •**
  - **í†µí•© ìœ„ì¹˜**: `optimization_scheduler.py`
  - **ë°©ë²•**: ë§¤ì‹œê°„, ë§¤ì¼, ë§¤ì£¼ ì‘ì—… ì„¤ì •
- [ ] **ìˆ˜ë™ ìµœì í™” ì—”ë“œí¬ì¸íŠ¸**
  - **ìœ„ì¹˜**: `routers/optimization_router.py` (ì‹ ê·œ ìƒì„± í•„ìš”)
  - **ë°©ë²•**: ë¬¸ì„œì˜ "B. ìˆ˜ë™ ìµœì í™” ì—”ë“œí¬ì¸íŠ¸" ì„¹ì…˜ ì°¸ì¡°
- [ ] **ìµœì í™” ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§**
  - **í†µí•© ìœ„ì¹˜**: `optimization_scheduler.py`
  - **ë°©ë²•**: SSE ë˜ëŠ” ë¡œê·¸ë¡œ ì§„í–‰ ìƒí™© ì „ë‹¬

---

## ğŸ¯ ìµœì í™” ì „ëµ ìš”ì•½

### MongoDB
1. **ì¸ë±ì‹±**: ëª¨ë“  ì¿¼ë¦¬ íŒ¨í„´ì— ë§ëŠ” ì¸ë±ìŠ¤ ìƒì„±
2. **TTL**: ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì‚­ì œ
3. **ì••ì¶•**: ì£¼ê¸°ì  ì»¬ë ‰ì…˜ ì••ì¶•
4. **í†µê³„**: ì¿¼ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ í†µê³„ ìˆ˜ì§‘

### Vector DB
1. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ì¸ë±ì‹±
2. **ì¤‘ë³µ ì œê±°**: ë™ì¼í•œ ë‚´ìš©ì˜ ë¬¸ì„œ ì œê±°
3. **ì¬ê³„ì‚°**: ì˜¤ë˜ëœ ì„ë² ë”© ì¬ê³„ì‚°
4. **ë©”íƒ€ë°ì´í„° ì •ë¦¬**: ë¶ˆí•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì œê±°

### Redis
1. **í‚¤ ìµœì í™”**: íš¨ìœ¨ì ì¸ í‚¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
2. **ì¸ë±ì‹±**: Sorted Setìœ¼ë¡œ ì •ë ¬ ìµœì í™”
3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: í° ê°’ ì••ì¶•, ë§Œë£Œëœ í‚¤ ì •ë¦¬
4. **ì›Œë°ì—…**: ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ì‚¬ì „ ë¡œë“œ

---

## ğŸ’¡ í•µì‹¬ ì›ì¹™

1. **ìë™í™”**: ì£¼ê¸°ì  ìµœì í™” ì‘ì—… ìë™ ì‹¤í–‰
2. **ëª¨ë‹ˆí„°ë§**: ìµœì í™” ì§„í–‰ ìƒí™© ë° ê²°ê³¼ ëª¨ë‹ˆí„°ë§
3. **ì ì§„ì **: ëŒ€ëŸ‰ ì‘ì—…ì€ ë°°ì¹˜ë¡œ ì²˜ë¦¬
4. **ì•ˆì „ì„±**: ìµœì í™” ì¤‘ ë°ì´í„° ì†ì‹¤ ë°©ì§€

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [03_CONTEXT_MANAGEMENT.md](./03_CONTEXT_MANAGEMENT.md): ìš”ì•½ ì €ì¥ ì‹œ ì¸ë±ì‹± í™œìš©
- [04_SESSION_RAG.md](./04_SESSION_RAG.md): RAG ì»¬ë ‰ì…˜ ì¸ë±ì‹±
- [08_MULTIMODAL_CONTEXT.md](./08_MULTIMODAL_CONTEXT.md): ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¸ë±ì‹±
