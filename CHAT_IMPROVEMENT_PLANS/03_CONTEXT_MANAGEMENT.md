# ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬

## ğŸ¯ ëª©í‘œ

ì¼ì •ëŸ‰ì˜ ëŒ€í™”ê°€ ìŒ“ì´ë©´ ìë™ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ì—¬:
1. í† í° ì œí•œ ë‚´ì—ì„œ ìµœëŒ€í•œ ë§ì€ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
2. ì¤‘ìš”í•œ ì •ë³´ëŠ” ë³´ì¡´í•˜ë©´ì„œ ì˜¤ë˜ëœ ì •ë³´ëŠ” ìš”ì•½
3. ì‚¬ìš©ìì—ê²Œ ìš”ì•½ ê³¼ì •ì„ ëª…í™•íˆ í‘œì‹œ

---

## ğŸ“Š í˜„ì¬ ìƒíƒœ

### êµ¬í˜„ëœ ê¸°ëŠ¥
- âœ… `SummaryMemory`: ì˜¤ë˜ëœ ëŒ€í™” ìë™ ìš”ì•½ (beanllm.domain.memory)
- âœ… `TokenMemory`: í† í° ìˆ˜ ê¸°ì¤€ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
- âœ… `WindowMemory`: ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
- âœ… `BufferMemory`: ëª¨ë“  ë©”ì‹œì§€ ì €ì¥

### ë¬¸ì œì 
- âŒ playgroundì—ì„œ í™œìš© ì•ˆ ë¨
- âŒ ìš”ì•½ ì „ëµì´ êµ¬ì²´ì ì´ì§€ ì•ŠìŒ
- âŒ ì €ì¥ ë° ì „ë‹¬ ë°©ì‹ì´ ëª…í™•í•˜ì§€ ì•ŠìŒ

---

## âœ… ê°œì„  ë°©ì•ˆ

### 1. ìš”ì•½ ì „ëµ (ì–´ë–»ê²Œ ìš”ì•½í• ì§€)

#### A. ìš”ì•½ íŠ¸ë¦¬ê±° ì¡°ê±´

**ì˜µì…˜ 1: ë©”ì‹œì§€ ìˆ˜ ê¸°ë°˜ (ê¶Œì¥)**
```python
# 20ê°œ ë©”ì‹œì§€ ì´ˆê³¼ ì‹œ ìš”ì•½
max_messages = 20
summary_trigger = 15  # 15ê°œ ì´ˆê³¼ ì‹œ ìš”ì•½ ì‹œì‘
```

**ì˜µì…˜ 2: í† í° ìˆ˜ ê¸°ë°˜**
```python
# 4000 í† í° ì´ˆê³¼ ì‹œ ìš”ì•½
max_tokens = 4000
token_threshold = 3500  # 3500 í† í° ì´ˆê³¼ ì‹œ ìš”ì•½ ì‹œì‘
```

**ì˜µì…˜ 3: í•˜ì´ë¸Œë¦¬ë“œ (ê¶Œì¥)**
```python
# ë©”ì‹œì§€ ìˆ˜ì™€ í† í° ìˆ˜ ëª¨ë‘ ê³ ë ¤
if message_count > 20 or estimated_tokens > 3500:
    trigger_summarization()
```

#### B. ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì „ëµ (ë™ì  êµ¬ì„±)

**ì „ëµ 1: í•µì‹¬ ì •ë³´ ë³´ì¡´ (ê¶Œì¥) - ë™ì  êµ¬ì„±**
```python
from services.prompt_builder import PromptBuilder

prompt_builder = PromptBuilder()

def build_summarization_prompt(
    conversation_history: str,
    session_context: Dict[str, Any],
    previous_summaries: Optional[List[str]] = None
) -> str:
    """
    ìš”ì•½ í”„ë¡¬í”„íŠ¸ ë™ì  êµ¬ì„±
    
    ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ 
    """
    base_template = PromptTemplate(
        template="""ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì •ë³´ëŠ” ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

1. ì£¼ìš” ì£¼ì œ ë° ëª©ì 
2. ì¤‘ìš”í•œ ê²°ì • ì‚¬í•­
3. ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­
4. í•´ê²°ëœ ë¬¸ì œì™€ í•´ê²° ë°©ë²•
5. ë¯¸ì™„ë£Œëœ ì‘ì—…ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„

ëŒ€í™” ë‚´ìš©:
{conversation_history}

ìš”ì•½ (200-300ì):""",
        input_variables=["conversation_history"]
    )
    
    # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë°˜ì˜
    if session_context.get("uploaded_files"):
        base_template = prompt_builder.optimizer.add_instructions(
            base_template.format(conversation_history=conversation_history),
            [f"ì„¸ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼: {', '.join(session_context['uploaded_files'])}"]
        )
    
    # ì´ì „ ìš”ì•½ì´ ìˆìœ¼ë©´ ì—°ì†ì„± ìœ ì§€
    if previous_summaries:
        base_template = prompt_builder.optimizer.add_instructions(
            base_template,
            [f"ì´ì „ ìš”ì•½: {previous_summaries[-1]}", "ì—°ì†ì„±ì„ ìœ ì§€í•˜ë©° ìš”ì•½í•˜ì„¸ìš”."]
        )
    
    return base_template
```

**ì „ëµ 2: êµ¬ì¡°í™”ëœ ìš”ì•½ - ë™ì  êµ¬ì„±**
```python
def build_structured_summarization_prompt(
    conversation_history: str,
    intent_history: List[str],
    tool_usage_history: List[str]
) -> str:
    """
    êµ¬ì¡°í™”ëœ ìš”ì•½ í”„ë¡¬í”„íŠ¸ (ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜)
    
    ì‚¬ìš©ëœ ë„êµ¬ì™€ ì˜ë„ë¥¼ ë°˜ì˜í•˜ì—¬ ìš”ì•½
    """
    composer = PromptComposer()
    
    # ê¸°ë³¸ êµ¬ì¡°
    composer.add_text("""
ë‹¤ìŒ ëŒ€í™”ë¥¼ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ì£¼ì œ: [ëŒ€í™”ì˜ ì£¼ìš” ì£¼ì œ]
ëª©ì : [ì‚¬ìš©ìì˜ ëª©ì ]
ì£¼ìš” ë‚´ìš©:
- [í•µì‹¬ í¬ì¸íŠ¸ 1]
- [í•µì‹¬ í¬ì¸íŠ¸ 2]
- [í•µì‹¬ í¬ì¸íŠ¸ 3]
ì¤‘ìš” ì •ë³´: [ë³´ì¡´í•´ì•¼ í•  íŠ¹ë³„í•œ ì •ë³´]
ë‹¤ìŒ ë‹¨ê³„: [ë¯¸ì™„ë£Œ ì‘ì—…ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„]
""")
    
    # ì‚¬ìš©ëœ ë„êµ¬ ì •ë³´ ì¶”ê°€
    if tool_usage_history:
        composer.add_text(f"ì‚¬ìš©ëœ ë„êµ¬: {', '.join(set(tool_usage_history))}")
    
    # ì˜ë„ ë³€í™” ì¶”ì 
    if len(intent_history) > 1:
        composer.add_text(f"ì˜ë„ ë³€í™”: {' â†’ '.join(intent_history[-3:])}")
    
    # ëŒ€í™” ë‚´ìš©
    composer.add_template(
        PromptTemplate(
            template="ëŒ€í™” ë‚´ìš©:\n{conversation_history}",
            input_variables=["conversation_history"]
        )
    )
    
    return composer.compose(conversation_history=conversation_history)
```

**ì „ëµ 3: ê³„ì¸µì  ìš”ì•½ (ê¸´ ëŒ€í™”ìš©)**
```python
# 1ë‹¨ê³„: ëŒ€í™”ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ê°ê° ìš”ì•½
# 2ë‹¨ê³„: ìš”ì•½ëœ ì²­í¬ë“¤ì„ ë‹¤ì‹œ ìš”ì•½
HIERARCHICAL_SUMMARIZATION = """
1ë‹¨ê³„: ëŒ€í™”ë¥¼ 5-10ê°œ ë©”ì‹œì§€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ê°ê° ìš”ì•½
2ë‹¨ê³„: ìš”ì•½ëœ ë‚´ìš©ë“¤ì„ í†µí•©í•˜ì—¬ ìµœì¢… ìš”ì•½
"""
```

#### C. ìš”ì•½ ëª¨ë¸ ì„ íƒ

**ì˜µì…˜ 1: ë™ì¼ ëª¨ë¸ ì‚¬ìš©**
```python
# ì‚¬ìš©ìê°€ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ë¡œ ìš”ì•½
summarizer = Client(model=context.model)  # ì˜ˆ: qwen2.5:0.5b
```

**ì˜µì…˜ 2: ì „ìš© ìš”ì•½ ëª¨ë¸**
```python
# ìš”ì•½ ì „ìš© ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš© (ë¹„ìš© ì ˆê°)
summarizer = Client(model="qwen2.5:0.5b")  # ë¹ ë¥´ê³  ì €ë ´
```

**ì˜µì…˜ 3: ì‚¬ìš©ì ì„ íƒ**
```python
# ì‚¬ìš©ìê°€ ìš”ì•½ ëª¨ë¸ ì„ íƒ ê°€ëŠ¥
summarizer = Client(model=user_settings.get("summary_model", "qwen2.5:0.5b"))
```

---

### 2. ì €ì¥ ì „ëµ (ì–´ë–»ê²Œ ì €ì¥í• ì§€)

#### A. í•˜ì´ë¸Œë¦¬ë“œ ì €ì¥ êµ¬ì¡°

**êµ¬ì¡°**:
```
MongoDB (ë©”íƒ€ë°ì´í„°)
â”œâ”€ session_id
â”œâ”€ summary (ìš”ì•½ëœ ë‚´ìš©)
â”œâ”€ summary_created_at
â”œâ”€ message_count
â””â”€ recent_messages (ìµœê·¼ 10ê°œ ë©”ì‹œì§€)

Vector DB (ì „ì²´ ë©”ì‹œì§€)
â”œâ”€ ëª¨ë“  ë©”ì‹œì§€ ë‚´ìš© (ì„ë² ë”©)
â”œâ”€ ìš”ì•½ë„ ë³„ë„ ë¬¸ì„œë¡œ ì €ì¥
â””â”€ ì„¸ì…˜ë³„ ì»¬ë ‰ì…˜
```

#### B. ì €ì¥ êµ¬í˜„

```python
# playground/backend/services/context_manager.py
class ContextManager:
    """
    ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì„œë¹„ìŠ¤
    
    ìš”ì•½, ì €ì¥, ì „ë‹¬ì„ í†µí•© ê´€ë¦¬
    """
    
    def __init__(self, session_id: str):
        from beanllm.domain.memory import create_memory
        from services.message_vector_store import message_vector_store
        
        self.session_id = session_id
        self.memory = create_memory(
            "summary",
            max_messages=20,
            summary_trigger=15
        )
        self.message_vector_store = message_vector_store
    
    async def add_message(
        self,
        role: str,
        content: str,
        model: str,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """ë©”ì‹œì§€ ì¶”ê°€ ë° ìë™ ìš”ì•½"""
        # 1. ë©”ëª¨ë¦¬ì— ì¶”ê°€
        self.memory.add_message(role, content, model=model, **metadata)
        
        # 2. Vector DBì— ì €ì¥
        await self.message_vector_store.save_message(
            session_id=self.session_id,
            message_id=f"{self.session_id}_{uuid.uuid4().hex[:8]}",
            role=role,
            content=content,
            model=model,
            timestamp=datetime.now(timezone.utc),
            metadata=metadata
        )
        
        # 3. ìš”ì•½ íŠ¸ë¦¬ê±° í™•ì¸
        if len(self.memory.messages) > self.memory.summary_trigger:
            await self._summarize_if_needed()
    
    async def _summarize_if_needed(self):
        """í•„ìš” ì‹œ ìš”ì•½ ì‹¤í–‰ (í”„ë¡¬í”„íŠ¸ ë™ì  êµ¬ì„±)"""
        # ìš”ì•½ì´ ì´ë¯¸ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if self.memory.summary:
            return
        
        # ìš”ì•½í•  ë©”ì‹œì§€ ì„ íƒ (ì˜¤ë˜ëœ ë©”ì‹œì§€ë“¤)
        messages_to_summarize = self.memory.messages[:-10]  # ìµœê·¼ 10ê°œ ì œì™¸
        
        # í”„ë¡¬í”„íŠ¸ ë™ì  êµ¬ì„±
        from services.prompt_builder import PromptBuilder
        prompt_builder = PromptBuilder()
        
        conversation_text = "\n".join([
            f"{m['role']}: {m['content']}" 
            for m in messages_to_summarize
        ])
        
        # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        session_context = {
            "uploaded_files": await self._get_session_files(),
            "intent_history": await self._get_intent_history(),
            "tool_usage": await self._get_tool_usage_history()
        }
        
        # ë™ì  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        summarization_prompt = prompt_builder.build_summarization_prompt(
            conversation_history=conversation_text,
            session_context=session_context,
            previous_summaries=[self.memory.summary] if self.memory.summary else None
        )
        messages_to_summarize = self.memory.messages[:-10]  # ìµœê·¼ 10ê°œ ì œì™¸
        
        if len(messages_to_summarize) < 5:
            return  # ìš”ì•½í•  ë©”ì‹œì§€ê°€ ë„ˆë¬´ ì ìŒ
        
        # ìš”ì•½ ìƒì„±
        summary = await self._generate_summary(messages_to_summarize)
        
        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.memory.summary = summary
        
        # MongoDBì— ìš”ì•½ ì €ì¥
        await self._save_summary_to_mongodb(summary)
        
        # Vector DBì—ë„ ìš”ì•½ì„ ë³„ë„ ë¬¸ì„œë¡œ ì €ì¥
        await self._save_summary_to_vector_db(summary)
    
    async def _generate_summary(self, messages: List[Message]) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ ìƒì„±"""
        from beanllm.facade.core import Client
        
        # ëŒ€í™” ë‚´ìš© êµ¬ì„±
        conversation_text = "\n".join([
            f"{msg.role}: {msg.content}"
            for msg in messages
        ])
        
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸ (í•µì‹¬ ì •ë³´ ë³´ì¡´)
        SUMMARIZATION_PROMPT = """
ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì •ë³´ëŠ” ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

1. ì£¼ìš” ì£¼ì œ ë° ëª©ì 
2. ì¤‘ìš”í•œ ê²°ì • ì‚¬í•­
3. ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­
4. í•´ê²°ëœ ë¬¸ì œì™€ í•´ê²° ë°©ë²•
5. ë¯¸ì™„ë£Œëœ ì‘ì—…ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„

ëŒ€í™” ë‚´ìš©:
{conversation_history}

ìš”ì•½ (200-300ì):
"""
        
        prompt = SUMMARIZATION_PROMPT.format(
            conversation_history=conversation_text
        )
        
        # ìš”ì•½ ëª¨ë¸ ì„ íƒ (ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš©)
        summarizer = Client(model="qwen2.5:0.5b")
        
        # ìš”ì•½ ìƒì„±
        response = await summarizer.chat([
            {"role": "user", "content": prompt}
        ])
        
        return response.content
    
    async def _save_summary_to_mongodb(self, summary: str):
        """MongoDBì— ìš”ì•½ ì €ì¥"""
        from database import get_mongodb_database
        db = get_mongodb_database()
        
        await db.chat_sessions.update_one(
            {"session_id": self.session_id},
            {
                "$set": {
                    "summary": summary,
                    "summary_created_at": datetime.now(timezone.utc),
                    "summary_message_count": len(self.memory.messages)
                }
            }
        )
    
    async def _save_summary_to_vector_db(self, summary: str):
        """Vector DBì— ìš”ì•½ ì €ì¥ (ê²€ìƒ‰ ê°€ëŠ¥í•˜ë„ë¡)"""
        await self.message_vector_store.save_message(
            session_id=self.session_id,
            message_id=f"{self.session_id}_summary_{uuid.uuid4().hex[:8]}",
            role="system",
            content=f"[ìš”ì•½] {summary}",
            model="summary",
            timestamp=datetime.now(timezone.utc),
            metadata={"type": "summary"}
        )
    
    async def get_context_for_llm(
        self,
        query: Optional[str] = None,
        use_query_refinement: bool = True
    ) -> List[Dict[str, str]]:
        """
        LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì¿¼ë¦¬ ì¬êµ¬ì„± í¬í•¨)
        
        Args:
            query: í˜„ì¬ ì¿¼ë¦¬ (ì¬êµ¬ì„± ëŒ€ìƒ)
            use_query_refinement: ì¿¼ë¦¬ ì¬êµ¬ì„± ì‚¬ìš© ì—¬ë¶€
        """
        messages = []
        
        # 1. ìš”ì•½ì´ ìˆìœ¼ë©´ system ë©”ì‹œì§€ë¡œ ì¶”ê°€ (í”„ë¡¬í”„íŠ¸ ë™ì  êµ¬ì„±)
        if self.memory.summary:
            from services.prompt_builder import PromptBuilder
            prompt_builder = PromptBuilder()
            
            summary_prompt = prompt_builder.build_context_prompt(
                summary=self.memory.summary,
                session_context=await self._get_session_context()
            )
            
            messages.append({
                "role": "system",
                "content": summary_prompt
            })
        
        # 2. ì¿¼ë¦¬ ì¬êµ¬ì„± (í•„ìš” ì‹œ)
        if query and use_query_refinement:
            from services.query_refiner import QueryRefiner
            refiner = QueryRefiner()
            
            # ì´ì „ ì¿¼ë¦¬ ì¬êµ¬ì„± íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
            previous_refinements = await self._get_query_refinement_history()
            
            refined_query = await refiner.refine_query(
                original_query=query,
                session_id=self.session_id,
                previous_results=previous_refinements
            )
            
            # ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ ì‚¬ìš©
            query = refined_query
        
        # 3. ìµœê·¼ ë©”ì‹œì§€ ì¶”ê°€
        recent_messages = self.memory.get_messages()
        for msg in recent_messages:
            messages.append({
                "role": msg.role,
                "content": msg.content
            })
        
        # 4. í˜„ì¬ ì¿¼ë¦¬ ì¶”ê°€ (ì¬êµ¬ì„±ëœ ê²½ìš°)
        if query:
            messages.append({
                "role": "user",
                "content": query
            })
        
        return messages
```

---

### 3. ì „ë‹¬ ì „ëµ (ì–´ë–»ê²Œ ì „ë‹¬í• ì§€)

#### A. SSE ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìš”ì•½ ê³¼ì • í‘œì‹œ

```python
# playground/backend/services/orchestrator.py (ì—…ë°ì´íŠ¸)
async def _handle_chat(
    self,
    context: OrchestratorContext,
    tool: Tool
) -> AsyncGenerator[AgenticEvent, None]:
    """Chat ë„êµ¬ í•¸ë“¤ëŸ¬ (ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ í†µí•©)"""
    from services.context_manager import ContextManager
    
    # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°
    context_manager = await get_context_manager(context.session_id)
    
    # ìš”ì•½ì´ í•„ìš”í•œì§€ í™•ì¸
    if context_manager.memory.needs_summarization():
        # ìš”ì•½ ì‹œì‘ ì´ë²¤íŠ¸
        yield AgenticEvent(
            type=EventType.TOOL_PROGRESS,
            data={
                "step": "summarizing",
                "message": "ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...",
                "progress": 0.1
            }
        )
        
        # ìš”ì•½ ì‹¤í–‰
        await context_manager._summarize_if_needed()
        
        # ìš”ì•½ ì™„ë£Œ ì´ë²¤íŠ¸
        yield AgenticEvent(
            type=EventType.TOOL_PROGRESS,
            data={
                "step": "summarized",
                "message": f"ìš”ì•½ ì™„ë£Œ: {context_manager.memory.summary[:100]}...",
                "progress": 0.2
            }
        )
    
    # ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    messages = await context_manager.get_context_for_llm()
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    messages.append({"role": "user", "content": context.query})
    
    # LLM í˜¸ì¶œ
    # ...
    
    # ì‘ë‹µì„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
    await context_manager.add_message("assistant", response.content, context.model)
```

#### B. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìš”ì•½ í‘œì‹œ

```typescript
// playground/frontend/src/app/chat/page.tsx
const handleSSEEvent = (event: MessageEvent) => {
  const data = JSON.parse(event.data);
  
  if (data.type === "tool_progress") {
    if (data.data.step === "summarizing") {
      // ìš”ì•½ ì¤‘ í‘œì‹œ
      setStatusMessage("ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤...");
    } else if (data.data.step === "summarized") {
      // ìš”ì•½ ì™„ë£Œ í‘œì‹œ
      setStatusMessage(`ìš”ì•½ ì™„ë£Œ: ${data.data.message}`);
      // ìš”ì•½ ë‚´ìš©ì„ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
      setSummary(data.data.message);
    }
  }
};
```

#### C. ìš”ì•½ ìºì‹± ë° ì „ë‹¬

**1. Redis ìºì‹±**
```python
# Redisì— ìš”ì•½ ìºì‹œ
async def get_cached_summary(session_id: str) -> Optional[str]:
    """ìºì‹œëœ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°"""
    from services.session_cache import session_cache
    
    cached = await session_cache.get(f"summary:{session_id}")
    if cached:
        return cached
    
    # MongoDBì—ì„œ ê°€ì ¸ì˜¤ê¸°
    db = get_mongodb_database()
    session = await db.chat_sessions.find_one({"session_id": session_id})
    if session and session.get("summary"):
        # Redisì— ìºì‹œ
        await session_cache.set(
            f"summary:{session_id}",
            session["summary"],
            ttl=3600  # 1ì‹œê°„
        )
        return session["summary"]
    
    return None
```

**2. LLMì— ì „ë‹¬í•˜ëŠ” ë°©ì‹**
```python
async def get_context_for_llm(self) -> List[Dict[str, str]]:
    """LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    messages = []
    
    # 1. ìš”ì•½ì´ ìˆìœ¼ë©´ system ë©”ì‹œì§€ë¡œ ì¶”ê°€
    if self.memory.summary:
        messages.append({
            "role": "system",
            "content": f"""ì´ì „ ëŒ€í™” ìš”ì•½:
{self.memory.summary}

ìµœê·¼ ëŒ€í™”:"""
        })
    
    # 2. ìµœê·¼ ë©”ì‹œì§€ ì¶”ê°€ (ìš”ì•½ ì œì™¸)
    recent_messages = self.memory.get_messages()
    for msg in recent_messages:
        messages.append({
            "role": msg.role,
            "content": msg.content
        })
    
    return messages
```

**3. ìš”ì•½ ì—…ë°ì´íŠ¸ ì‹œ ì „ë‹¬**
```python
# ìš”ì•½ì´ ìƒˆë¡œ ìƒì„±ë˜ë©´ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
if new_summary_created:
    yield AgenticEvent(
        type=EventType.TOOL_PROGRESS,
        data={
            "step": "context_summarized",
            "message": "ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í–ˆìŠµë‹ˆë‹¤. ì´ì „ ëŒ€í™”ì˜ í•µì‹¬ ë‚´ìš©ì€ ê¸°ì–µí•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "summary_preview": summary[:100] + "..."
        }
    )
```

---

## ğŸ“‹ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ìš”ì•½ ì „ëµ
- [x] ìš”ì•½ íŠ¸ë¦¬ê±° ì¡°ê±´ ê²°ì • (ë©”ì‹œì§€ ìˆ˜/í† í° ìˆ˜) âœ… (2025-01-26)
- [x] ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì‘ì„± (í•µì‹¬ ì •ë³´ ë³´ì¡´) âœ… (2025-01-26)
- [x] ìš”ì•½ ëª¨ë¸ ì„ íƒ (ê²½ëŸ‰ ëª¨ë¸) âœ… (2025-01-26)
- [x] ìš”ì•½ ìƒì„± êµ¬í˜„ (`context_manager.py`ì˜ `summarize_if_needed`) âœ…
- [ ] **í”„ë¡¬í”„íŠ¸ ë™ì  êµ¬ì„±** (ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜)
  - **í˜„ì¬**: ê³ ì •ëœ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
  - **í•„ìš”**: ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸, ì´ì „ ìš”ì•½, ë„êµ¬ ì´ë ¥ ë°˜ì˜
  - **í†µí•© ìœ„ì¹˜**: `context_manager.py`ì˜ `_generate_summary()` ë©”ì„œë“œ
  - **ë°©ë²•**: `PromptBuilder` ì„œë¹„ìŠ¤ í™œìš© (07_INTENT_CLASSIFIER.md ì°¸ì¡°)
  - [ ] ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë°˜ì˜
  - [ ] ì´ì „ ìš”ì•½ ì—°ì†ì„± ìœ ì§€
  - [ ] ë„êµ¬ ì‚¬ìš© ì´ë ¥ ë°˜ì˜
- [ ] ìš”ì•½ í’ˆì§ˆ ê²€ì¦

### ì €ì¥ ì „ëµ
- [x] ContextManager ìƒì„± âœ… (2025-01-25)
- [x] ìš”ì•½ ìƒì„± ë° ë©”ëª¨ë¦¬ ì €ì¥ âœ… (`context_manager.py`)
- [ ] **MongoDBì— ìš”ì•½ ì €ì¥**
  - **í˜„ì¬**: ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ (`_session_summaries` dict)
  - **í•„ìš”**: MongoDB `chat_sessions` ì»¬ë ‰ì…˜ì— `summary` í•„ë“œ ì €ì¥
  - **í†µí•© ìœ„ì¹˜**: `context_manager.py`ì˜ `summarize_if_needed()` ë©”ì„œë“œ
  - **ë°©ë²•**:
    ```python
    # summarize_if_needed() ë©”ì„œë“œì— ì¶”ê°€
    from database import get_mongodb_database
    db = get_mongodb_database()
    await db.chat_sessions.update_one(
        {"session_id": session_id},
        {"$set": {
            "summary": summary,
            "summary_created_at": datetime.now(timezone.utc),
            "summary_message_count": len(messages_to_summarize)
        }}
    )
    ```
- [ ] **Vector DBì— ìš”ì•½ ì €ì¥ (ê²€ìƒ‰ ê°€ëŠ¥)**
  - **í†µí•© ìœ„ì¹˜**: `message_vector_store.py`
  - **ë°©ë²•**: ìš”ì•½ì„ ë³„ë„ ë©”ì‹œì§€ë¡œ ì €ì¥ (role="system", type="summary")
- [ ] í•˜ì´ë¸Œë¦¬ë“œ ì €ì¥ êµ¬ì¡° êµ¬í˜„
- [ ] MongoDB ì¸ë±ì‹± (ìš”ì•½ ê²€ìƒ‰ ìµœì í™”) - [13_DB_OPTIMIZATION.md](./13_DB_OPTIMIZATION.md) ì°¸ì¡°
- [ ] Vector DB ì¸ë±ì‹± (ìš”ì•½ ê²€ìƒ‰ ìµœì í™”) - [13_DB_OPTIMIZATION.md](./13_DB_OPTIMIZATION.md) ì°¸ì¡°
- [ ] **ì¿¼ë¦¬ ì¬êµ¬ì„± íˆìŠ¤í† ë¦¬ ì €ì¥**
  - **íŒŒì¼**: MongoDB `query_refinements` ì»¬ë ‰ì…˜ (ì‹ ê·œ)
  - **êµ¬ì¡°**:
    ```python
    {
        "refinement_id": str,
        "session_id": str,
        "original_query": str,
        "refined_query": str,
        "refinement_type": "feedback" | "relevance" | "hyde",
        "user_feedback": Optional[str],
        "success": bool,  # ì¬êµ¬ì„± í›„ ê²€ìƒ‰ ì„±ê³µ ì—¬ë¶€
        "improvement_score": Optional[float],  # ê°œì„ ë„ (0.0-1.0)
        "created_at": datetime
    }
    ```
  - **í†µí•© ìœ„ì¹˜**: `QueryRefiner.refine_query()` ë©”ì„œë“œ (07_INTENT_CLASSIFIER.md ì°¸ì¡°)
  - [ ] ì›ë³¸ ì¿¼ë¦¬ â†’ ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ ë§¤í•‘
  - [ ] í”¼ë“œë°± ê¸°ë°˜ ì¬êµ¬ì„± ê¸°ë¡
  - [ ] ì¬êµ¬ì„± íš¨ê³¼ ì¶”ì  (ì„±ê³µë¥ , ê°œì„ ë„)
- [ ] **í”„ë¡¬í”„íŠ¸ êµ¬ì„± íˆìŠ¤í† ë¦¬ ì €ì¥**
  - **íŒŒì¼**: MongoDB `prompt_history` ì»¬ë ‰ì…˜ (ì‹ ê·œ)
  - **êµ¬ì¡°**:
    ```python
    {
        "prompt_id": str,
        "session_id": str,
        "prompt_type": "rag" | "intent" | "summary" | "chat",
        "base_template": str,
        "final_prompt": str,
        "modifications": Dict[str, Any],  # ì¶”ê°€ëœ instructions, constraints ë“±
        "effectiveness": Optional[float],  # íš¨ê³¼ì„± ì ìˆ˜
        "created_at": datetime
    }
    ```
  - **í†µí•© ìœ„ì¹˜**: `PromptBuilder` ê° ë©”ì„œë“œì—ì„œ (07_INTENT_CLASSIFIER.md ì°¸ì¡°)
  - [ ] ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê¸°ë¡
  - [ ] í”„ë¡¬í”„íŠ¸ ë³€í˜• ì´ë ¥
  - [ ] í”„ë¡¬í”„íŠ¸ íš¨ê³¼ ë¶„ì„

### ì „ë‹¬ ì „ëµ
- [x] SSEë¡œ ìš”ì•½ ê³¼ì • í‘œì‹œ âœ… (2025-01-26)
- [x] ìš”ì•½ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ LLMì— ì „ë‹¬ âœ… (`get_context_with_summary()` êµ¬í˜„ë¨)
- [ ] **í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìš”ì•½ í‘œì‹œ**
  - **ìœ„ì¹˜**: `playground/frontend/src/app/chat/page.tsx`
  - **ë°©ë²•**: SSE ì´ë²¤íŠ¸ `tool_progress`ì—ì„œ `step="summarized"` ì²˜ë¦¬
  - **UI**: ì‚¬ì´ë“œë°” ë˜ëŠ” ìƒë‹¨ì— ìš”ì•½ í‘œì‹œ
- [ ] **ìš”ì•½ ìºì‹± (Redis)**
  - **í†µí•© ìœ„ì¹˜**: `context_manager.py`ì˜ `summarize_if_needed()`
  - **ë°©ë²•**: ìš”ì•½ ìƒì„± ì „ Redis ìºì‹œ í™•ì¸, ìƒì„± í›„ ìºì‹œ ì €ì¥
  - **ìºì‹œ í‚¤**: `summary:{session_id}:{message_count}`
- [ ] **ì¿¼ë¦¬ ì¬êµ¬ì„± í†µí•©** (ì „ë‹¬ ì‹œ)
  - **í†µí•© ìœ„ì¹˜**: `context_manager.py`ì˜ `get_context_for_llm()` ë©”ì„œë“œ
  - **ë°©ë²•**: ì¿¼ë¦¬ ì¬êµ¬ì„± ì˜µì…˜ì´ ìˆìœ¼ë©´ `QueryRefiner` í™œìš©
  - **ì£¼ì˜**: ìš”ì•½ ìƒì„±ì—ëŠ” ì˜í–¥ ì—†ë„ë¡ (ìš”ì•½ì€ ì›ë³¸ ë©”ì‹œì§€ ê¸°ë°˜)
- [ ] Redis ì¸ë±ì‹± (ìš”ì•½ ìºì‹œ ìµœì í™”) - [13_DB_OPTIMIZATION.md](./13_DB_OPTIMIZATION.md) ì°¸ì¡°

---

## ğŸ¯ ìµœì¢… êµ¬ì¡°

```
ë©”ì‹œì§€ ì¶”ê°€
    â†“
ë©”ëª¨ë¦¬ì— ì €ì¥ (SummaryMemory)
    â†“
20ê°œ ì´ˆê³¼? â†’ ìš”ì•½ íŠ¸ë¦¬ê±°
    â†“
LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±
    â†“
MongoDBì— ìš”ì•½ ì €ì¥
    â†“
Vector DBì— ìš”ì•½ ì €ì¥ (ê²€ìƒ‰ ê°€ëŠ¥)
    â†“
ìµœê·¼ 10ê°œ ë©”ì‹œì§€ + ìš”ì•½ì„ LLMì— ì „ë‹¬
```

---

## ğŸ’¡ í•µì‹¬ ì›ì¹™

1. **ìë™ ìš”ì•½**: 20ê°œ ë©”ì‹œì§€ ì´ˆê³¼ ì‹œ ìë™ ìš”ì•½
2. **í•µì‹¬ ë³´ì¡´**: ì¤‘ìš”í•œ ì •ë³´ëŠ” ë°˜ë“œì‹œ ìš”ì•½ì— í¬í•¨
3. **ê²€ìƒ‰ ê°€ëŠ¥**: ìš”ì•½ë„ Vector DBì— ì €ì¥í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥
4. **ì‚¬ìš©ì ì¸ì§€**: ìš”ì•½ ê³¼ì •ì„ SSEë¡œ ì‹¤ì‹œê°„ í‘œì‹œ
