"""
ChunkValidator - ì²­í¬(Document) ê²€ì¦
SOLID ì›ì¹™:
- SRP: ì²­í¬ ê²€ì¦ë§Œ ë‹´ë‹¹
- OCP: ìƒˆë¡œìš´ ê²€ì¦ ê·œì¹™ ì¶”ê°€ ê°€ëŠ¥
"""

from __future__ import annotations

from collections import defaultdict
from typing import Any, Dict, List, Optional, Set, Tuple

from beanllm.utils.logging import get_logger

logger = get_logger(__name__)


class ChunkValidator:
    """
    ì²­í¬ ê²€ì¦ê¸°

    ì±…ì„:
    - ì²­í¬ í¬ê¸° ê²€ì¦
    - ì¤‘ë³µ ì²­í¬ íƒì§€
    - ë©”íƒ€ë°ì´í„° ê²€ì¦
    - ì²­í¬ ê°„ overlap ê²€ì¦
    - ê¶Œì¥ì‚¬í•­ ìƒì„±
    """

    def __init__(
        self,
        min_chunk_size: int = 100,
        max_chunk_size: int = 2000,
        overlap_threshold: float = 0.9,
    ) -> None:
        """
        Args:
            min_chunk_size: ìµœì†Œ ì²­í¬ í¬ê¸° (characters)
            max_chunk_size: ìµœëŒ€ ì²­í¬ í¬ê¸° (characters)
            overlap_threshold: ì¤‘ë³µ íŒë‹¨ ì„ê³„ê°’ (Jaccard similarity)
        """
        self.min_chunk_size = min_chunk_size
        self.max_chunk_size = max_chunk_size
        self.overlap_threshold = overlap_threshold

    def validate_size(
        self, documents: List[Any]
    ) -> Tuple[List[Dict[str, Any]], Dict[str, int]]:
        """
        ì²­í¬ í¬ê¸° ê²€ì¦

        Args:
            documents: Document ë¦¬ìŠ¤íŠ¸

        Returns:
            Tuple[List[Dict], Dict]:
                - issues: ë¬¸ì œê°€ ìˆëŠ” ì²­í¬ ëª©ë¡
                - distribution: í¬ê¸° ë¶„í¬ {"0-200": 10, "200-500": 50, ...}
        """
        logger.info(f"Validating chunk sizes for {len(documents)} documents")

        issues = []
        sizes = []

        for i, doc in enumerate(documents):
            content = doc.page_content if hasattr(doc, "page_content") else str(doc)
            size = len(content)
            sizes.append(size)

            if size < self.min_chunk_size:
                issues.append(
                    {
                        "type": "size_too_small",
                        "chunk_id": i,
                        "size": size,
                        "min_size": self.min_chunk_size,
                        "details": f"Chunk size {size} < {self.min_chunk_size}",
                    }
                )
            elif size > self.max_chunk_size:
                issues.append(
                    {
                        "type": "size_too_large",
                        "chunk_id": i,
                        "size": size,
                        "max_size": self.max_chunk_size,
                        "details": f"Chunk size {size} > {self.max_chunk_size}",
                    }
                )

        # Compute size distribution
        distribution = self._compute_size_distribution(sizes)

        logger.info(
            f"Size validation completed: {len(issues)} issues found, "
            f"distribution: {distribution}"
        )

        return issues, distribution

    def _compute_size_distribution(self, sizes: List[int]) -> Dict[str, int]:
        """
        í¬ê¸° ë¶„í¬ ê³„ì‚°

        Args:
            sizes: ì²­í¬ í¬ê¸° ë¦¬ìŠ¤íŠ¸

        Returns:
            Dict: í¬ê¸° êµ¬ê°„ë³„ ê°œìˆ˜
        """
        bins = [0, 200, 500, 1000, 2000, float("inf")]
        labels = ["0-200", "200-500", "500-1000", "1000-2000", "2000+"]

        distribution = {label: 0 for label in labels}

        for size in sizes:
            for i in range(len(bins) - 1):
                if bins[i] <= size < bins[i + 1]:
                    distribution[labels[i]] += 1
                    break

        return distribution

    def detect_duplicates(
        self, documents: List[Any], threshold: Optional[float] = None
    ) -> List[Tuple[int, int]]:
        """
        ì¤‘ë³µ ì²­í¬ íƒì§€ (Jaccard similarity ê¸°ë°˜)

        Args:
            documents: Document ë¦¬ìŠ¤íŠ¸
            threshold: Jaccard similarity ì„ê³„ê°’ (Noneì´ë©´ self.overlap_threshold ì‚¬ìš©)

        Returns:
            List[Tuple[int, int]]: ì¤‘ë³µ ì²­í¬ ì¸ë±ìŠ¤ ìŒ

        Mathematical Details:
            Jaccard similarity = |A âˆ© B| / |A âˆª B|
            - A, B: ë‘ ì²­í¬ì˜ ë‹¨ì–´ ì§‘í•©
            - 0 ~ 1 ì‚¬ì´ ê°’ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
        """
        threshold = threshold or self.overlap_threshold
        logger.info(
            f"Detecting duplicates in {len(documents)} documents "
            f"(threshold={threshold})"
        )

        duplicates = []

        # Compute Jaccard similarity for all pairs (O(nÂ²))
        # For large datasets, use LSH (Locality Sensitive Hashing)
        for i in range(len(documents)):
            for j in range(i + 1, len(documents)):
                content_i = (
                    documents[i].page_content
                    if hasattr(documents[i], "page_content")
                    else str(documents[i])
                )
                content_j = (
                    documents[j].page_content
                    if hasattr(documents[j], "page_content")
                    else str(documents[j])
                )

                similarity = self._jaccard_similarity(content_i, content_j)

                if similarity >= threshold:
                    duplicates.append((i, j))

        logger.info(f"Found {len(duplicates)} duplicate pairs")
        return duplicates

    def _jaccard_similarity(self, text1: str, text2: str) -> float:
        """
        Jaccard similarity ê³„ì‚°

        Args:
            text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸
            text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸

        Returns:
            float: Jaccard similarity (0 ~ 1)
        """
        # Tokenize (simple word-based)
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if len(words1) == 0 and len(words2) == 0:
            return 1.0  # Both empty

        intersection = len(words1 & words2)
        union = len(words1 | words2)

        if union == 0:
            return 0.0

        return intersection / union

    def validate_metadata(
        self, documents: List[Any], required_keys: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        ë©”íƒ€ë°ì´í„° ê²€ì¦

        Args:
            documents: Document ë¦¬ìŠ¤íŠ¸
            required_keys: í•„ìˆ˜ ë©”íƒ€ë°ì´í„° í‚¤ ëª©ë¡

        Returns:
            List[Dict]: ë©”íƒ€ë°ì´í„° ë¬¸ì œ ëª©ë¡
        """
        required_keys = required_keys or []
        logger.info(
            f"Validating metadata for {len(documents)} documents "
            f"(required keys: {required_keys})"
        )

        issues = []

        for i, doc in enumerate(documents):
            metadata = doc.metadata if hasattr(doc, "metadata") else {}

            # Check for missing required keys
            for key in required_keys:
                if key not in metadata:
                    issues.append(
                        {
                            "type": "missing_metadata",
                            "chunk_id": i,
                            "missing_key": key,
                            "details": f"Required metadata key '{key}' is missing",
                        }
                    )

            # Check for empty metadata
            if not metadata:
                issues.append(
                    {
                        "type": "empty_metadata",
                        "chunk_id": i,
                        "details": "Metadata is empty",
                    }
                )

        logger.info(f"Metadata validation completed: {len(issues)} issues found")
        return issues

    def check_overlap(
        self, documents: List[Any]
    ) -> Optional[Dict[str, Any]]:
        """
        ì²­í¬ ê°„ overlap í†µê³„

        Args:
            documents: Document ë¦¬ìŠ¤íŠ¸

        Returns:
            Dict: Overlap í†µê³„ ë˜ëŠ” None (ê³„ì‚° ë¶ˆê°€ëŠ¥ ì‹œ)

        Note:
            ìˆœì°¨ì ìœ¼ë¡œ ì¸ì ‘í•œ ì²­í¬ ê°„ overlapë§Œ í™•ì¸
            ì „ì²´ pair-wiseëŠ” O(nÂ²)ë¡œ ë¹„íš¨ìœ¨ì 
        """
        logger.info(f"Checking overlap for {len(documents)} documents")

        if len(documents) < 2:
            logger.warning("Need at least 2 documents to check overlap")
            return None

        overlaps = []

        for i in range(len(documents) - 1):
            content_i = (
                documents[i].page_content
                if hasattr(documents[i], "page_content")
                else str(documents[i])
            )
            content_j = (
                documents[i + 1].page_content
                if hasattr(documents[i + 1], "page_content")
                else str(documents[i + 1])
            )

            # Find longest common substring (LCS)
            lcs_length = self._longest_common_substring_length(content_i, content_j)
            overlap_ratio = lcs_length / min(len(content_i), len(content_j))

            overlaps.append(
                {
                    "chunk_pair": (i, i + 1),
                    "lcs_length": lcs_length,
                    "overlap_ratio": overlap_ratio,
                }
            )

        # Statistics
        overlap_ratios = [o["overlap_ratio"] for o in overlaps]
        stats = {
            "num_pairs": len(overlaps),
            "avg_overlap_ratio": sum(overlap_ratios) / len(overlap_ratios)
            if overlap_ratios
            else 0.0,
            "max_overlap_ratio": max(overlap_ratios) if overlap_ratios else 0.0,
            "min_overlap_ratio": min(overlap_ratios) if overlap_ratios else 0.0,
        }

        logger.info(f"Overlap check completed: {stats}")
        return stats

    def _longest_common_substring_length(self, text1: str, text2: str) -> int:
        """
        ìµœì¥ ê³µí†µ ë¶€ë¶„ ë¬¸ìì—´ ê¸¸ì´ (LCS)

        Args:
            text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸
            text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸

        Returns:
            int: LCS ê¸¸ì´

        Algorithm:
            Dynamic Programming O(m*n)
        """
        m, n = len(text1), len(text2)
        if m == 0 or n == 0:
            return 0

        # DP table
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        max_length = 0

        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if text1[i - 1] == text2[j - 1]:
                    dp[i][j] = dp[i - 1][j - 1] + 1
                    max_length = max(max_length, dp[i][j])

        return max_length

    def generate_recommendations(
        self,
        size_issues: List[Dict[str, Any]],
        duplicates: List[Tuple[int, int]],
        metadata_issues: List[Dict[str, Any]],
        overlap_stats: Optional[Dict[str, Any]],
    ) -> List[str]:
        """
        ê²€ì¦ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±

        Args:
            size_issues: í¬ê¸° ë¬¸ì œ ëª©ë¡
            duplicates: ì¤‘ë³µ ì²­í¬ ëª©ë¡
            metadata_issues: ë©”íƒ€ë°ì´í„° ë¬¸ì œ ëª©ë¡
            overlap_stats: Overlap í†µê³„

        Returns:
            List[str]: ê¶Œì¥ì‚¬í•­ ëª©ë¡
        """
        recommendations = []

        # Size recommendations
        too_small = sum(1 for issue in size_issues if issue["type"] == "size_too_small")
        too_large = sum(1 for issue in size_issues if issue["type"] == "size_too_large")

        if too_small > 0:
            recommendations.append(
                f"âš ï¸  {too_small} chunks are too small (< {self.min_chunk_size} chars). "
                "Consider increasing chunk_size or reducing chunk_overlap."
            )

        if too_large > 0:
            recommendations.append(
                f"âš ï¸  {too_large} chunks are too large (> {self.max_chunk_size} chars). "
                "Consider decreasing chunk_size."
            )

        # Duplicate recommendations
        if len(duplicates) > 0:
            recommendations.append(
                f"âš ï¸  Found {len(duplicates)} duplicate chunk pairs. "
                "Consider deduplication or adjusting chunk_overlap."
            )

        # Metadata recommendations
        if len(metadata_issues) > 0:
            recommendations.append(
                f"âš ï¸  {len(metadata_issues)} metadata issues found. "
                "Ensure all chunks have proper metadata (source, page, etc.)."
            )

        # Overlap recommendations
        if overlap_stats and overlap_stats["avg_overlap_ratio"] > 0.5:
            recommendations.append(
                f"âš ï¸  High overlap detected (avg {overlap_stats['avg_overlap_ratio']:.2%}). "
                "Consider reducing chunk_overlap parameter."
            )
        elif overlap_stats and overlap_stats["avg_overlap_ratio"] < 0.1:
            recommendations.append(
                f"ğŸ’¡ Low overlap detected (avg {overlap_stats['avg_overlap_ratio']:.2%}). "
                "This may cause loss of context. Consider increasing chunk_overlap."
            )

        if not recommendations:
            recommendations.append("âœ… No major issues detected. Chunks look good!")

        return recommendations

    def validate_all(
        self,
        documents: List[Any],
        required_metadata_keys: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ê²€ì¦ íŒŒì´í”„ë¼ì¸

        Args:
            documents: Document ë¦¬ìŠ¤íŠ¸
            required_metadata_keys: í•„ìˆ˜ ë©”íƒ€ë°ì´í„° í‚¤

        Returns:
            Dict: ê²€ì¦ ê²°ê³¼
                - total_chunks: ì´ ì²­í¬ ìˆ˜
                - size_issues: í¬ê¸° ë¬¸ì œ
                - size_distribution: í¬ê¸° ë¶„í¬
                - duplicates: ì¤‘ë³µ ì²­í¬
                - metadata_issues: ë©”íƒ€ë°ì´í„° ë¬¸ì œ
                - overlap_stats: Overlap í†µê³„
                - recommendations: ê¶Œì¥ì‚¬í•­
        """
        logger.info(f"Starting full validation for {len(documents)} documents")

        # 1. Size validation
        size_issues, size_distribution = self.validate_size(documents)

        # 2. Duplicate detection
        duplicates = self.detect_duplicates(documents)

        # 3. Metadata validation
        metadata_issues = self.validate_metadata(documents, required_metadata_keys)

        # 4. Overlap check
        overlap_stats = self.check_overlap(documents)

        # 5. Generate recommendations
        recommendations = self.generate_recommendations(
            size_issues, duplicates, metadata_issues, overlap_stats
        )

        results = {
            "total_chunks": len(documents),
            "valid_chunks": len(documents)
            - len(size_issues)
            - len(duplicates)
            - len(metadata_issues),
            "size_issues": size_issues,
            "size_distribution": size_distribution,
            "duplicate_chunks": duplicates,
            "metadata_issues": metadata_issues,
            "overlap_stats": overlap_stats,
            "recommendations": recommendations,
        }

        logger.info("Full validation completed")
        return results
