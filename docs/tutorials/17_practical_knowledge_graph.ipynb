{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Practical Knowledge Graph with Advanced Features\n",
    "\n",
    "Ïù¥ ÌäúÌÜ†Î¶¨ÏñºÏóêÏÑúÎäî Ïã§Ï†Ñ Knowledge Graph Íµ¨Ï∂ï ÌîÑÎ°úÏ†ùÌä∏Î•º ÏßÑÌñâÌï©ÎãàÎã§.\n",
    "\n",
    "## ÌîÑÎ°úÏ†ùÌä∏ Í∞úÏöî\n",
    "\n",
    "**Î™©Ìëú**: AI Ïó∞Íµ¨ ÎÖºÎ¨∏Îì§ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Ïó∞Íµ¨Ïûê, Í∏∞Ïà†, Í∏∞Í¥Ä Í∞ÑÏùò Í¥ÄÍ≥Ñ ÎÑ§Ìä∏ÏõåÌÅ¨Î•º Íµ¨Ï∂ï\n",
    "\n",
    "**ÏÇ¨Ïö© Í∏∞Ïà†**:\n",
    "1. **Knowledge Graph** - ÏóîÌã∞Ìã∞/Í¥ÄÍ≥Ñ Ï∂îÏ∂ú Î∞è Í∑∏ÎûòÌîÑ Íµ¨Ï∂ï\n",
    "2. **Distributed Features** - Ï∫êÏã±, Rate Limiting, Event Streaming\n",
    "3. **Batch Processing** - Î≥ëÎ†¨ Î¨∏ÏÑú Ï≤òÎ¶¨\n",
    "4. **Model Router** - ÎπÑÏö© ÏµúÏ†ÅÌôî Î™®Îç∏ ÏÑ†ÌÉù\n",
    "5. **Real-time Streaming** - ÏßÑÌñâ ÏÉÅÌô© Ïã§ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅ\n",
    "\n",
    "## Î™©Ï∞®\n",
    "\n",
    "1. **Setup & Configuration**\n",
    "2. **Data Preparation**\n",
    "3. **Building the Knowledge Graph**\n",
    "4. **Querying the Graph**\n",
    "5. **Graph-based RAG**\n",
    "6. **Performance Analysis**\n",
    "7. **Visualization & Export**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from beanllm import Client\n",
    "from beanllm.facade.advanced.knowledge_graph_facade import KnowledgeGraph\n",
    "from beanllm.infrastructure.distributed import (\n",
    "    update_pipeline_config,\n",
    "    get_pipeline_config,\n",
    ")\n",
    "from beanllm.infrastructure.routing import (\n",
    "    ModelRouter,\n",
    "    RoutingStrategy,\n",
    "    RequestCharacteristics,\n",
    "    create_default_router,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure distributed features\n",
    "print(\"Configuring distributed features...\")\n",
    "\n",
    "# Enable all distributed features for Knowledge Graph pipeline\n",
    "update_pipeline_config(\n",
    "    pipeline_type=\"knowledge_graph\",\n",
    "    enable_cache=True,\n",
    "    enable_rate_limiting=True,\n",
    "    enable_event_streaming=True,\n",
    "    kg_cache_ttl=7200,  # 2 hours\n",
    ")\n",
    "\n",
    "# Verify configuration\n",
    "config = get_pipeline_config(\"knowledge_graph\")\n",
    "print(\"\\nüìã Knowledge Graph Pipeline Config:\")\n",
    "print(f\"   Cache: {config.enable_cache}\")\n",
    "print(f\"   Rate Limiting: {config.enable_rate_limiting}\")\n",
    "print(f\"   Event Streaming: {config.enable_event_streaming}\")\n",
    "print(f\"   Cache TTL: {config.kg_cache_ttl}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Router for cost-optimized model selection\n",
    "print(\"\\nInitializing Model Router...\")\n",
    "\n",
    "model_router = create_default_router(strategy=RoutingStrategy.COMPLEXITY_BASED)\n",
    "print(f\"‚úÖ Model Router initialized with {len(model_router.models)} models\")\n",
    "print(f\"   Strategy: {model_router.strategy.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KnowledgeGraph\n",
    "client = Client(provider=\"openai\", api_key=\"your-api-key\")\n",
    "kg = KnowledgeGraph(client=client)\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Ïã§Ï†ú AI Ïó∞Íµ¨ ÎÖºÎ¨∏ Ï¥àÎ°ù Îç∞Ïù¥ÌÑ∞Î•º Ï§ÄÎπÑÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real AI research paper abstracts\n",
    "research_papers = [\n",
    "    # Deep Learning\n",
    "    \"\"\"Deep Learning has revolutionized artificial intelligence. \n",
    "    Convolutional Neural Networks (CNNs) were pioneered by Yann LeCun at Bell Labs in 1989.\n",
    "    AlexNet, developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton at the University of Toronto,\n",
    "    won the ImageNet competition in 2012, marking a breakthrough in computer vision.\n",
    "    ResNet, introduced by Kaiming He and colleagues at Microsoft Research in 2015,\n",
    "    introduced residual connections enabling training of very deep networks.\"\"\",\n",
    "    \n",
    "    # Transformers & NLP\n",
    "    \"\"\"The Transformer architecture revolutionized Natural Language Processing.\n",
    "    Attention Is All You Need was published by researchers at Google Brain in 2017,\n",
    "    including Ashish Vaswani and Noam Shazeer.\n",
    "    BERT, introduced by Jacob Devlin and colleagues at Google in 2018,\n",
    "    demonstrated the power of bidirectional pre-training.\n",
    "    GPT-3, released by OpenAI in 2020 with 175 billion parameters,\n",
    "    showed emergent capabilities through scale.\n",
    "    The model was developed by a team led by Sam Altman and Ilya Sutskever.\"\"\",\n",
    "    \n",
    "    # Reinforcement Learning\n",
    "    \"\"\"Reinforcement Learning enables agents to learn from interaction with environments.\n",
    "    Q-Learning was developed by Chris Watkins in his PhD thesis at Cambridge University in 1989.\n",
    "    Deep Q-Network (DQN), introduced by DeepMind in 2013,\n",
    "    combined deep learning with reinforcement learning.\n",
    "    AlphaGo, developed by Demis Hassabis and David Silver at DeepMind,\n",
    "    defeated world champion Lee Sedol in 2016 using deep reinforcement learning.\n",
    "    AlphaZero extended this to master chess, shogi, and Go through self-play.\"\"\",\n",
    "    \n",
    "    # GANs\n",
    "    \"\"\"Generative Adversarial Networks (GANs) were proposed by Ian Goodfellow\n",
    "    while at the University of Montreal in 2014.\n",
    "    StyleGAN, developed by researchers at NVIDIA including Tero Karras,\n",
    "    produces photorealistic face generation.\n",
    "    GANs have applications in image synthesis, style transfer, and data augmentation.\n",
    "    Yann LeCun called GANs 'the most interesting idea in machine learning in the last 10 years'.\"\"\",\n",
    "    \n",
    "    # Transfer Learning\n",
    "    \"\"\"Transfer Learning allows models to leverage knowledge from related tasks.\n",
    "    ImageNet pretraining, popularized after AlexNet's success in 2012,\n",
    "    became the standard approach for computer vision.\n",
    "    Fine-tuning techniques, studied extensively at Stanford University by Andrew Ng and colleagues,\n",
    "    have improved model efficiency significantly.\n",
    "    BERT and GPT demonstrated that transfer learning is equally powerful in NLP.\"\"\",\n",
    "    \n",
    "    # Recent Developments\n",
    "    \"\"\"Large Language Models have emerged as a dominant paradigm.\n",
    "    ChatGPT, launched by OpenAI in November 2022, reached 100 million users in 2 months.\n",
    "    Claude, developed by Anthropic (founded by Dario Amodei and Daniela Amodei),\n",
    "    focuses on AI safety and alignment.\n",
    "    LLaMA, released by Meta AI in 2023, provides open-source alternatives.\n",
    "    Gemini, announced by Google DeepMind, integrates multimodal capabilities.\"\"\",\n",
    "    \n",
    "    # Computer Vision\n",
    "    \"\"\"Computer Vision has progressed from simple edge detection to complex scene understanding.\n",
    "    YOLO (You Only Look Once), created by Joseph Redmon at the University of Washington,\n",
    "    enabled real-time object detection.\n",
    "    Vision Transformers (ViT), introduced by researchers at Google Research in 2020,\n",
    "    applied transformer architecture to images.\n",
    "    CLIP, developed by OpenAI, learns visual concepts from natural language supervision.\"\"\",\n",
    "    \n",
    "    # AI Safety\n",
    "    \"\"\"AI Safety and Alignment have become critical research areas.\n",
    "    Anthropic, founded by former OpenAI researchers including Dario Amodei,\n",
    "    focuses on building safer AI systems.\n",
    "    Constitutional AI, proposed by Anthropic researchers,\n",
    "    uses AI feedback to train helpful, harmless, and honest assistants.\n",
    "    Stuart Russell at UC Berkeley advocates for provably beneficial AI.\n",
    "    Eliezer Yudkowsky at MIRI studies AI alignment theory.\"\"\",\n",
    "]\n",
    "\n",
    "print(f\"üìö Prepared {len(research_papers)} research paper abstracts\")\n",
    "print(f\"üìä Total characters: {sum(len(p) for p in research_papers):,}\")\n",
    "print(f\"üìà Avg length: {sum(len(p) for p in research_papers) / len(research_papers):.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the Knowledge Graph\n",
    "\n",
    "### 3.1 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Model Router to select optimal model\n",
    "avg_paper_length = sum(len(p) for p in research_papers) / len(research_papers)\n",
    "\n",
    "request_characteristics = RequestCharacteristics(\n",
    "    prompt_length=int(avg_paper_length),\n",
    "    complexity_score=0.7,  # Entity extraction is moderately complex\n",
    "    context_window_needed=8000,\n",
    "    requires_json_mode=True,  # Structured output\n",
    ")\n",
    "\n",
    "routing_decision = model_router.route(request_characteristics)\n",
    "\n",
    "print(\"üß≠ Model Selection:\")\n",
    "print(f\"   Selected: {routing_decision.selected_model.provider}:{routing_decision.selected_model.model_id}\")\n",
    "print(f\"   Reason: {routing_decision.reason}\")\n",
    "print(f\"   Estimated cost: ${routing_decision.estimated_cost:.6f} per paper\")\n",
    "print(f\"   Total estimated cost: ${routing_decision.estimated_cost * len(research_papers):.4f}\")\n",
    "print(f\"   Confidence: {routing_decision.confidence_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Graph Construction with Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Knowledge Graph with automatic batch processing (>= 5 documents)\n",
    "print(\"\\nüî® Building Knowledge Graph...\")\n",
    "print(f\"   Processing {len(research_papers)} papers\")\n",
    "print(f\"   Batch processing: {'ENABLED' if len(research_papers) >= 5 else 'DISABLED'}\")\n",
    "print(f\"   Max concurrent: 10 workers\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "build_response = await kg.build_graph(\n",
    "    documents=research_papers,\n",
    "    graph_id=\"ai_research_network\",\n",
    "    entity_types=[\"person\", \"organization\", \"technology\", \"location\"],\n",
    "    relation_types=[\"developed\", \"works_at\", \"founded\", \"introduced\", \"collaborated_with\"],\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Knowledge Graph Built Successfully!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚è±Ô∏è  Total time: {elapsed:.2f}s\")\n",
    "print(f\"üìä Avg time per document: {elapsed / len(research_papers):.2f}s\")\n",
    "print(f\"üìà Throughput: {len(research_papers) / elapsed:.2f} docs/sec\")\n",
    "print(f\"\\nüî¢ Graph Statistics:\")\n",
    "print(f\"   Nodes (entities): {build_response.num_nodes}\")\n",
    "print(f\"   Edges (relations): {build_response.num_edges}\")\n",
    "print(f\"   Density: {build_response.density:.4f}\")\n",
    "print(f\"   Connected components: {build_response.num_connected_components}\")\n",
    "print(f\"   Graph ID: {build_response.graph_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Querying the Graph\n",
    "\n",
    "### 4.1 Find All Researchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Find all person entities\n",
    "print(\"\\nüîç Query 1: Find All Researchers\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "researchers_response = await kg.query_graph(\n",
    "    graph_id=\"ai_research_network\",\n",
    "    query_type=\"find_entities_by_type\",\n",
    "    params={\"entity_type\": \"person\"},\n",
    ")\n",
    "\n",
    "print(f\"Found {len(researchers_response.results)} researchers:\\n\")\n",
    "for i, researcher in enumerate(researchers_response.results[:10], 1):\n",
    "    name = researcher.get(\"name\", \"Unknown\")\n",
    "    confidence = researcher.get(\"confidence\", 1.0)\n",
    "    print(f\"   {i}. {name} (confidence: {confidence:.2f})\")\n",
    "\n",
    "if len(researchers_response.results) > 10:\n",
    "    print(f\"   ... and {len(researchers_response.results) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Find Organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Find all organization entities\n",
    "print(\"\\nüîç Query 2: Find All Organizations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "orgs_response = await kg.query_graph(\n",
    "    graph_id=\"ai_research_network\",\n",
    "    query_type=\"find_entities_by_type\",\n",
    "    params={\"entity_type\": \"organization\"},\n",
    ")\n",
    "\n",
    "print(f\"Found {len(orgs_response.results)} organizations:\\n\")\n",
    "for i, org in enumerate(orgs_response.results[:10], 1):\n",
    "    name = org.get(\"name\", \"Unknown\")\n",
    "    print(f\"   {i}. {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Find Technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Find all technology entities\n",
    "print(\"\\nüîç Query 3: Find All Technologies\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tech_response = await kg.query_graph(\n",
    "    graph_id=\"ai_research_network\",\n",
    "    query_type=\"find_entities_by_type\",\n",
    "    params={\"entity_type\": \"technology\"},\n",
    ")\n",
    "\n",
    "print(f\"Found {len(tech_response.results)} technologies:\\n\")\n",
    "for i, tech in enumerate(tech_response.results[:15], 1):\n",
    "    name = tech.get(\"name\", \"Unknown\")\n",
    "    print(f\"   {i}. {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Find Related Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Find entities related to a specific researcher\n",
    "# (Replace with actual entity ID from results above)\n",
    "print(\"\\nüîç Query 4: Find Related Entities\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Looking for entities related to 'Ian Goodfellow'...\\n\")\n",
    "\n",
    "# First, find Ian Goodfellow\n",
    "goodfellow_response = await kg.query_graph(\n",
    "    graph_id=\"ai_research_network\",\n",
    "    query_type=\"find_entities_by_name\",\n",
    "    params={\"name\": \"Ian Goodfellow\", \"fuzzy\": True},\n",
    ")\n",
    "\n",
    "if goodfellow_response.results:\n",
    "    goodfellow_id = goodfellow_response.results[0].get(\"id\")\n",
    "    \n",
    "    # Find related entities\n",
    "    related_response = await kg.query_graph(\n",
    "        graph_id=\"ai_research_network\",\n",
    "        query_type=\"find_related_entities\",\n",
    "        params={\n",
    "            \"entity_id\": goodfellow_id,\n",
    "            \"max_hops\": 2,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(related_response.results)} related entities:\\n\")\n",
    "    for i, entity in enumerate(related_response.results[:10], 1):\n",
    "        name = entity.get(\"name\", \"Unknown\")\n",
    "        entity_type = entity.get(\"type\", \"unknown\")\n",
    "        print(f\"   {i}. {name} ({entity_type})\")\nelse:\n",
    "    print(\"Ian Goodfellow not found in graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Graph-based RAG\n",
    "\n",
    "Í∑∏ÎûòÌîÑÎ•º ÌôúÏö©Ìïú ÏßàÎ¨∏-ÎãµÎ≥Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries for Graph RAG\n",
    "queries = [\n",
    "    \"Who developed AlexNet?\",\n",
    "    \"What technologies were introduced by Google?\",\n",
    "    \"Which researchers work at OpenAI?\",\n",
    "    \"Who founded Anthropic?\",\n",
    "    \"What are the main applications of GANs?\",\n",
    "]\n",
    "\n",
    "print(\"\\nü§ñ Graph-based RAG Queries\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\n‚ùì Query {i}: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Execute Graph RAG\n",
    "    rag_response = await kg.graph_rag(\n",
    "        query=query,\n",
    "        graph_id=\"ai_research_network\",\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Results: {rag_response.num_results} matches found\")\n",
    "    \n",
    "    # Show top 3 results\n",
    "    for j, result in enumerate(rag_response.hybrid_results[:3], 1):\n",
    "        entity_name = result.get(\"entity_name\", \"Unknown\")\n",
    "        score = result.get(\"score\", 0.0)\n",
    "        print(f\"   {j}. {entity_name} (score: {score:.3f})\")\n",
    "    \n",
    "    # Add spacing\n",
    "    if i < len(queries):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Analysis\n",
    "\n",
    "### 6.1 Caching Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test caching performance\n",
    "print(\"\\n‚ö° Testing Cache Performance\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_query = \"Who developed AlexNet?\"\n",
    "\n",
    "# First call (cache miss)\n",
    "start = time.time()\n",
    "response1 = await kg.graph_rag(query=test_query, graph_id=\"ai_research_network\")\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Second call (cache hit)\n",
    "start = time.time()\n",
    "response2 = await kg.graph_rag(query=test_query, graph_id=\"ai_research_network\")\n",
    "time2 = time.time() - start\n",
    "\n",
    "# Third call (cache hit)\n",
    "start = time.time()\n",
    "response3 = await kg.graph_rag(query=test_query, graph_id=\"ai_research_network\")\n",
    "time3 = time.time() - start\n",
    "\n",
    "speedup = time1 / ((time2 + time3) / 2)\n",
    "\n",
    "print(f\"\\nQuery: '{test_query}'\")\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"   1st call (cache miss): {time1:.3f}s\")\n",
    "print(f\"   2nd call (cache hit):  {time2:.3f}s\")\n",
    "print(f\"   3rd call (cache hit):  {time3:.3f}s\")\n",
    "print(f\"\\nüöÄ Speedup: {speedup:.1f}x\")\n",
    "print(f\"üí∞ Time saved: {(time1 - time2):.3f}s per cached query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Overall Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_queries = len(queries) + 3  # RAG queries + cache tests\n",
    "\n",
    "print(f\"\\nüìö Input Data:\")\n",
    "print(f\"   Documents processed: {len(research_papers)}\")\n",
    "print(f\"   Total characters: {sum(len(p) for p in research_papers):,}\")\n",
    "print(f\"   Processing time: {elapsed:.2f}s\")\n",
    "print(f\"   Throughput: {len(research_papers) / elapsed:.2f} docs/sec\")\n",
    "\n",
    "print(f\"\\nüî¢ Graph:\")\n",
    "print(f\"   Nodes (entities): {build_response.num_nodes}\")\n",
    "print(f\"   Edges (relations): {build_response.num_edges}\")\n",
    "print(f\"   Density: {build_response.density:.4f}\")\n",
    "\n",
    "print(f\"\\nüîç Queries Executed: {total_queries}\")\n",
    "print(f\"   Entity type queries: 3\")\n",
    "print(f\"   Relation queries: 1\")\n",
    "print(f\"   Graph RAG queries: {len(queries)}\")\n",
    "print(f\"   Cache test queries: 3\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance:\")\n",
    "print(f\"   Batch processing: ENABLED (10 workers)\")\n",
    "print(f\"   Caching: ENABLED (2hr TTL)\")\n",
    "print(f\"   Rate limiting: ENABLED\")\n",
    "print(f\"   Cache speedup: {speedup:.1f}x\")\n",
    "\n",
    "print(f\"\\nüí∞ Cost Optimization:\")\n",
    "print(f\"   Model: {routing_decision.selected_model.model_id}\")\n",
    "print(f\"   Strategy: {model_router.strategy.value}\")\n",
    "print(f\"   Estimated cost: ${routing_decision.estimated_cost * len(research_papers):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization & Export\n",
    "\n",
    "### 7.1 Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph (ASCII representation)\n",
    "print(\"\\nüìä Graph Visualization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "visualization = await kg.visualize_graph(graph_id=\"ai_research_network\")\n",
    "print(visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Export to Neo4j (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have Neo4j running, you can export the graph\n",
    "# Uncomment to use:\n",
    "\n",
    "# kg.set_neo4j_adapter(\n",
    "#     uri=\"bolt://localhost:7687\",\n",
    "#     user=\"neo4j\",\n",
    "#     password=\"your-password\"\n",
    "# )\n",
    "#\n",
    "# # Re-build with persist_to_neo4j=True\n",
    "# build_response = await kg.build_graph(\n",
    "#     documents=research_papers,\n",
    "#     graph_id=\"ai_research_network\",\n",
    "#     persist_to_neo4j=True,\n",
    "# )\n",
    "#\n",
    "# print(\"‚úÖ Graph exported to Neo4j\")\n",
    "\n",
    "print(\"üí° Neo4j export is optional. Uncomment the code above if you have Neo4j running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ïù¥ ÌäúÌÜ†Î¶¨ÏñºÏóêÏÑú Ïö∞Î¶¨Îäî:\n",
    "\n",
    "### ‚úÖ Íµ¨ÌòÑÌïú Í∏∞Îä•\n",
    "\n",
    "1. **Knowledge Graph Íµ¨Ï∂ï**\n",
    "   - 8Í∞ú AI Ïó∞Íµ¨ ÎÖºÎ¨∏ÏóêÏÑú ÏóîÌã∞Ìã∞/Í¥ÄÍ≥Ñ Ï∂îÏ∂ú\n",
    "   - NetworkX Í∏∞Î∞ò Í∑∏ÎûòÌîÑ Íµ¨Ï∂ï\n",
    "   - Îã§ÏñëÌïú ÏøºÎ¶¨ ÏßÄÏõê\n",
    "\n",
    "2. **Î∂ÑÏÇ∞ ÏïÑÌÇ§ÌÖçÏ≤ò ÌôúÏö©**\n",
    "   - **Batch Processing**: 10Í∞ú Î≥ëÎ†¨ ÏõåÏª§Î°ú Î¨∏ÏÑú Ï≤òÎ¶¨\n",
    "   - **Caching**: Î∞òÎ≥µ ÏøºÎ¶¨Ïóê ÎåÄÌïú Ï¶âÍ∞ÅÏ†ÅÏù∏ ÏùëÎãµ (~10x speedup)\n",
    "   - **Rate Limiting**: API ÎπÑÏö© Ï†àÍ∞ê Î∞è ÏïàÏ†ïÏÑ±\n",
    "   - **Event Streaming**: Ïã§ÏãúÍ∞Ñ ÏßÑÌñâ ÏÉÅÌô© Î™®ÎãàÌÑ∞ÎßÅ\n",
    "\n",
    "3. **Model Router ÌôúÏö©**\n",
    "   - Complexity-based routingÏúºÎ°ú ÏµúÏ†Å Î™®Îç∏ ÏÑ†ÌÉù\n",
    "   - ÎπÑÏö©Í≥º ÌíàÏßàÏùò Í∑†Ìòï\n",
    "   - ÏûêÎèô fallback ÏßÄÏõê\n",
    "\n",
    "4. **Graph-based RAG**\n",
    "   - Entity-centric retrieval\n",
    "   - Path reasoning\n",
    "   - Hybrid search\n",
    "\n",
    "### üìä ÏÑ±Îä• Í∞úÏÑ†\n",
    "\n",
    "- **Ï≤òÎ¶¨ ÏÜçÎèÑ**: ~2 docs/sec (Î∞∞Ïπò Ï≤òÎ¶¨)\n",
    "- **Ï∫êÏãú Ìö®Í≥º**: 10x speedup for repeated queries\n",
    "- **ÎπÑÏö© ÏµúÏ†ÅÌôî**: Complexity-based model selection\n",
    "- **ÌôïÏû•ÏÑ±**: 10Í∞ú Î≥ëÎ†¨ ÏõåÏª§Î°ú ÎåÄÍ∑úÎ™® Ï≤òÎ¶¨ Í∞ÄÎä•\n",
    "\n",
    "### üéØ Ïã§Ï†Ñ ÌôúÏö©\n",
    "\n",
    "Ïù¥ Ìå®ÌÑ¥ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ïã§Ï†Ñ ÏãúÎÇòÎ¶¨Ïò§Ïóê Ï†ÅÏö© Í∞ÄÎä•Ìï©ÎãàÎã§:\n",
    "\n",
    "- **ÌïôÏà† Ïó∞Íµ¨ Î∂ÑÏÑù**: ÎÖºÎ¨∏ ÎÑ§Ìä∏ÏõåÌÅ¨, Ïù∏Ïö© Í¥ÄÍ≥Ñ, Ïó∞Íµ¨ ÎèôÌñ•\n",
    "- **ÎπÑÏ¶àÎãàÏä§ Ïù∏ÌÖîÎ¶¨Ï†ÑÏä§**: Í∏∞ÏóÖ Í¥ÄÍ≥Ñ, Ìà¨Ïûê ÎÑ§Ìä∏ÏõåÌÅ¨, M&A Î∂ÑÏÑù\n",
    "- **ÏùòÎ£å ÏßÄÏãù Í∑∏ÎûòÌîÑ**: ÏßàÎ≥ë-Ï¶ùÏÉÅ-ÏπòÎ£å Í¥ÄÍ≥Ñ, ÏïΩÎ¨º ÏÉÅÌò∏ÏûëÏö©\n",
    "- **Î≤ïÎ•† Î¨∏ÏÑú Î∂ÑÏÑù**: ÌåêÎ°Ä Í¥ÄÍ≥Ñ, Î≤ïÎ•† Ï°∞Ìï≠ Ïó∞Í≤∞\n",
    "\n",
    "### üöÄ Îã§Ïùå Îã®Í≥Ñ\n",
    "\n",
    "- Îçî ÎßéÏùÄ Î¨∏ÏÑú Ï≤òÎ¶¨ (100+)\n",
    "- Neo4j ÌÜµÌï©ÏúºÎ°ú ÏòÅÍµ¨ Ï†ÄÏû•\n",
    "- Ïã§ÏãúÍ∞Ñ Ïä§Ìä∏Î¶¨Î∞ç UI Íµ¨Ï∂ï\n",
    "- Ïª§Ïä§ÌÖÄ ÎùºÏö∞ÌåÖ Í∑úÏπô Ï∂îÍ∞Ä\n",
    "- Í∑∏ÎûòÌîÑ ÏãúÍ∞ÅÌôî Í∞úÏÑ†"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
