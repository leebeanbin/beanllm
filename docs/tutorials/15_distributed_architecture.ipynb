{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ Distributed Architecture - ë¶„ì‚° ì‹œìŠ¤í…œ êµ¬ì„±\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ beanllmì˜ ë¶„ì‚° ì•„í‚¤í…ì²˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. Redisì™€ Kafkaë¥¼ í™œìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“‹ ëª©ì°¨\n",
    "\n",
    "- [1. ë¶„ì‚° ì•„í‚¤í…ì²˜ ê¸°ë³¸](#1-ë¶„ì‚°-ì•„í‚¤í…ì²˜-ê¸°ë³¸)\n",
    "- [2. Redis í™œìš©](#2-redis-í™œìš©)\n",
    "- [3. Kafka í™œìš©](#3-kafka-í™œìš©)\n",
    "- [4. ë°ì½”ë ˆì´í„° íŒ¨í„´](#4-ë°ì½”ë ˆì´í„°-íŒ¨í„´)\n",
    "- [5. ë™ì  ì„¤ì •](#5-ë™ì -ì„¤ì •)\n",
    "- [6. ì‹¤ì „ ì˜ˆì œ](#6-ì‹¤ì „-ì˜ˆì œ)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ ì™„ë£Œí•˜ë©´:\n",
    "- âœ… ë¶„ì‚° ì•„í‚¤í…ì²˜ì˜ ê°œë…ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- âœ… Redisë¥¼ í™œìš©í•œ Rate Limitingê³¼ Cachingì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- âœ… Kafkaë¥¼ í™œìš©í•œ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- âœ… ë°ì½”ë ˆì´í„° íŒ¨í„´ìœ¼ë¡œ ë¶„ì‚° ê¸°ëŠ¥ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "- âœ… ë™ì ìœ¼ë¡œ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ì‚¬ì „ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "- [01_setup_and_installation.ipynb](01_setup_and_installation.ipynb) ì™„ë£Œ\n",
    "- [02_core_client.ipynb](02_core_client.ipynb) ì™„ë£Œ\n",
    "- Redis ë° Kafka ì„œë²„ ì‹¤í–‰ (ì„ íƒì )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¶„ì‚° ì•„í‚¤í…ì²˜ ê¸°ë³¸\n",
    "\n",
    "ë¶„ì‚° ì•„í‚¤í…ì²˜ëŠ” Redisì™€ Kafkaë¥¼ í™œìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "> ğŸ’¡ **ë¶„ì‚° ì•„í‚¤í…ì²˜ì˜ í•µì‹¬**:\n",
    "> - **Redis**: Rate Limiting, Caching, Distributed Locks, Short-term Queues\n",
    "> - **Kafka**: Event Streaming, Long-term Queues, Streaming Processing\n",
    "> - **Fallback**: ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¸ë©”ëª¨ë¦¬ë¡œ ì „í™˜\n",
    "> - **ë°ì½”ë ˆì´í„° íŒ¨í„´**: ì½”ë“œ ë³€ê²½ ì—†ì´ ë¶„ì‚° ê¸°ëŠ¥ ì ìš©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ë¶„ì‚° ì•„í‚¤í…ì²˜ í™œì„±í™”\n",
    "os.environ[\"USE_DISTRIBUTED\"] = \"true\"\n",
    "os.environ[\"REDIS_HOST\"] = \"localhost\"\n",
    "os.environ[\"REDIS_PORT\"] = \"6379\"\n",
    "os.environ[\"KAFKA_BOOTSTRAP_SERVERS\"] = \"localhost:9092\"\n",
    "\n",
    "from beanllm.infrastructure.distributed import (\n",
    "    check_redis_health,\n",
    "    check_kafka_health,\n",
    ")\n",
    "\n",
    "# ê±´ê°• ìƒíƒœ í™•ì¸\n",
    "redis_ok = check_redis_health()\n",
    "kafka_ok = check_kafka_health()\n",
    "\n",
    "print(\"âœ… ë¶„ì‚° ì•„í‚¤í…ì²˜ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š Redis ìƒíƒœ: {'âœ… ì—°ê²°ë¨' if redis_ok else 'âŒ ì—°ê²° ì‹¤íŒ¨'}\")\n",
    "print(f\"ğŸ“Š Kafka ìƒíƒœ: {'âœ… ì—°ê²°ë¨' if kafka_ok else 'âŒ ì—°ê²° ì‹¤íŒ¨'}\")\n",
    "\n",
    "if not redis_ok or not kafka_ok:\n",
    "    print(\"\\nğŸ’¡ Fallback ëª¨ë“œ:\")\n",
    "    print(\"  - ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¸ë©”ëª¨ë¦¬ë¡œ ì „í™˜\")\n",
    "    print(\"  - ê¸°ëŠ¥ì€ ì •ìƒ ì‘ë™í•˜ì§€ë§Œ ë¶„ì‚° ê¸°ëŠ¥ì€ ë¹„í™œì„±í™”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Redis í™œìš©\n",
    "\n",
    "RedisëŠ” Rate Limiting, Caching, Distributed Locksì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "### 2.1 Rate Limiting\n",
    "\n",
    "ìš”ì²­ ì†ë„ë¥¼ ì œí•œí•˜ì—¬ API ë¹„ìš©ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import get_rate_limiter\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "# Rate Limiter ê°€ì ¸ì˜¤ê¸°\n",
    "rate_limiter = get_rate_limiter()\n",
    "\n",
    "\n",
    "# Rate Limit í™•ì¸\n",
    "async def check_rate_limit():\n",
    "    key = \"user:123\"\n",
    "    limit = 5  # 5ì´ˆë‹¹ 5ê°œ ìš”ì²­\n",
    "\n",
    "    print(\"ğŸ” Rate Limiting í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "    for i in range(10):\n",
    "        allowed = await rate_limiter.is_allowed(key, limit, window=5.0)\n",
    "\n",
    "        if allowed:\n",
    "            print(f\"âœ… ìš”ì²­ {i+1}: í—ˆìš©ë¨\")\n",
    "            # ì‹¤ì œ ìš”ì²­ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "            await asyncio.sleep(0.5)\n",
    "        else:\n",
    "            print(f\"âŒ ìš”ì²­ {i+1}: Rate Limit ì´ˆê³¼ - ìš”ì²­ ê±°ë¶€\")\n",
    "            # ëŒ€ê¸° ì‹œê°„ ê³„ì‚°\n",
    "            wait_time = await rate_limiter.get_wait_time(key, limit, window=5.0)\n",
    "            print(f\"   â³ ëŒ€ê¸° ì‹œê°„: {wait_time:.2f}ì´ˆ\")\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await check_rate_limit()\n",
    "\n",
    "print(\"\\nğŸ’¡ Rate Limitingì˜ ì¥ì :\")\n",
    "print(\"  - API ë¹„ìš© ê´€ë¦¬ (OpenAI, Anthropic ë“±)\")\n",
    "print(\"  - ì„œë²„ ë¶€í•˜ ë°©ì§€\")\n",
    "print(\"  - ê³µì •í•œ ë¦¬ì†ŒìŠ¤ ë¶„ë°°\")\n",
    "print(\"  - DDoS ê³µê²© ë°©ì–´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Caching\n",
    "\n",
    "ìì£¼ ì‚¬ìš©ë˜ëŠ” ê²°ê³¼ë¥¼ ìºì‹±í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import get_cache\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "# Cache ê°€ì ¸ì˜¤ê¸°\n",
    "cache = get_cache()\n",
    "\n",
    "\n",
    "async def use_cache_example():\n",
    "    \"\"\"ìºì‹±ì„ ì‚¬ìš©í•œ ì¿¼ë¦¬ ì²˜ë¦¬\"\"\"\n",
    "\n",
    "    print(\"ğŸ” Caching í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "    query = \"Pythonì´ë€?\"\n",
    "    key = f\"rag:query:{hashlib.md5(query.encode()).hexdigest()}\"\n",
    "\n",
    "    # ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)\n",
    "    print(\"ğŸ“ ì²« ë²ˆì§¸ ìš”ì²­:\")\n",
    "    start = time.time()\n",
    "\n",
    "    cached = await cache.get(key)\n",
    "    if cached:\n",
    "        print(f\"âœ… ìºì‹œ íˆíŠ¸: {cached}\")\n",
    "    else:\n",
    "        print(\"âŒ ìºì‹œ ë¯¸ìŠ¤ - ì‹¤ì œ ì²˜ë¦¬ ìˆ˜í–‰\")\n",
    "        # ì‹¤ì œ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (1ì´ˆ ì†Œìš”)\n",
    "        await asyncio.sleep(1.0)\n",
    "        result = \"Pythonì€ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "        # ìºì‹œ ì €ì¥ (TTL: 3600ì´ˆ)\n",
    "        await cache.set(key, result, ttl=3600)\n",
    "        print(f\"âœ… ìºì‹œ ì €ì¥: {key[:32]}...\")\n",
    "        print(f\"ğŸ“ ê²°ê³¼: {result[:50]}...\")\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed:.3f}ì´ˆ\\n\")\n",
    "\n",
    "    # ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ íˆíŠ¸)\n",
    "    print(\"ğŸ“ ë‘ ë²ˆì§¸ ìš”ì²­ (ë™ì¼ ì¿¼ë¦¬):\")\n",
    "    start = time.time()\n",
    "\n",
    "    cached = await cache.get(key)\n",
    "    if cached:\n",
    "        print(f\"âœ… ìºì‹œ íˆíŠ¸!\")\n",
    "        print(f\"ğŸ“ ê²°ê³¼: {cached[:50]}...\")\n",
    "    else:\n",
    "        print(\"âŒ ìºì‹œ ë¯¸ìŠ¤\")\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed:.3f}ì´ˆ\")\n",
    "\n",
    "    # ì„±ëŠ¥ ê°œì„  ê³„ì‚°\n",
    "    improvement = (1.0 - elapsed) / 1.0 * 100\n",
    "    print(f\"\\nğŸ“Š ì„±ëŠ¥ ê°œì„ : {improvement:.1f}% ë¹ ë¦„\")\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await use_cache_example()\n",
    "\n",
    "print(\"\\nğŸ’¡ Cachingì˜ ì¥ì :\")\n",
    "print(\"  - ì‘ë‹µ ì‹œê°„ ë‹¨ì¶• (ìˆ˜ ì´ˆ â†’ ë°€ë¦¬ì´ˆ)\")\n",
    "print(\"  - API ë¹„ìš© ì ˆê° (ë™ì¼ ì¿¼ë¦¬ ì¬ì‚¬ìš©)\")\n",
    "print(\"  - ì„œë²„ ë¶€í•˜ ê°ì†Œ\")\n",
    "print(\"  - ì‚¬ìš©ì ê²½í—˜ ê°œì„ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kafka í™œìš©\n",
    "\n",
    "KafkaëŠ” ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì¥ê¸° ì‘ì—… íì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "### 3.1 ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°\n",
    "\n",
    "ëª¨ë“  ìš”ì²­ê³¼ ë™ì‘ì„ ì´ë²¤íŠ¸ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import get_event_logger\n",
    "import json\n",
    "\n",
    "# Event Logger ê°€ì ¸ì˜¤ê¸°\n",
    "event_logger = get_event_logger()\n",
    "\n",
    "\n",
    "async def log_event_example():\n",
    "    \"\"\"ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì œ\"\"\"\n",
    "\n",
    "    print(\"ğŸ” Event Streaming í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "    # ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ ë°œí–‰\n",
    "    events = [\n",
    "        {\n",
    "            \"event_type\": \"llm.request\",\n",
    "            \"data\": {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"user_id\": \"user123\",\n",
    "                \"tokens\": 150,\n",
    "                \"cost\": 0.005,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"event_type\": \"rag.query\",\n",
    "            \"data\": {\n",
    "                \"query\": \"Pythonì´ë€?\",\n",
    "                \"user_id\": \"user123\",\n",
    "                \"top_k\": 5,\n",
    "                \"latency\": 0.234,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"event_type\": \"rag.retrieve\",\n",
    "            \"data\": {\n",
    "                \"query\": \"Pythonì´ë€?\",\n",
    "                \"num_docs\": 5,\n",
    "                \"latency\": 0.123,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"event_type\": \"llm.response\",\n",
    "            \"data\": {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"user_id\": \"user123\",\n",
    "                \"tokens\": 320,\n",
    "                \"latency\": 1.456,\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for event in events:\n",
    "        await event_logger.log_event(event_type=event[\"event_type\"], data=event[\"data\"])\n",
    "        print(f\"âœ… ì´ë²¤íŠ¸ ë°œí–‰: {event['event_type']}\")\n",
    "        print(f\"   ğŸ“ ë°ì´í„°: {json.dumps(event['data'], indent=6, ensure_ascii=False)}\")\n",
    "        print()\n",
    "\n",
    "    print(\"âœ… ëª¨ë“  ì´ë²¤íŠ¸ ë°œí–‰ ì™„ë£Œ!\\n\")\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await log_event_example()\n",
    "\n",
    "print(\"ğŸ’¡ Event Streamingì˜ í™œìš©:\")\n",
    "print(\"  - ëª¨ë“  ìš”ì²­ ì¶”ì  (ê°ì‚¬ ë¡œê·¸)\")\n",
    "print(\"  - ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§ (ëŒ€ì‹œë³´ë“œ)\")\n",
    "print(\"  - ì‹¤ì‹œê°„ ì•Œë¦¼ (ì´ìƒ ê°ì§€)\")\n",
    "print(\"  - ë°ì´í„° ë¶„ì„ (ì‚¬ìš© íŒ¨í„´)\")\n",
    "print(\"  - ë””ë²„ê¹… (ë¬¸ì œ ì¶”ì )\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Kafkaì˜ ì¥ì :\")\n",
    "print(\"  - ì˜êµ¬ ì €ì¥ (ë°ì´í„° ì†ì‹¤ ì—†ìŒ)\")\n",
    "print(\"  - ë†’ì€ ì²˜ë¦¬ëŸ‰ (ì´ˆë‹¹ ìˆ˜ë°±ë§Œ ë©”ì‹œì§€)\")\n",
    "print(\"  - í™•ì¥ ê°€ëŠ¥ (ìˆ˜í‰ í™•ì¥)\")\n",
    "print(\"  - ë‚´êµ¬ì„± (ë³µì œ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ì‘ì—… í\n",
    "\n",
    "ì¥ê¸° ì‘ì—…ì„ íì— ë„£ì–´ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import get_task_queue\n",
    "import uuid\n",
    "\n",
    "# Task Queue ê°€ì ¸ì˜¤ê¸°\n",
    "task_queue = get_task_queue()\n",
    "\n",
    "\n",
    "async def queue_task_example():\n",
    "    \"\"\"ì‘ì—… í ì˜ˆì œ\"\"\"\n",
    "\n",
    "    print(\"ğŸ” Task Queue í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "    # ë‹¤ì–‘í•œ ì‘ì—…ì„ íì— ì¶”ê°€\n",
    "    tasks = [\n",
    "        {\n",
    "            \"task_type\": \"process_document\",\n",
    "            \"payload\": {\"file_path\": \"document1.pdf\", \"user_id\": \"user123\"},\n",
    "            \"priority\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"task_type\": \"process_document\",\n",
    "            \"payload\": {\"file_path\": \"document2.pdf\", \"user_id\": \"user123\"},\n",
    "            \"priority\": \"medium\",\n",
    "        },\n",
    "        {\n",
    "            \"task_type\": \"generate_summary\",\n",
    "            \"payload\": {\"doc_id\": \"doc123\", \"max_length\": 500},\n",
    "            \"priority\": \"low\",\n",
    "        },\n",
    "        {\n",
    "            \"task_type\": \"build_knowledge_graph\",\n",
    "            \"payload\": {\"doc_ids\": [\"doc1\", \"doc2\", \"doc3\"]},\n",
    "            \"priority\": \"high\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    task_ids = []\n",
    "    for task in tasks:\n",
    "        task_id = await task_queue.enqueue(\n",
    "            task_type=task[\"task_type\"], payload=task[\"payload\"], priority=task[\"priority\"]\n",
    "        )\n",
    "        task_ids.append(task_id)\n",
    "        print(f\"âœ… ì‘ì—… íì— ì¶”ê°€:\")\n",
    "        print(f\"   ğŸ“ ID: {task_id}\")\n",
    "        print(f\"   ğŸ·ï¸  íƒ€ì…: {task['task_type']}\")\n",
    "        print(f\"   âš¡ ìš°ì„ ìˆœìœ„: {task['priority']}\")\n",
    "        print()\n",
    "\n",
    "    print(f\"âœ… ì´ {len(task_ids)}ê°œ ì‘ì—… íì— ì¶”ê°€ ì™„ë£Œ!\\n\")\n",
    "\n",
    "    # ì‘ì—… ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ë³„ë„ ì›Œì»¤ì—ì„œ)\n",
    "    print(\"ğŸ”„ ì‘ì—… ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜:\\n\")\n",
    "\n",
    "    for i in range(2):\n",
    "        # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ì‘ì—…ë¶€í„° ì²˜ë¦¬\n",
    "        task = await task_queue.dequeue(\"process_document\")\n",
    "        if task:\n",
    "            print(f\"âš™ï¸  ì‘ì—… ì²˜ë¦¬ ì¤‘: {task.id}\")\n",
    "            print(f\"   ğŸ“ íƒ€ì…: {task.task_type}\")\n",
    "            print(f\"   ğŸ’¾ í˜ì´ë¡œë“œ: {task.payload}\")\n",
    "\n",
    "            # ì‘ì—… ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "            await asyncio.sleep(0.5)\n",
    "\n",
    "            # ì‘ì—… ì™„ë£Œ\n",
    "            await task_queue.complete(task.id)\n",
    "            print(f\"âœ… ì‘ì—… ì™„ë£Œ: {task.id}\\n\")\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await queue_task_example()\n",
    "\n",
    "print(\"ğŸ’¡ Task Queueì˜ í™œìš©:\")\n",
    "print(\"  - ì¥ê¸° ì‘ì—… ë¹„ë™ê¸° ì²˜ë¦¬\")\n",
    "print(\"  - ì‘ì—… ìš°ì„ ìˆœìœ„ ê´€ë¦¬\")\n",
    "print(\"  - ì‘ì—… ì¬ì‹œë„ (ì‹¤íŒ¨ ì‹œ)\")\n",
    "print(\"  - ì‘ì—… ìƒíƒœ ì¶”ì \")\n",
    "print(\"  - ì›Œì»¤ ìŠ¤ì¼€ì¼ë§\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì‚¬ìš© ì‚¬ë¡€:\")\n",
    "print(\"  - ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬\")\n",
    "print(\"  - ë°°ì¹˜ ì„ë² ë”© ìƒì„±\")\n",
    "print(\"  - Knowledge Graph êµ¬ì¶•\")\n",
    "print(\"  - ì •ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ë§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë°ì½”ë ˆì´í„° íŒ¨í„´\n",
    "\n",
    "ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ë³€ê²½ ì—†ì´ ë¶„ì‚° ê¸°ëŠ¥ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed.pipeline_decorators import (\n",
    "    with_distributed_features,\n",
    ")\n",
    "\n",
    "\n",
    "# ë°ì½”ë ˆì´í„°ë¡œ ë¶„ì‚° ê¸°ëŠ¥ ì ìš©\n",
    "@with_distributed_features(\n",
    "    pipeline_type=\"rag\",\n",
    "    enable_cache=True,\n",
    "    enable_rate_limiting=True,\n",
    "    enable_event_streaming=True,\n",
    "    cache_key_prefix=\"rag:query\",\n",
    "    rate_limit_key=\"rag:search\",\n",
    "    event_type=\"rag.query\",\n",
    ")\n",
    "async def rag_query(query: str) -> str:\n",
    "    \"\"\"RAG ì¿¼ë¦¬ (ë¶„ì‚° ê¸°ëŠ¥ ìë™ ì ìš©)\"\"\"\n",
    "    # ì‹¤ì œ ë¡œì§ë§Œ ì‘ì„±\n",
    "    # ë¶„ì‚° ê¸°ëŠ¥ì€ ë°ì½”ë ˆì´í„°ê°€ ìë™ ì²˜ë¦¬:\n",
    "    #   1. Rate Limiting í™•ì¸\n",
    "    #   2. ìºì‹œ í™•ì¸\n",
    "    #   3. ì‹¤ì œ ì²˜ë¦¬ (ìºì‹œ ë¯¸ìŠ¤ ì‹œ)\n",
    "    #   4. ìºì‹œ ì €ì¥\n",
    "    #   5. ì´ë²¤íŠ¸ ë°œí–‰\n",
    "\n",
    "    # ì‹¤ì œ RAG ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "    print(f\"ğŸ” ì¿¼ë¦¬ ì²˜ë¦¬: {query}\")\n",
    "    await asyncio.sleep(0.5)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "\n",
    "    return f\"ë‹µë³€: {query}ì— ëŒ€í•œ ìƒì„¸í•œ ë‹µë³€ì…ë‹ˆë‹¤. Pythonì€ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ...\"\n",
    "\n",
    "\n",
    "print(\"âœ… ë°ì½”ë ˆì´í„° íŒ¨í„´ ì ìš© ì™„ë£Œ!\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ ë°ì½”ë ˆì´í„°ì˜ ì¥ì :\")\n",
    "print(\"  - ì½”ë“œ ë³€ê²½ ìµœì†Œí™” (3-5ì¤„ë§Œ ì‘ì„±)\")\n",
    "print(\"  - ì¤‘ë³µ ì½”ë“œ ì œê±° (85-90% ê°ì†Œ)\")\n",
    "print(\"  - ì¼ê´€ëœ ë¶„ì‚° ê¸°ëŠ¥ ì ìš©\")\n",
    "print(\"  - ìœ ì§€ë³´ìˆ˜ ìš©ì´\")\n",
    "print(\"  - í…ŒìŠ¤íŠ¸ ìš©ì´\\n\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì œ\n",
    "print(\"ğŸ”„ ì‹¤í–‰ ì˜ˆì œ:\\n\")\n",
    "\n",
    "for i in range(3):\n",
    "    result = await rag_query(\"Pythonì´ë€?\")\n",
    "    print(f\"ğŸ“ ê²°ê³¼ {i+1}: {result[:50]}...\\n\")\n",
    "    await asyncio.sleep(0.2)\n",
    "\n",
    "print(\"ğŸ’¡ ìë™ ì ìš©ëœ ê¸°ëŠ¥:\")\n",
    "print(\"  âœ… Rate Limiting: ìš”ì²­ ì†ë„ ì œí•œ\")\n",
    "print(\"  âœ… Caching: ì²« ë²ˆì§¸ ìš”ì²­ í›„ ìºì‹œì—ì„œ ë°˜í™˜\")\n",
    "print(\"  âœ… Event Streaming: ëª¨ë“  ìš”ì²­ ì´ë²¤íŠ¸ ë°œí–‰\")\n",
    "print(\"  âœ… Fallback: ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ì‹¤íŒ¨ ì‹œ ì¸ë©”ëª¨ë¦¬ë¡œ ì „í™˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë™ì  ì„¤ì •\n",
    "\n",
    "ëŸ°íƒ€ì„ì— ë¶„ì‚° ê¸°ëŠ¥ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import (\n",
    "    update_pipeline_config,\n",
    "    get_pipeline_config,\n",
    "    reset_pipeline_config,\n",
    ")\n",
    "import json\n",
    "\n",
    "print(\"ğŸ” ë™ì  ì„¤ì • ë³€ê²½ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "# 1. ì´ˆê¸° ì„¤ì • í™•ì¸\n",
    "print(\"ğŸ“Š ì´ˆê¸° ì„¤ì •:\")\n",
    "config = get_pipeline_config(\"rag\")\n",
    "print(json.dumps(config, indent=2, ensure_ascii=False))\n",
    "print()\n",
    "\n",
    "# 2. Rate Limiting ë¹„í™œì„±í™”\n",
    "print(\"ğŸ”§ Rate Limiting ë¹„í™œì„±í™”:\")\n",
    "update_pipeline_config(\n",
    "    pipeline_type=\"rag\",\n",
    "    enable_rate_limiting=False,  # Rate Limiting ë¹„í™œì„±í™”\n",
    ")\n",
    "config = get_pipeline_config(\"rag\")\n",
    "print(f\"  enable_rate_limiting: {config['enable_rate_limiting']}\")\n",
    "print()\n",
    "\n",
    "# 3. ìºì‹œ TTL ë³€ê²½\n",
    "print(\"ğŸ”§ ìºì‹œ TTL ë³€ê²½ (3600 â†’ 7200ì´ˆ):\")\n",
    "update_pipeline_config(\n",
    "    pipeline_type=\"rag\",\n",
    "    rag_cache_ttl=7200,  # 2ì‹œê°„ìœ¼ë¡œ ë³€ê²½\n",
    ")\n",
    "config = get_pipeline_config(\"rag\")\n",
    "print(f\"  rag_cache_ttl: {config['rag_cache_ttl']}ì´ˆ\")\n",
    "print()\n",
    "\n",
    "# 4. ì—¬ëŸ¬ ì„¤ì • ë™ì‹œ ë³€ê²½\n",
    "print(\"ğŸ”§ ì—¬ëŸ¬ ì„¤ì • ë™ì‹œ ë³€ê²½:\")\n",
    "update_pipeline_config(\n",
    "    pipeline_type=\"rag\",\n",
    "    enable_rate_limiting=True,\n",
    "    enable_cache=True,\n",
    "    enable_event_streaming=True,\n",
    "    rag_cache_ttl=3600,\n",
    ")\n",
    "config = get_pipeline_config(\"rag\")\n",
    "print(f\"  enable_rate_limiting: {config['enable_rate_limiting']}\")\n",
    "print(f\"  enable_cache: {config['enable_cache']}\")\n",
    "print(f\"  enable_event_streaming: {config['enable_event_streaming']}\")\n",
    "print(f\"  rag_cache_ttl: {config['rag_cache_ttl']}ì´ˆ\")\n",
    "print()\n",
    "\n",
    "# 5. ì„¤ì • ì´ˆê¸°í™”\n",
    "print(\"ğŸ”§ ì„¤ì • ì´ˆê¸°í™”:\")\n",
    "reset_pipeline_config(\"rag\")\n",
    "config = get_pipeline_config(\"rag\")\n",
    "print(f\"  ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "print(\"âœ… ë™ì  ì„¤ì • ë³€ê²½ ì™„ë£Œ!\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ ë™ì  ì„¤ì •ì˜ í™œìš©:\")\n",
    "print(\"  - ì¬ì‹œì‘ ì—†ì´ ì„¤ì • ë³€ê²½\")\n",
    "print(\"  - A/B í…ŒìŠ¤íŠ¸ (ì‚¬ìš©ì ê·¸ë£¹ë³„ ì„¤ì •)\")\n",
    "print(\"  - ì‹¤ì‹œê°„ ìµœì í™” (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ë°˜)\")\n",
    "print(\"  - ê¸´ê¸‰ ëŒ€ì‘ (ë¬¸ì œ ë°œìƒ ì‹œ ë¹ ë¥¸ ë¹„í™œì„±í™”)\")\n",
    "print(\"  - ë¹„ìš© ì ˆê° (í”¼í¬ ì‹œê°„ Rate Limit ì¡°ì •)\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì‚¬ìš© ì‚¬ë¡€:\")\n",
    "print(\"  - íŠ¸ë˜í”½ ê¸‰ì¦ ì‹œ Rate Limit ê°•í™”\")\n",
    "print(\"  - ìºì‹œ ë¯¸ìŠ¤ìœ¨ ë†’ì„ ë•Œ TTL ì¦ê°€\")\n",
    "print(\"  - ë””ë²„ê¹… ì‹œ Event Streaming í™œì„±í™”\")\n",
    "print(\"  - ë¹„ìš© ì ˆê° ëª¨ë“œ (ìºì‹± ê°•í™”)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‹¤ì „ ì˜ˆì œ\n",
    "\n",
    "### 6.1 ë¶„ì‚° RAG ì‹œìŠ¤í…œ\n",
    "\n",
    "ë¶„ì‚° ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed.pipeline_decorators import (\n",
    "    with_distributed_features,\n",
    ")\n",
    "import time\n",
    "\n",
    "\n",
    "# ë¶„ì‚° ê¸°ëŠ¥ì´ ì ìš©ëœ RAG\n",
    "@with_distributed_features(\n",
    "    pipeline_type=\"rag\",\n",
    "    enable_cache=True,\n",
    "    enable_rate_limiting=True,\n",
    "    enable_event_streaming=True,\n",
    "    cache_key_prefix=\"rag:query\",\n",
    "    rate_limit_key=\"rag:search\",\n",
    "    event_type=\"rag.query\",\n",
    ")\n",
    "async def distributed_rag_query(query: str, top_k: int = 5) -> dict:\n",
    "    \"\"\"ë¶„ì‚° RAG ì‹œìŠ¤í…œ\"\"\"\n",
    "\n",
    "    # ì‹¤ì œ RAG ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "    await asyncio.sleep(0.8)  # ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜\n",
    "\n",
    "    # ê²°ê³¼ ë°˜í™˜\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"top_k\": top_k,\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"content\": f\"Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "                \"score\": 0.95,\n",
    "                \"source\": \"python_intro.pdf\",\n",
    "            },\n",
    "            {\n",
    "                \"content\": f\"Pythonì€ ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.\",\n",
    "                \"score\": 0.89,\n",
    "                \"source\": \"python_features.pdf\",\n",
    "            },\n",
    "            {\n",
    "                \"content\": f\"Pythonì€ ë°ì´í„° ê³¼í•™, ì›¹ ê°œë°œ, ìë™í™” ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.\",\n",
    "                \"score\": 0.85,\n",
    "                \"source\": \"python_applications.pdf\",\n",
    "            },\n",
    "        ],\n",
    "        \"answer\": \"Pythonì€ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, ê°„ê²°í•œ ë¬¸ë²•ê³¼ ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\",\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"ğŸ” ë¶„ì‚° RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì¿¼ë¦¬ (ìºì‹œ ë¯¸ìŠ¤)\n",
    "print(\"ğŸ“ ì²« ë²ˆì§¸ ì¿¼ë¦¬:\")\n",
    "start = time.time()\n",
    "result1 = await distributed_rag_query(\"Pythonì´ë€?\")\n",
    "elapsed1 = time.time() - start\n",
    "print(f\"âœ… ì™„ë£Œ!\")\n",
    "print(f\"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed1:.3f}ì´ˆ\")\n",
    "print(f\"   ğŸ“Š ê²°ê³¼ ìˆ˜: {len(result1['results'])}\")\n",
    "print(f\"   ğŸ’¬ ë‹µë³€: {result1['answer'][:50]}...\")\n",
    "print()\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì¿¼ë¦¬ (ìºì‹œ íˆíŠ¸)\n",
    "print(\"ğŸ“ ë‘ ë²ˆì§¸ ì¿¼ë¦¬ (ë™ì¼):\")\n",
    "start = time.time()\n",
    "result2 = await distributed_rag_query(\"Pythonì´ë€?\")\n",
    "elapsed2 = time.time() - start\n",
    "print(f\"âœ… ì™„ë£Œ!\")\n",
    "print(f\"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed2:.3f}ì´ˆ (ìºì‹œ íˆíŠ¸)\")\n",
    "print(f\"   ğŸ“Š ê²°ê³¼ ìˆ˜: {len(result2['results'])}\")\n",
    "print()\n",
    "\n",
    "# ì„±ëŠ¥ ê°œì„  ê³„ì‚°\n",
    "improvement = (elapsed1 - elapsed2) / elapsed1 * 100\n",
    "print(f\"ğŸ“Š ì„±ëŠ¥ ê°œì„ : {improvement:.1f}% ë¹ ë¦„\\n\")\n",
    "\n",
    "print(\"âœ… ë¶„ì‚° RAG ì‹œìŠ¤í…œ ì™„ë£Œ!\\n\")\n",
    "\n",
    "print(\"ğŸ’¡ ìë™ ì ìš©ë˜ëŠ” ê¸°ëŠ¥:\")\n",
    "print(\"  âœ… Caching: ë™ì¼ ì¿¼ë¦¬ ì¬ì‚¬ìš© â†’ ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•\")\n",
    "print(\"  âœ… Rate Limiting: API ë¹„ìš© ê´€ë¦¬ â†’ ë¹„ìš© ì ˆê°\")\n",
    "print(\"  âœ… Event Streaming: ëª¨ë“  ìš”ì²­ ì¶”ì  â†’ ë¶„ì„ & ëª¨ë‹ˆí„°ë§\")\n",
    "print(\"  âœ… Distributed Locks: ë™ì‹œì„± ì œì–´ â†’ ë°ì´í„° ì¼ê´€ì„±\")\n",
    "print(\"  âœ… Fallback: ì‹¤íŒ¨ ì‹œ ìë™ ì „í™˜ â†’ ì•ˆì •ì„±\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì‹¤ì „ í™œìš©:\")\n",
    "print(\"  - ê³ ê° ì§€ì› ì±—ë´‡ (ìºì‹±ìœ¼ë¡œ ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•)\")\n",
    "print(\"  - ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ (Rate Limitingìœ¼ë¡œ ë¹„ìš© ê´€ë¦¬)\")\n",
    "print(\"  - ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Event Streamingìœ¼ë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¸ ì‹œê°í™” ì˜ˆì œ\n",
    "\n",
    "### ë¶„ì‚° ì•„í‚¤í…ì²˜ êµ¬ì¡°\n",
    "\n",
    "> ğŸ’¡ **ì´ë¯¸ì§€ í•„ìš”**: ë¶„ì‚° ì•„í‚¤í…ì²˜ì˜ êµ¬ì¡°ë¥¼ ë³´ì—¬ì£¼ëŠ” ë‹¤ì´ì–´ê·¸ë¨\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆì´ì–´\n",
    "app_rect = mpatches.Rectangle((5, 6), 4, 1, facecolor='lightblue', edgecolor='black')\n",
    "ax.add_patch(app_rect)\n",
    "ax.text(7, 6.5, 'Application Layer', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Redis\n",
    "redis_rect = mpatches.Rectangle((1, 3), 2, 1, facecolor='lightcoral', edgecolor='black')\n",
    "ax.add_patch(redis_rect)\n",
    "ax.text(2, 3.5, 'Redis', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "ax.text(2, 3.2, 'Rate Limiting\\nCaching\\nLocks', ha='center', va='top', fontsize=8)\n",
    "\n",
    "# Kafka\n",
    "kafka_rect = mpatches.Rectangle((7, 3), 2, 1, facecolor='lightgreen', edgecolor='black')\n",
    "ax.add_patch(kafka_rect)\n",
    "ax.text(8, 3.5, 'Kafka', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "ax.text(8, 3.2, 'Event Streaming\\nTask Queue', ha='center', va='top', fontsize=8)\n",
    "\n",
    "# ì—°ê²°ì„ \n",
    "ax.arrow(6, 6, -3, -2.5, head_width=0.2, head_length=0.2, fc='black', ec='black')\n",
    "ax.arrow(8, 6, -1, -2.5, head_width=0.2, head_length=0.2, fc='black', ec='black')\n",
    "\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(2, 7)\n",
    "ax.axis('off')\n",
    "plt.title('ë¶„ì‚° ì•„í‚¤í…ì²˜ êµ¬ì¡°', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**í•„ìš”í•œ ì´ë¯¸ì§€**:\n",
    "- ë‹¤ì´ì–´ê·¸ë¨: Application Layerê°€ ìƒë‹¨ì— ìˆê³ , Redisì™€ Kafkaê°€ í•˜ë‹¨ì— ë°°ì¹˜\n",
    "- Applicationì—ì„œ Redisì™€ Kafkaë¡œ í™”ì‚´í‘œ ì—°ê²°\n",
    "- ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í•  í‘œì‹œ\n",
    "- ë©”ì‹œì§€ íë¦„ ë‹¤ì´ì–´ê·¸ë¨ (ì„ íƒì )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import (\n",
    "    get_cache_stats,\n",
    "    get_rate_limiter_stats,\n",
    "    get_event_logger_stats,\n",
    "    get_task_queue_stats,\n",
    ")\n",
    "\n",
    "\n",
    "async def monitoring_example():\n",
    "    \"\"\"ë¶„ì‚° ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ\"\"\"\n",
    "\n",
    "    print(\"ğŸ” ë¶„ì‚° ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§:\\n\")\n",
    "\n",
    "    # 1. ìºì‹œ í†µê³„\n",
    "    print(\"ğŸ“Š ìºì‹œ í†µê³„:\")\n",
    "    cache_stats = await get_cache_stats()\n",
    "    print(f\"  ì´ í‚¤ ìˆ˜: {cache_stats.get('total_keys', 0):,}\")\n",
    "    print(f\"  ìºì‹œ íˆíŠ¸: {cache_stats.get('hits', 0):,}\")\n",
    "    print(f\"  ìºì‹œ ë¯¸ìŠ¤: {cache_stats.get('misses', 0):,}\")\n",
    "\n",
    "    hit_rate = (\n",
    "        cache_stats.get(\"hits\", 0) / (cache_stats.get(\"hits\", 0) + cache_stats.get(\"misses\", 1))\n",
    "        if cache_stats.get(\"hits\", 0) + cache_stats.get(\"misses\", 0) > 0\n",
    "        else 0\n",
    "    )\n",
    "    print(f\"  íˆíŠ¸ìœ¨: {hit_rate * 100:.1f}%\")\n",
    "    print(f\"  ë©”ëª¨ë¦¬ ì‚¬ìš©: {cache_stats.get('memory_usage', 0) / 1024 / 1024:.1f} MB\")\n",
    "    print()\n",
    "\n",
    "    # 2. Rate Limiter í†µê³„\n",
    "    print(\"ğŸ“Š Rate Limiter í†µê³„:\")\n",
    "    rate_limiter_stats = await get_rate_limiter_stats()\n",
    "    print(f\"  ì´ ìš”ì²­: {rate_limiter_stats.get('total_requests', 0):,}\")\n",
    "    print(f\"  í—ˆìš©: {rate_limiter_stats.get('allowed', 0):,}\")\n",
    "    print(f\"  ê±°ë¶€: {rate_limiter_stats.get('rejected', 0):,}\")\n",
    "\n",
    "    rejection_rate = (\n",
    "        rate_limiter_stats.get(\"rejected\", 0) / rate_limiter_stats.get(\"total_requests\", 1)\n",
    "        if rate_limiter_stats.get(\"total_requests\", 0) > 0\n",
    "        else 0\n",
    "    )\n",
    "    print(f\"  ê±°ë¶€ìœ¨: {rejection_rate * 100:.1f}%\")\n",
    "    print()\n",
    "\n",
    "    # 3. Event Logger í†µê³„\n",
    "    print(\"ğŸ“Š Event Logger í†µê³„:\")\n",
    "    event_stats = await get_event_logger_stats()\n",
    "    print(f\"  ì´ ì´ë²¤íŠ¸: {event_stats.get('total_events', 0):,}\")\n",
    "    print(f\"  ì„±ê³µ: {event_stats.get('success', 0):,}\")\n",
    "    print(f\"  ì‹¤íŒ¨: {event_stats.get('failed', 0):,}\")\n",
    "    print()\n",
    "\n",
    "    if event_stats.get(\"by_type\"):\n",
    "        print(\"  ì´ë²¤íŠ¸ íƒ€ì…ë³„:\")\n",
    "        for event_type, count in event_stats.get(\"by_type\", {}).items():\n",
    "            print(f\"    - {event_type}: {count:,}\")\n",
    "        print()\n",
    "\n",
    "    # 4. Task Queue í†µê³„\n",
    "    print(\"ğŸ“Š Task Queue í†µê³„:\")\n",
    "    queue_stats = await get_task_queue_stats()\n",
    "    print(f\"  ëŒ€ê¸° ì¤‘: {queue_stats.get('pending', 0):,}\")\n",
    "    print(f\"  ì²˜ë¦¬ ì¤‘: {queue_stats.get('processing', 0):,}\")\n",
    "    print(f\"  ì™„ë£Œ: {queue_stats.get('completed', 0):,}\")\n",
    "    print(f\"  ì‹¤íŒ¨: {queue_stats.get('failed', 0):,}\")\n",
    "    print()\n",
    "\n",
    "    # 5. ì „ì²´ ìƒíƒœ ìš”ì•½\n",
    "    print(\"ğŸ“Š ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
    "\n",
    "    # ê±´ê°• ìƒíƒœ\n",
    "    redis_ok = check_redis_health()\n",
    "    kafka_ok = check_kafka_health()\n",
    "\n",
    "    print(f\"  Redis: {'ğŸŸ¢ ì •ìƒ' if redis_ok else 'ğŸ”´ ì¥ì• '}\")\n",
    "    print(f\"  Kafka: {'ğŸŸ¢ ì •ìƒ' if kafka_ok else 'ğŸ”´ ì¥ì• '}\")\n",
    "\n",
    "    # ì„±ëŠ¥ ì§€í‘œ\n",
    "    print(\n",
    "        f\"  ìºì‹œ íˆíŠ¸ìœ¨: {hit_rate * 100:.1f}% {'ğŸŸ¢' if hit_rate > 0.8 else 'ğŸŸ¡' if hit_rate > 0.5 else 'ğŸ”´'}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Rate Limit ê±°ë¶€ìœ¨: {rejection_rate * 100:.1f}% {'ğŸŸ¢' if rejection_rate < 0.1 else 'ğŸŸ¡' if rejection_rate < 0.3 else 'ğŸ”´'}\"\n",
    "    )\n",
    "\n",
    "    # í ì ì²´ ìƒíƒœ\n",
    "    queue_backlog = queue_stats.get(\"pending\", 0) + queue_stats.get(\"processing\", 0)\n",
    "    print(\n",
    "        f\"  í ì ì²´: {queue_backlog:,} {'ğŸŸ¢' if queue_backlog < 100 else 'ğŸŸ¡' if queue_backlog < 1000 else 'ğŸ”´'}\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await monitoring_example()\n",
    "\n",
    "print(\"ğŸ’¡ ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸:\")\n",
    "print(\"  - ìºì‹œ íˆíŠ¸ìœ¨ > 80%: ìºì‹± íš¨ê³¼ì \")\n",
    "print(\"  - Rate Limit ê±°ë¶€ìœ¨ < 10%: ì ì ˆí•œ ì œí•œ\")\n",
    "print(\"  - í ì ì²´ < 100: ì²˜ë¦¬ ì†ë„ ì¶©ë¶„\")\n",
    "print(\"  - ì´ë²¤íŠ¸ ì‹¤íŒ¨ìœ¨ < 1%: ì‹œìŠ¤í…œ ì•ˆì •\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ë””ë²„ê¹… ë°©ë²•:\")\n",
    "print(\"  1. ìºì‹œ íˆíŠ¸ìœ¨ ë‚®ìŒ â†’ TTL ì¦ê°€ ë˜ëŠ” í‚¤ ì„¤ê³„ ê°œì„ \")\n",
    "print(\"  2. Rate Limit ê±°ë¶€ìœ¨ ë†’ìŒ â†’ ì œí•œ ì™„í™” ë˜ëŠ” ì‚¬ìš©ì êµìœ¡\")\n",
    "print(\"  3. í ì ì²´ ë°œìƒ â†’ ì›Œì»¤ ìˆ˜ ì¦ê°€ ë˜ëŠ” ë°°ì¹˜ í¬ê¸° ì¡°ì •\")\n",
    "print(\"  4. ì´ë²¤íŠ¸ ì‹¤íŒ¨ â†’ Kafka ì—°ê²° í™•ì¸ ë˜ëŠ” Fallback í™œì„±í™”\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì•Œë¦¼ ì„¤ì • ê¶Œì¥:\")\n",
    "print(\"  - ìºì‹œ íˆíŠ¸ìœ¨ < 50%\")\n",
    "print(\"  - Rate Limit ê±°ë¶€ìœ¨ > 30%\")\n",
    "print(\"  - í ì ì²´ > 1000\")\n",
    "print(\"  - Redis/Kafka ì—°ê²° ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 ëª¨ë‹ˆí„°ë§ & ë””ë²„ê¹…\n",
    "\n",
    "ë¶„ì‚° ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import BatchProcessor\n",
    "import time\n",
    "\n",
    "\n",
    "async def batch_processing_example():\n",
    "    \"\"\"ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì œ\"\"\"\n",
    "\n",
    "    print(\"ğŸ” ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬:\\n\")\n",
    "\n",
    "    # BatchProcessor ìƒì„±\n",
    "    batch_processor = BatchProcessor(\n",
    "        batch_size=10,  # ë°°ì¹˜ í¬ê¸°\n",
    "        max_workers=4,  # ì›Œì»¤ ìˆ˜\n",
    "        use_distributed=True,  # ë¶„ì‚° í ì‚¬ìš©\n",
    "    )\n",
    "\n",
    "    # ì²˜ë¦¬í•  ë¬¸ì„œ ëª©ë¡ (1000ê°œ)\n",
    "    documents = [f\"document_{i:04d}.pdf\" for i in range(1000)]\n",
    "\n",
    "    print(f\"ğŸ“š ì´ ë¬¸ì„œ ìˆ˜: {len(documents)}\")\n",
    "    print(f\"âš™ï¸  ë°°ì¹˜ í¬ê¸°: {batch_processor.batch_size}\")\n",
    "    print(f\"ğŸ‘· ì›Œì»¤ ìˆ˜: {batch_processor.max_workers}\")\n",
    "    print()\n",
    "\n",
    "    # ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "    async def process_document(doc_path: str) -> dict:\n",
    "        \"\"\"ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬\"\"\"\n",
    "        # ì‹¤ì œ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "        await asyncio.sleep(0.05)  # 50ms ì²˜ë¦¬ ì‹œê°„\n",
    "\n",
    "        return {\n",
    "            \"doc_path\": doc_path,\n",
    "            \"status\": \"success\",\n",
    "            \"num_pages\": 10,\n",
    "            \"num_chunks\": 25,\n",
    "        }\n",
    "\n",
    "    # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰\n",
    "    print(\"ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘...\")\n",
    "    start = time.time()\n",
    "\n",
    "    results = await batch_processor.process_batch(\n",
    "        items=documents, process_func=process_document, show_progress=True  # ì§„í–‰ë¥  í‘œì‹œ\n",
    "    )\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # ê²°ê³¼ ë¶„ì„\n",
    "    success_count = sum(1 for r in results if r.get(\"status\") == \"success\")\n",
    "    total_pages = sum(r.get(\"num_pages\", 0) for r in results)\n",
    "    total_chunks = sum(r.get(\"num_chunks\", 0) for r in results)\n",
    "\n",
    "    print(f\"\\nâœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "    print(f\"   â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ\")\n",
    "    print(f\"   ğŸ“Š ì²˜ë¦¬ëŸ‰: {len(documents) / elapsed:.1f} docs/sec\")\n",
    "    print(f\"   âœ… ì„±ê³µ: {success_count}/{len(documents)}\")\n",
    "    print(f\"   ğŸ“„ ì´ í˜ì´ì§€: {total_pages:,}\")\n",
    "    print(f\"   ğŸ“ ì´ ì²­í¬: {total_chunks:,}\")\n",
    "    print()\n",
    "\n",
    "    # ìˆœì°¨ ì²˜ë¦¬ì™€ ë¹„êµ\n",
    "    print(\"ğŸ“Š ìˆœì°¨ ì²˜ë¦¬ì™€ ë¹„êµ:\")\n",
    "    sequential_time = len(documents) * 0.05  # ìˆœì°¨ ì²˜ë¦¬ ì˜ˆìƒ ì‹œê°„\n",
    "    speedup = sequential_time / elapsed\n",
    "    print(f\"   ìˆœì°¨ ì²˜ë¦¬ ì˜ˆìƒ ì‹œê°„: {sequential_time:.2f}ì´ˆ\")\n",
    "    print(f\"   ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ\")\n",
    "    print(f\"   ì†ë„ í–¥ìƒ: {speedup:.1f}ë°°\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await batch_processing_example()\n",
    "\n",
    "print(\"ğŸ’¡ BatchProcessorì˜ ì¥ì :\")\n",
    "print(\"  - ë³‘ë ¬ ì²˜ë¦¬: CPU/IO ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì  í™œìš©\")\n",
    "print(\"  - ë¶„ì‚° í: ì—¬ëŸ¬ ì›Œì»¤ë¡œ ì‘ì—… ë¶„ì‚°\")\n",
    "print(\"  - ì§„í–‰ë¥  í‘œì‹œ: ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í™•ì¸\")\n",
    "print(\"  - ì—ëŸ¬ í•¸ë“¤ë§: ê°œë³„ í•­ëª© ì‹¤íŒ¨í•´ë„ ì „ì²´ ê³„ì†\")\n",
    "print(\"  - ì¬ì‹œë„: ì‹¤íŒ¨í•œ í•­ëª© ìë™ ì¬ì‹œë„\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì‚¬ìš© ì‚¬ë¡€:\")\n",
    "print(\"  - ëŒ€ëŸ‰ ë¬¸ì„œ ì„ë² ë”© ìƒì„± (1000+ ë¬¸ì„œ)\")\n",
    "print(\"  - ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬ (OCR, Vision RAG)\")\n",
    "print(\"  - Knowledge Graph ëŒ€ëŸ‰ êµ¬ì¶•\")\n",
    "print(\"  - ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ (BatchProcessor)\n",
    "\n",
    "BatchProcessorë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beanllm.infrastructure.distributed import (\n",
    "    check_redis_health,\n",
    "    check_kafka_health,\n",
    ")\n",
    "\n",
    "\n",
    "async def test_fallback():\n",
    "    \"\"\"Fallback ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "\n",
    "    print(\"ğŸ” Fallback ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "\n",
    "    # 1. ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸\n",
    "    print(\"ğŸ“Š ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ:\")\n",
    "    redis_ok = check_redis_health()\n",
    "    kafka_ok = check_kafka_health()\n",
    "\n",
    "    print(f\"  Redis: {'âœ… ì—°ê²°ë¨' if redis_ok else 'âŒ ì—°ê²° ì‹¤íŒ¨ â†’ Fallback'}\")\n",
    "    print(f\"  Kafka: {'âœ… ì—°ê²°ë¨' if kafka_ok else 'âŒ ì—°ê²° ì‹¤íŒ¨ â†’ Fallback'}\")\n",
    "    print()\n",
    "\n",
    "    # 2. ë¶„ì‚° ê¸°ëŠ¥ ì‚¬ìš© (ìë™ Fallback)\n",
    "    @with_distributed_features(\n",
    "        pipeline_type=\"test\",\n",
    "        enable_cache=True,\n",
    "        enable_rate_limiting=True,\n",
    "        enable_event_streaming=True,\n",
    "    )\n",
    "    async def test_with_fallback(query: str) -> str:\n",
    "        return f\"ì²˜ë¦¬ ì™„ë£Œ: {query}\"\n",
    "\n",
    "    # 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    print(\"ğŸ”„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰:\")\n",
    "    try:\n",
    "        result = await test_with_fallback(\"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\")\n",
    "        print(f\"âœ… ì„±ê³µ: {result}\")\n",
    "        print()\n",
    "\n",
    "        if not redis_ok:\n",
    "            print(\"ğŸ’¡ Redis ì—°ê²° ì‹¤íŒ¨:\")\n",
    "            print(\"  - Rate Limiting â†’ ì¸ë©”ëª¨ë¦¬ Rate Limiter ì‚¬ìš©\")\n",
    "            print(\"  - Caching â†’ ì¸ë©”ëª¨ë¦¬ ìºì‹œ ì‚¬ìš©\")\n",
    "            print(\"  - Distributed Lock â†’ ë¡œì»¬ ë½ ì‚¬ìš©\")\n",
    "            print()\n",
    "\n",
    "        if not kafka_ok:\n",
    "            print(\"ğŸ’¡ Kafka ì—°ê²° ì‹¤íŒ¨:\")\n",
    "            print(\"  - Event Streaming â†’ ë¡œì»¬ ë¡œê·¸ ì‚¬ìš©\")\n",
    "            print(\"  - Task Queue â†’ ì¸ë©”ëª¨ë¦¬ í ì‚¬ìš©\")\n",
    "            print()\n",
    "\n",
    "        print(\"âœ… Fallbackì´ ì •ìƒ ì‘ë™í•˜ì—¬ ê¸°ëŠ¥ì€ ê³„ì† ë™ì‘í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await test_fallback()\n",
    "\n",
    "print(\"ğŸ’¡ Fallbackì˜ ì¥ì :\")\n",
    "print(\"  - ì•ˆì •ì„±: ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ì‹¤íŒ¨í•´ë„ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ìŒ\")\n",
    "print(\"  - ìœ ì—°ì„±: ê°œë°œ í™˜ê²½ì—ì„œëŠ” ì¸ë©”ëª¨ë¦¬, í”„ë¡œë•ì…˜ì—ì„œëŠ” ë¶„ì‚°\")\n",
    "print(\"  - ì ì§„ì  ë„ì…: ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ë¥¼ í•˜ë‚˜ì”© ì¶”ê°€ ê°€ëŠ¥\")\n",
    "print(\"  - ë””ë²„ê¹…: ë¡œì»¬ í™˜ê²½ì—ì„œ ì‰½ê²Œ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Fallback ë™ì‘ ë°©ì‹:\")\n",
    "print(\"  1. ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ì—°ê²° ì‹œë„\")\n",
    "print(\"  2. ì—°ê²° ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¸ë©”ëª¨ë¦¬ë¡œ ì „í™˜\")\n",
    "print(\"  3. ê²½ê³  ë¡œê·¸ ì¶œë ¥ (ìš´ì˜ìì—ê²Œ ì•Œë¦¼)\")\n",
    "print(\"  4. ê¸°ëŠ¥ì€ ì •ìƒ ì‘ë™ (ì„±ëŠ¥ ì•½ê°„ ì €í•˜)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Fallback ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ë¶„ì‚° ì»´í¬ë„ŒíŠ¸ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¸ë©”ëª¨ë¦¬ë¡œ ì „í™˜ë˜ëŠ” ê²ƒì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "\n",
    "async def benchmark_performance(use_distributed: bool, num_requests: int = 20):\n",
    "    \"\"\"ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\"\"\"\n",
    "\n",
    "    # í™˜ê²½ ì„¤ì •\n",
    "    os.environ[\"USE_DISTRIBUTED\"] = \"true\" if use_distributed else \"false\"\n",
    "\n",
    "    # ê°„ë‹¨í•œ í•¨ìˆ˜ ì •ì˜\n",
    "    @with_distributed_features(\n",
    "        pipeline_type=\"test\",\n",
    "        enable_cache=True,\n",
    "        enable_rate_limiting=False,  # ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•´ ë¹„í™œì„±í™”\n",
    "        enable_event_streaming=False,\n",
    "    )\n",
    "    async def test_function(query: str) -> str:\n",
    "        await asyncio.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "        return f\"ê²°ê³¼: {query}\"\n",
    "\n",
    "    latencies = []\n",
    "\n",
    "    # ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)\n",
    "    start = time.time()\n",
    "    await test_function(\"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\")\n",
    "    first_latency = time.time() - start\n",
    "\n",
    "    # ë‚˜ë¨¸ì§€ ìš”ì²­ (ìºì‹œ íˆíŠ¸)\n",
    "    for i in range(num_requests - 1):\n",
    "        start = time.time()\n",
    "        await test_function(\"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\")\n",
    "        latency = time.time() - start\n",
    "        latencies.append(latency)\n",
    "\n",
    "    return {\n",
    "        \"mode\": \"ë¶„ì‚° ì•„í‚¤í…ì²˜\" if use_distributed else \"ì¸ë©”ëª¨ë¦¬\",\n",
    "        \"first_latency\": first_latency,\n",
    "        \"avg_latency\": statistics.mean(latencies),\n",
    "        \"p50_latency\": statistics.median(latencies),\n",
    "        \"p95_latency\": (\n",
    "            statistics.quantiles(latencies, n=20)[18] if len(latencies) >= 20 else max(latencies)\n",
    "        ),\n",
    "        \"total_requests\": num_requests,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"ğŸ” ì„±ëŠ¥ ë¹„êµ: ë¶„ì‚° vs ì¸ë©”ëª¨ë¦¬\\n\")\n",
    "\n",
    "# ì¸ë©”ëª¨ë¦¬ ë²¤ì¹˜ë§ˆí¬\n",
    "print(\"ğŸ“Š ì¸ë©”ëª¨ë¦¬ ëª¨ë“œ:\")\n",
    "inmemory_result = await benchmark_performance(use_distributed=False, num_requests=20)\n",
    "print(f\"  ì²« ìš”ì²­: {inmemory_result['first_latency']:.4f}ì´ˆ\")\n",
    "print(f\"  í‰ê· : {inmemory_result['avg_latency']:.4f}ì´ˆ\")\n",
    "print(f\"  P50: {inmemory_result['p50_latency']:.4f}ì´ˆ\")\n",
    "print(f\"  P95: {inmemory_result['p95_latency']:.4f}ì´ˆ\")\n",
    "print()\n",
    "\n",
    "# ë¶„ì‚° ì•„í‚¤í…ì²˜ ë²¤ì¹˜ë§ˆí¬\n",
    "print(\"ğŸ“Š ë¶„ì‚° ì•„í‚¤í…ì²˜ ëª¨ë“œ:\")\n",
    "distributed_result = await benchmark_performance(use_distributed=True, num_requests=20)\n",
    "print(f\"  ì²« ìš”ì²­: {distributed_result['first_latency']:.4f}ì´ˆ\")\n",
    "print(f\"  í‰ê· : {distributed_result['avg_latency']:.4f}ì´ˆ\")\n",
    "print(f\"  P50: {distributed_result['p50_latency']:.4f}ì´ˆ\")\n",
    "print(f\"  P95: {distributed_result['p95_latency']:.4f}ì´ˆ\")\n",
    "print()\n",
    "\n",
    "# ë¹„êµ ê²°ê³¼\n",
    "print(\"ğŸ“Š ë¹„êµ ê²°ê³¼:\")\n",
    "first_overhead = (\n",
    "    (distributed_result[\"first_latency\"] - inmemory_result[\"first_latency\"])\n",
    "    / inmemory_result[\"first_latency\"]\n",
    "    * 100\n",
    ")\n",
    "avg_overhead = (\n",
    "    (distributed_result[\"avg_latency\"] - inmemory_result[\"avg_latency\"])\n",
    "    / inmemory_result[\"avg_latency\"]\n",
    "    * 100\n",
    ")\n",
    "\n",
    "print(f\"  ì²« ìš”ì²­ ì˜¤ë²„í—¤ë“œ: {first_overhead:+.1f}%\")\n",
    "print(f\"  í‰ê·  ì˜¤ë²„í—¤ë“œ: {avg_overhead:+.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’¡ ë¶„ì„:\")\n",
    "print(\"  - ì¸ë©”ëª¨ë¦¬: ë‚®ì€ ë ˆì´í„´ì‹œ, ë‹¨ì¼ ì„œë²„ ì œí•œ\")\n",
    "print(\"  - ë¶„ì‚°: ì•½ê°„ì˜ ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ, ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥\")\n",
    "print(\"  - ìºì‹œ íˆíŠ¸ ì‹œ: ë‘ ë°©ì‹ ëª¨ë‘ ë¹ ë¥¸ ì‘ë‹µ\")\n",
    "print(\"  - ê¶Œì¥: í”„ë¡œí† íƒ€ì…ì€ ì¸ë©”ëª¨ë¦¬, í”„ë¡œë•ì…˜ì€ ë¶„ì‚°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ì„±ëŠ¥ ë¹„êµ: ë¶„ì‚° vs ì¸ë©”ëª¨ë¦¬\n",
    "\n",
    "ë¶„ì‚° ì•„í‚¤í…ì²˜ì™€ ì¸ë©”ëª¨ë¦¬ ë°©ì‹ì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "Distributed Architectureë¥¼ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤! ğŸ‰\n",
    "\n",
    "### ğŸ“š ì „ì²´ í•™ìŠµ ì™„ë£Œ\n",
    "\n",
    "ëª¨ë“  íŠœí† ë¦¬ì–¼ì„ ì™„ë£Œí•˜ì…¨ìŠµë‹ˆë‹¤! ì´ì œ beanllmì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ”— ê´€ë ¨ ë¬¸ì„œ\n",
    "\n",
    "- [README.md](../../README.md) - í”„ë¡œì íŠ¸ ê°œìš”\n",
    "- [ARCHITECTURE.md](../../ARCHITECTURE.md) - ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…\n",
    "- [DEPENDENCY_RULES.md](../../DEPENDENCY_RULES.md) - ì˜ì¡´ì„± ê·œì¹™\n",
    "- [API Reference](../API_REFERENCE.md) - ì™„ì „í•œ API ë¬¸ì„œ\n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©**: í•™ìŠµí•œ ë‚´ìš©ì„ ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”\n",
    "2. **ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬**: GitHubì—ì„œ ì´ìŠˆë¥¼ ì œì¶œí•˜ê±°ë‚˜ PRì„ ì œì¶œí•˜ì„¸ìš”\n",
    "3. **ê¸°ëŠ¥ í™•ì¥**: í•„ìš”í•œ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê±°ë‚˜ ê°œì„ í•˜ì„¸ìš”\n",
    "\n",
    "---\n",
    "\n",
    "**âœ… ëª¨ë“  íŠœí† ë¦¬ì–¼ ì™„ë£Œ! ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
