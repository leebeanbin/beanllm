{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ”— Chain & Graph - ì‘ì—… ì²´ì¸ êµ¬ì„±\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ beanllmì˜ Chainê³¼ Graph ê¸°ëŠ¥ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì—¬ëŸ¬ ì‘ì—…ì„ ìˆœì°¨ì  ë˜ëŠ” ë³‘ë ¬ë¡œ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ ëª©ì°¨\n",
        "\n",
        "- [1. Chain ê¸°ë³¸ ì‚¬ìš©](#1-chain-ê¸°ë³¸-ì‚¬ìš©)\n",
        "- [2. Sequential Chain](#2-sequential-chain)\n",
        "- [3. Parallel Chain](#3-parallel-chain)\n",
        "- [4. Prompt Chain](#4-prompt-chain)\n",
        "- [5. Chain Builder](#5-chain-builder)\n",
        "- [6. Graph ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°](#6-graph-ê¸°ë°˜-ì›Œí¬í”Œë¡œìš°)\n",
        "- [7. ì‹¤ì „ ì˜ˆì œ](#7-ì‹¤ì „-ì˜ˆì œ)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì„ ì™„ë£Œí•˜ë©´:\n",
        "- âœ… Chainì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—…ì„ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- âœ… ìˆœì°¨ì  ë° ë³‘ë ¬ ì‹¤í–‰ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- âœ… Graph ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- âœ… ë³µì¡í•œ ì‘ì—… íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“š ì‚¬ì „ ìš”êµ¬ì‚¬í•­\n",
        "\n",
        "- [01_setup_and_installation.ipynb](01_setup_and_installation.ipynb) ì™„ë£Œ\n",
        "- [02_core_client.ipynb](02_core_client.ipynb) ì™„ë£Œ\n",
        "- [05_agent_and_tools.ipynb](05_agent_and_tools.ipynb) ì™„ë£Œ (ê¶Œì¥)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chain ê¸°ë³¸ ì‚¬ìš©\n",
        "\n",
        "Chainì€ ì—¬ëŸ¬ LLM í˜¸ì¶œì„ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "> ğŸ’¡ **Chainì˜ í•µì‹¬**:\n",
        "> - ì‘ì—…ì„ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬\n",
        "> - ì´ì „ ë‹¨ê³„ì˜ ì¶œë ¥ì„ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "> - ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from beanllm import Client, Chain\n",
        "\n",
        "\n",
        "async def basic_chain():\n",
        "    \"\"\"ê¸°ë³¸ Chain ì˜ˆì œ\"\"\"\n",
        "\n",
        "    # Client ìƒì„±\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # Chain ìƒì„±\n",
        "    chain = Chain(client)\n",
        "\n",
        "    # Chain ì‹¤í–‰\n",
        "    result = await chain.run(\"Pythonì´ë€ ë¬´ì—‡ì¸ê°€ìš”? ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "    print(f\"âœ… Chain ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ì¶œë ¥: {result.output}\")\n",
        "    print(f\"\\nğŸ“Š ì‹¤í–‰ ë‹¨ê³„: {len(result.steps)}ê°œ\")\n",
        "    for i, step in enumerate(result.steps, 1):\n",
        "        print(f\"  {i}. {step.get('type', 'unknown')}: {step.get('content', '')[:50]}...\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# result = await basic_chain()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sequential Chain\n",
        "\n",
        "ì—¬ëŸ¬ Chainì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ì „ Chainì˜ ì¶œë ¥ì´ ë‹¤ìŒ Chainì˜ ì…ë ¥ì´ ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from beanllm import SequentialChain, Chain, Client\n",
        "\n",
        "\n",
        "async def sequential_chain_example():\n",
        "    \"\"\"Sequential Chain ì˜ˆì œ\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # ì—¬ëŸ¬ Chain ìƒì„±\n",
        "    chain1 = Chain(client)  # ì²« ë²ˆì§¸ ì‘ì—…\n",
        "    chain2 = Chain(client)  # ë‘ ë²ˆì§¸ ì‘ì—…\n",
        "    chain3 = Chain(client)  # ì„¸ ë²ˆì§¸ ì‘ì—…\n",
        "\n",
        "    # Sequential Chain ìƒì„±\n",
        "    sequential = SequentialChain([chain1, chain2, chain3])\n",
        "\n",
        "    # ì‹¤í–‰\n",
        "    result = await sequential.run(input=\"Python í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "    print(f\"âœ… Sequential Chain ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ìµœì¢… ì¶œë ¥: {result.output[:200]}...\")\n",
        "    print(f\"\\nğŸ“Š ì´ ë‹¨ê³„: {len(result.steps)}ê°œ\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await sequential_chain_example()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€\n",
        "\n",
        "í…ìŠ¤íŠ¸ ìš”ì•½ â†’ ë²ˆì—­ â†’ í¬ë§·íŒ… ê°™ì€ ì‹¤ì œ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•´ë´…ì‹œë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def text_processing_pipeline():\n",
        "    \"\"\"í…ìŠ¤íŠ¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # 1ë‹¨ê³„: ìš”ì•½\n",
        "    summary_chain = Chain(client)\n",
        "\n",
        "    # 2ë‹¨ê³„: ë²ˆì—­ (ìš”ì•½ ê²°ê³¼ë¥¼ ë²ˆì—­)\n",
        "    translate_chain = Chain(client)\n",
        "\n",
        "    # 3ë‹¨ê³„: í¬ë§·íŒ… (ë²ˆì—­ ê²°ê³¼ë¥¼ í¬ë§·íŒ…)\n",
        "    format_chain = Chain(client)\n",
        "\n",
        "    # Sequential Chain ìƒì„±\n",
        "    pipeline = SequentialChain([summary_chain, translate_chain, format_chain])\n",
        "\n",
        "    long_text = \"\"\"\n",
        "    Pythonì€ 1991ë…„ì— ë°œí‘œëœ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\n",
        "    ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
        "    ë™ì  íƒ€ì… ì‹œìŠ¤í…œê³¼ í•´ì„í˜• ì–¸ì–´ì…ë‹ˆë‹¤.\n",
        "    ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° íŒ¨ëŸ¬ë‹¤ì„ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    result = await pipeline.run(input=long_text)\n",
        "\n",
        "    print(\"ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸:\")\n",
        "    print(long_text[:100] + \"...\")\n",
        "    print(f\"\\nâœ… ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“„ ìµœì¢… ê²°ê³¼: {result.output[:200]}...\")\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await text_processing_pipeline()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Parallel Chain\n",
        "\n",
        "ì—¬ëŸ¬ Chainì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from beanllm import ParallelChain, Chain, Client\n",
        "\n",
        "\n",
        "async def parallel_chain_example():\n",
        "    \"\"\"Parallel Chain ì˜ˆì œ\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # ì—¬ëŸ¬ Chain ìƒì„± (ë³‘ë ¬ ì‹¤í–‰)\n",
        "    chain1 = Chain(client)  # ì‘ì—… 1\n",
        "    chain2 = Chain(client)  # ì‘ì—… 2\n",
        "    chain3 = Chain(client)  # ì‘ì—… 3\n",
        "\n",
        "    # Parallel Chain ìƒì„±\n",
        "    parallel = ParallelChain([chain1, chain2, chain3])\n",
        "\n",
        "    # ì‹¤í–‰ (ëª¨ë“  Chainì´ ë™ì‹œì— ì‹¤í–‰ë¨)\n",
        "    result = await parallel.run(input=\"Pythonì˜ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "    print(f\"âœ… Parallel Chain ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“Š ë³‘ë ¬ ì‹¤í–‰ëœ Chain ìˆ˜: {len(result.steps)}ê°œ\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼:\")\n",
        "    for i, step in enumerate(result.steps, 1):\n",
        "        print(f\"  {i}. {step.get('output', '')[:100]}...\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await parallel_chain_example()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prompt Chain\n",
        "\n",
        "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ëœ í˜•ì‹ì˜ ì¶œë ¥ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from beanllm import PromptChain, Client\n",
        "\n",
        "\n",
        "async def prompt_chain_example():\n",
        "    \"\"\"Prompt Chain ì˜ˆì œ\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
        "    template = \"\"\"\n",
        "    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”.\n",
        "    \n",
        "    í…ìŠ¤íŠ¸: {input}\n",
        "    \n",
        "    ìš”ì•½:\n",
        "    1. ì£¼ìš” ë‚´ìš©\n",
        "    2. í•µì‹¬ í¬ì¸íŠ¸\n",
        "    3. ê²°ë¡ \n",
        "    \"\"\"\n",
        "\n",
        "    # Prompt Chain ìƒì„±\n",
        "    prompt_chain = PromptChain(client, template)\n",
        "\n",
        "    # ì‹¤í–‰\n",
        "    text = \"Pythonì€ ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\"\n",
        "    result = await prompt_chain.run(input=text)\n",
        "\n",
        "    print(f\"âœ… Prompt Chain ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼:\\n{result.output}\")\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await prompt_chain_example()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Chain Builder\n",
        "\n",
        "Fluent APIë¥¼ ì‚¬ìš©í•˜ì—¬ Chainì„ ì‰½ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from beanllm import ChainBuilder, Client\n",
        "\n",
        "\n",
        "async def chain_builder_example():\n",
        "    \"\"\"Chain Builder ì˜ˆì œ\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # Fluent APIë¡œ Chain êµ¬ì„±\n",
        "    chain = ChainBuilder(client).with_template(\"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½: {input}\").verbose(True).build()\n",
        "\n",
        "    result = await chain.run(input=\"Pythonì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\")\n",
        "\n",
        "    print(f\"âœ… Chain Builderë¡œ ìƒì„±ëœ Chain ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼: {result.output}\")\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await chain_builder_example()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Graph ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°\n",
        "\n",
        "ë³µì¡í•œ ì¡°ê±´ë¶€ ë¶„ê¸°ì™€ ë£¨í”„ë¥¼ í¬í•¨í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### 6.1 ê¸°ë³¸ Graph\n",
        "\n",
        "ë…¸ë“œì™€ ì—£ì§€ë¡œ êµ¬ì„±ëœ ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from beanllm import Graph, Client\n",
        "\n",
        "\n",
        "async def graph_example():\n",
        "    \"\"\"Graph ì˜ˆì œ\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # Graph ìƒì„±\n",
        "    graph = Graph(client)\n",
        "\n",
        "    # ë…¸ë“œ ì¶”ê°€\n",
        "    graph.add_node(\"start\", lambda x: f\"ì‹œì‘: {x}\")\n",
        "    graph.add_node(\"process\", lambda x: f\"ì²˜ë¦¬: {x.upper()}\")\n",
        "    graph.add_node(\"end\", lambda x: f\"ì™„ë£Œ: {x}\")\n",
        "\n",
        "    # ì—£ì§€ ì¶”ê°€ (ë…¸ë“œ ê°„ ì—°ê²°)\n",
        "    graph.add_edge(\"start\", \"process\")\n",
        "    graph.add_edge(\"process\", \"end\")\n",
        "\n",
        "    # ì‹¤í–‰\n",
        "    result = await graph.run(\"í…ŒìŠ¤íŠ¸\")\n",
        "\n",
        "    print(f\"âœ… Graph ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼: {result}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await graph_example()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 ì¡°ê±´ë¶€ ë¶„ê¸°\n",
        "\n",
        "ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def conditional_graph():\n",
        "    \"\"\"ì¡°ê±´ë¶€ ë¶„ê¸° Graph\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    graph = Graph(client)\n",
        "\n",
        "    # ë…¸ë“œ ì¶”ê°€\n",
        "    graph.add_node(\"input\", lambda x: x)\n",
        "    graph.add_node(\"check\", lambda x: len(x) > 10)  # ì¡°ê±´ ì²´í¬\n",
        "    graph.add_node(\"short\", lambda x: f\"ì§§ì€ í…ìŠ¤íŠ¸: {x}\")\n",
        "    graph.add_node(\"long\", lambda x: f\"ê¸´ í…ìŠ¤íŠ¸: {x}\")\n",
        "\n",
        "    # ì—£ì§€ ì¶”ê°€\n",
        "    graph.add_edge(\"input\", \"check\")\n",
        "    graph.add_conditional_edge(\"check\", \"short\", lambda x: not x)  # Falseë©´ short\n",
        "    graph.add_conditional_edge(\"check\", \"long\", lambda x: x)  # Trueë©´ long\n",
        "\n",
        "    # ì‹¤í–‰\n",
        "    result1 = await graph.run(\"ì§§ìŒ\")\n",
        "    result2 = await graph.run(\"ì´ê²ƒì€ ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤\")\n",
        "\n",
        "    print(f\"âœ… ì§§ì€ í…ìŠ¤íŠ¸ ê²°ê³¼: {result1}\")\n",
        "    print(f\"âœ… ê¸´ í…ìŠ¤íŠ¸ ê²°ê³¼: {result2}\")\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await conditional_graph()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ì‹¤ì „ ì˜ˆì œ\n",
        "\n",
        "### 7.1 ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def document_processing_pipeline():\n",
        "    \"\"\"ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # 1. ë¬¸ì„œ ë¡œë”© Chain\n",
        "    load_chain = Chain(client)\n",
        "\n",
        "    # 2. ìš”ì•½ Chain\n",
        "    summary_chain = PromptChain(client, \"ë‹¤ìŒ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\\n{input}\\n\\nìš”ì•½:\")\n",
        "\n",
        "    # 3. í‚¤ì›Œë“œ ì¶”ì¶œ Chain\n",
        "    keyword_chain = PromptChain(\n",
        "        client, \"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\\n{input}\\n\\ní‚¤ì›Œë“œ:\"\n",
        "    )\n",
        "\n",
        "    # Sequential Chainìœ¼ë¡œ ì—°ê²°\n",
        "    pipeline = SequentialChain([load_chain, summary_chain, keyword_chain])\n",
        "\n",
        "    document = \"Pythonì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\"\n",
        "\n",
        "    result = await pipeline.run(input=document)\n",
        "\n",
        "    print(\"ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ìµœì¢… ê²°ê³¼: {result.output}\")\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await document_processing_pipeline()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 ë³‘ë ¬ ë¶„ì„ ì‹œìŠ¤í…œ\n",
        "\n",
        "ì—¬ëŸ¬ ê´€ì ì—ì„œ ë™ì‹œì— ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def parallel_analysis():\n",
        "    \"\"\"ë³‘ë ¬ ë¶„ì„ ì‹œìŠ¤í…œ\"\"\"\n",
        "\n",
        "    client = Client(model=\"gpt-4o\")\n",
        "\n",
        "    # ì—¬ëŸ¬ ë¶„ì„ Chain ìƒì„±\n",
        "    sentiment_chain = PromptChain(client, \"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {input}\")\n",
        "\n",
        "    topic_chain = PromptChain(client, \"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì£¼ì œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”: {input}\")\n",
        "\n",
        "    style_chain = PromptChain(client, \"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {input}\")\n",
        "\n",
        "    # Parallel Chainìœ¼ë¡œ ì—°ê²°\n",
        "    analysis = ParallelChain([sentiment_chain, topic_chain, style_chain])\n",
        "\n",
        "    text = \"Pythonì€ ì •ë§ í›Œë¥­í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤!\"\n",
        "\n",
        "    result = await analysis.run(input=text)\n",
        "\n",
        "    print(\"ğŸ“Š ë³‘ë ¬ ë¶„ì„ ì™„ë£Œ!\")\n",
        "    print(f\"ğŸ“ ê²°ê³¼: {len(result.steps)}ê°œ ë¶„ì„ ì™„ë£Œ\")\n",
        "\n",
        "\n",
        "# ì‹¤í–‰ (ì£¼ì„ í•´ì œ)\n",
        "# await parallel_analysis()\n",
        "print(\"ğŸ’¡ ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¸ ì‹œê°í™” ì˜ˆì œ\n",
        "\n",
        "### Chain êµ¬ì¡° ì‹œê°í™”\n",
        "\n",
        "> ğŸ’¡ **ì´ë¯¸ì§€ í•„ìš”**: Chainì˜ êµ¬ì¡°ë¥¼ ë³´ì—¬ì£¼ëŠ” ë‹¤ì´ì–´ê·¸ë¨\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Sequential Chain êµ¬ì¡°\n",
        "nodes = [\"Input\", \"Chain 1\", \"Chain 2\", \"Chain 3\", \"Output\"]\n",
        "x_positions = [0, 2, 4, 6, 8]\n",
        "\n",
        "for i, (node, x) in enumerate(zip(nodes, x_positions)):\n",
        "    color = \"lightblue\" if i == 0 or i == len(nodes)-1 else \"lightgreen\"\n",
        "    rect = mpatches.Rectangle((x-0.5, -0.3), 1, 0.6, facecolor=color, edgecolor='black')\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(x, 0, node, ha='center', va='center', fontsize=10)\n",
        "    \n",
        "    if i < len(nodes) - 1:\n",
        "        ax.arrow(x+0.5, 0, 1, 0, head_width=0.1, head_length=0.1, fc='black', ec='black')\n",
        "\n",
        "ax.set_xlim(-1, 9)\n",
        "ax.set_ylim(-1, 1)\n",
        "ax.axis('off')\n",
        "plt.title('Sequential Chain êµ¬ì¡°', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**í•„ìš”í•œ ì´ë¯¸ì§€**:\n",
        "- í”Œë¡œìš°ì°¨íŠ¸: Sequential Chainì˜ ì„ í˜• êµ¬ì¡°\n",
        "- Input â†’ Chain 1 â†’ Chain 2 â†’ Chain 3 â†’ Output\n",
        "- ê° ë…¸ë“œëŠ” ë°•ìŠ¤ë¡œ í‘œì‹œ\n",
        "- í™”ì‚´í‘œë¡œ ë°ì´í„° íë¦„ í‘œì‹œ\n",
        "- ë³‘ë ¬ Chainì˜ ê²½ìš° ì—¬ëŸ¬ ê²½ë¡œê°€ ë™ì‹œì— ì‹¤í–‰ë˜ëŠ” êµ¬ì¡°\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "Chainê³¼ Graphë¥¼ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤! ë‹¤ìŒ íŠœí† ë¦¬ì–¼ë¡œ ì§„í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "### ğŸ“š ì¶”ì²œ í•™ìŠµ ìˆœì„œ\n",
        "\n",
        "1. **[07_multi_agent.ipynb](07_multi_agent.ipynb)** - Multi-Agent\n",
        "   - ì—¬ëŸ¬ Agent í˜‘ì—…\n",
        "   - ì—ì´ì „íŠ¸ ê°„ í†µì‹ \n",
        "\n",
        "2. **[08_vision_rag.ipynb](08_vision_rag.ipynb)** - Vision RAG\n",
        "   - ì´ë¯¸ì§€ ê¸°ë°˜ RAG\n",
        "   - ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰\n",
        "\n",
        "3. **[09_ocr.ipynb](09_ocr.ipynb)** - OCR\n",
        "   - ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "   - ë¬¸ì„œ ë””ì§€í„¸í™”\n",
        "\n",
        "### ğŸ”— ê´€ë ¨ ë¬¸ì„œ\n",
        "\n",
        "- [API Reference](../API_REFERENCE.md#chain) - Chain API ìƒì„¸ ë¬¸ì„œ\n",
        "- [README.md](../../README.md) - í”„ë¡œì íŠ¸ ê°œìš”\n",
        "\n",
        "---\n",
        "\n",
        "**âœ… Chain & Graph ì™„ë£Œ! ë‹¤ìŒ ë…¸íŠ¸ë¶ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”.**\n",
        "ã„±ã„±"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
