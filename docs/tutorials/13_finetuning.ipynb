{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# π“ Fine-tuning - λ¨λΈ νμΈνλ‹\n",
        "\n",
        "μ΄ λ…ΈνΈλ¶μ€ beanllmμ νμΈνλ‹ κΈ°λ¥μ„ ν•™μµν•©λ‹λ‹¤. μ»¤μ¤ν…€ λ°μ΄ν„°μ…‹μΌλ΅ λ¨λΈμ„ ν•™μµν•  μ μμµλ‹λ‹¤.\n",
        "\n",
        "## π“‹ λ©μ°¨\n",
        "\n",
        "- [1. νμΈνλ‹ κΈ°λ³Έ](#1-νμΈνλ‹-κΈ°λ³Έ)\n",
        "- [2. λ°μ΄ν„°μ…‹ μ¤€λΉ„](#2-λ°μ΄ν„°μ…‹-μ¤€λΉ„)\n",
        "- [3. ν•™μµ μ‹¤ν–‰](#3-ν•™μµ-μ‹¤ν–‰)\n",
        "- [4. λ¨λΈ ν‰κ°€](#4-λ¨λΈ-ν‰κ°€)\n",
        "\n",
        "---\n",
        "\n",
        "## π― ν•™μµ λ©ν‘\n",
        "\n",
        "μ΄ λ…ΈνΈλ¶μ„ μ™„λ£ν•λ©΄:\n",
        "- β… νμΈνλ‹μ κ°λ…μ„ μ΄ν•΄ν•  μ μμµλ‹λ‹¤\n",
        "- β… λ°μ΄ν„°μ…‹μ„ μ¤€λΉ„ν•  μ μμµλ‹λ‹¤\n",
        "- β… λ¨λΈμ„ νμΈνλ‹ν•  μ μμµλ‹λ‹¤\n",
        "- β… νμΈνλ‹λ λ¨λΈμ„ ν‰κ°€ν•  μ μμµλ‹λ‹¤\n",
        "\n",
        "---\n",
        "\n",
        "## π“ μ‚¬μ „ μ”κµ¬μ‚¬ν•­\n",
        "\n",
        "- [01_setup_and_installation.ipynb](01_setup_and_installation.ipynb) μ™„λ£\n",
        "- [02_core_client.ipynb](02_core_client.ipynb) μ™„λ£\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. νμΈνλ‹ κΈ°λ³Έ\n",
        "\n",
        "νμΈνλ‹μ€ μ‚¬μ „ ν•™μµλ λ¨λΈμ„ νΉμ • μ‘μ—…μ— λ§κ² μ΅°μ •ν•λ” κ³Όμ •μ…λ‹λ‹¤. λ€κ·λ¨ λ°μ΄ν„°λ΅ μ‚¬μ „ ν•™μµλ λ¨λΈμ„ μμ‹ μ λ„λ©”μΈμ΄λ‚ μ‘μ—…μ— λ§κ² μ¶”κ°€ ν•™μµμ‹μΌ μ„±λ¥μ„ ν–¥μƒμ‹ν‚¬ μ μμµλ‹λ‹¤.\n",
        "\n",
        "> π’΅ **νμΈνλ‹μ ν•µμ‹¬**:\n",
        "> - **μ‚¬μ „ ν•™μµλ λ¨λΈ ν™μ©**: μ΄λ―Έ ν•™μµλ μ§€μ‹κ³Ό ν¨ν„΄ ν™μ©\n",
        "> - **μ»¤μ¤ν…€ λ°μ΄ν„°μ…‹μΌλ΅ ν•™μµ**: μμ‹ μ λ„λ©”μΈ λ°μ΄ν„°λ΅ νΉν™”\n",
        "> - **νΉμ • μ‘μ—…μ— μµμ ν™”**: νΉμ • μ‘μ—…μ μ„±λ¥ ν–¥μƒ\n",
        "> - **λΉ„μ© ν¨μ¨μ„±**: μ²μλ¶€ν„° ν•™μµν•λ” κ²ƒλ³΄λ‹¤ ν›¨μ”¬ μ €λ ΄\n",
        "\n",
        "> π’΅ **νμΈνλ‹ vs ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§**:\n",
        "> - **ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§**: λΉ λ¥΄κ³  λΉ„μ©μ΄ λ‚®μ§€λ§ μ ν•μ \n",
        "> - **νμΈνλ‹**: λ” μ •ν™•ν•κ³  μΌκ΄€μ μ΄μ§€λ§ μ‹κ°„κ³Ό λΉ„μ© μ†μ”\n",
        "> - **ν•μ΄λΈλ¦¬λ“**: ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ + νμΈνλ‹ μ΅°ν•©\n",
        "\n",
        "> π’΅ **νμΈνλ‹μ΄ μ μ©ν• κ²½μ°**:\n",
        "> - νΉμ • λ„λ©”μΈ μ©μ–΄μ™€ μ»¨ν…μ¤νΈκ°€ ν•„μ”ν• κ²½μ°\n",
        "> - μΌκ΄€λ ν•μ‹μ μ‘λ‹µμ΄ ν•„μ”ν• κ²½μ°\n",
        "> - ν”„λ΅¬ν”„νΈλ§μΌλ΅λ” μ›ν•λ” κ²°κ³Όλ¥Ό μ–»κΈ° μ–΄λ ¤μ΄ κ²½μ°\n",
        "> - λ€λ‰μ λ„λ©”μΈ νΉν™” λ°μ΄ν„°κ°€ μλ” κ²½μ°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from beanllm import FineTuner\n",
        "import json\n",
        "\n",
        "# ============================================\n",
        "# νμΈνλ‹ κΈ°λ³Έ\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"νμΈνλ‹ κΈ°λ³Έ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# νμΈνλ‹ μ¤€λΉ„\n",
        "print(\"\\n[FineTuner μƒμ„±]\")\n",
        "# fine_tuner = FineTuner(\n",
        "#     base_model=\"gpt-4o\",  # λλ” \"gpt-3.5-turbo\"\n",
        "#     provider=\"openai\"\n",
        "# )\n",
        "\n",
        "print(\"β… FineTuner μ¤€λΉ„ μ™„λ£!\")\n",
        "print(\"\\nπ’΅ νμΈνλ‹ ν”„λ΅μ„Έμ¤:\")\n",
        "print(\"  1. λ°μ΄ν„°μ…‹ μ¤€λΉ„ (JSONL ν•μ‹)\")\n",
        "print(\"  2. λ°μ΄ν„° κ²€μ¦ λ° μ—…λ΅λ“\")\n",
        "print(\"  3. ν•™μµ μ‘μ—… μ‹μ‘\")\n",
        "print(\"  4. ν•™μµ μ§„ν–‰ μƒν™© λ¨λ‹ν„°λ§\")\n",
        "print(\"  5. λ¨λΈ ν‰κ°€ λ° ν…μ¤νΈ\")\n",
        "print(\"  6. λ¨λΈ λ°°ν¬ λ° μ‚¬μ©\")\n",
        "\n",
        "print(\"\\nπ’΅ μ§€μ›ν•λ” Provider:\")\n",
        "print(\"  - OpenAI Fine-tuning API: ν΄λΌμ°λ“ κΈ°λ°, κ°„νΈν•¨\")\n",
        "print(\"  - Axolotl: λ΅μ»¬ ν•™μµ, μ™„μ „ν• μ μ–΄\")\n",
        "\n",
        "# ============================================\n",
        "# νμΈνλ‹ μµμ… μ„¤λ…\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"νμΈνλ‹ μµμ…\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "fine_tuning_options = {\n",
        "    \"base_model\": {\n",
        "        \"description\": \"κΈ°λ³Έ λ¨λΈ μ„ νƒ\",\n",
        "        \"options\": [\"gpt-4o\", \"gpt-3.5-turbo\"],\n",
        "        \"recommendation\": \"μ‘μ—… λ³µμ΅λ„μ— λ”°λΌ μ„ νƒ\",\n",
        "    },\n",
        "    \"training_epochs\": {\n",
        "        \"description\": \"ν•™μµ μ—ν¬ν¬ μ\",\n",
        "        \"options\": \"1-10 (μΌλ°μ μΌλ΅ 3-5)\",\n",
        "        \"recommendation\": \"λ°μ΄ν„°μ…‹ ν¬κΈ°μ— λ”°λΌ μ΅°μ •\",\n",
        "    },\n",
        "    \"learning_rate\": {\n",
        "        \"description\": \"ν•™μµλ¥ \",\n",
        "        \"options\": \"μλ™ λλ” μλ™ μ„¤μ •\",\n",
        "        \"recommendation\": \"μΌλ°μ μΌλ΅ μλ™ μ„¤μ • κ¶μ¥\",\n",
        "    },\n",
        "    \"batch_size\": {\n",
        "        \"description\": \"λ°°μΉ ν¬κΈ°\",\n",
        "        \"options\": \"μλ™ λλ” μλ™ μ„¤μ •\",\n",
        "        \"recommendation\": \"λ°μ΄ν„°μ…‹ ν¬κΈ°μ— λ”°λΌ μλ™ μ΅°μ •\",\n",
        "    },\n",
        "}\n",
        "\n",
        "print(\"\\nπ“ νμΈνλ‹ μ£Όμ” μµμ…:\")\n",
        "for option, info in fine_tuning_options.items():\n",
        "    print(f\"\\n[{option}]\")\n",
        "    print(f\"  μ„¤λ…: {info['description']}\")\n",
        "    print(f\"  μµμ…: {info['options']}\")\n",
        "    print(f\"  κ¶μ¥: {info['recommendation']}\")\n",
        "\n",
        "print(\"\\nπ’΅ νμΈνλ‹ ν:\")\n",
        "print(\"  - λ°μ΄ν„°μ…‹ ν’μ§μ΄ κ°€μ¥ μ¤‘μ”ν•©λ‹λ‹¤\")\n",
        "print(\"  - μµμ† 10κ°, κ¶μ¥ 50-100κ° μ΄μƒμ μƒν”\")\n",
        "print(\"  - λ‹¤μ–‘ν•κ³  λ€ν‘μ μΈ μμ  ν¬ν•¨\")\n",
        "print(\"  - κ²€μ¦ λ°μ΄ν„°μ…‹λ„ μ¤€λΉ„ν•λ” κ²ƒμ΄ μΆ‹μµλ‹λ‹¤\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"β… νμΈνλ‹ κΈ°λ³Έ ν•™μµ μ™„λ£!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. λ°μ΄ν„°μ…‹ μ¤€λΉ„\n",
        "\n",
        "νμΈνλ‹μ„ μ„ν• λ°μ΄ν„°μ…‹μ„ μ¤€λΉ„ν•©λ‹λ‹¤. λ°μ΄ν„°μ…‹μ ν’μ§μ΄ νμΈνλ‹ μ„±κ³µμ ν•µμ‹¬μ…λ‹λ‹¤.\n",
        "\n",
        "> π’΅ **λ°μ΄ν„°μ…‹ μ”κµ¬μ‚¬ν•­**:\n",
        "> - **JSONL ν•μ‹**: κ° μ¤„μ΄ ν•λ‚μ JSON κ°μ²΄\n",
        "> - **λ©”μ‹μ§€ ν•μ‹**: OpenAI ν•μ‹ (system, user, assistant)\n",
        "> - **μµμ† μƒν” μ**: 10κ° μ΄μƒ (κ¶μ¥: 50-100κ° μ΄μƒ)\n",
        "> - **ν’μ§**: λ‹¤μ–‘ν•κ³  λ€ν‘μ μΈ μμ \n",
        "\n",
        "> π’΅ **λ°μ΄ν„°μ…‹ κµ¬μ΅°**:\n",
        "> ```json\n",
        "> {\n",
        ">   \"messages\": [\n",
        ">     {\"role\": \"system\", \"content\": \"μ‹μ¤ν… λ©”μ‹μ§€\"},\n",
        ">     {\"role\": \"user\", \"content\": \"μ‚¬μ©μ μ§λ¬Έ\"},\n",
        ">     {\"role\": \"assistant\", \"content\": \"μ–΄μ‹μ¤ν„΄νΈ μ‘λ‹µ\"}\n",
        ">   ]\n",
        "> }\n",
        "> ```\n",
        "\n",
        "> β οΈ **μ£Όμμ‚¬ν•­**:\n",
        "> - κ° λ©”μ‹μ§€λ” roleκ³Ό content ν•„λ“λ¥Ό κ°€μ Έμ•Ό ν•©λ‹λ‹¤\n",
        "> - system λ©”μ‹μ§€λ” μ„ νƒμ μ΄μ§€λ§ κ¶μ¥λ©λ‹λ‹¤\n",
        "> - assistant μ‘λ‹µμ€ λ…ν™•ν•κ³  μΌκ΄€λμ–΄μ•Ό ν•©λ‹λ‹¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# λ°μ΄ν„°μ…‹ μ¤€λΉ„\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"λ°μ΄ν„°μ…‹ μ¤€λΉ„\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# λ°μ΄ν„°μ…‹ μμ  (JSONL ν•μ‹)\n",
        "dataset_examples = [\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"λ‹Ήμ‹ μ€ λ„μ›€μ΄ λλ” AI μ–΄μ‹μ¤ν„΄νΈμ…λ‹λ‹¤.\"},\n",
        "            {\"role\": \"user\", \"content\": \"μ•λ…•ν•μ„Έμ”\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"μ•λ…•ν•μ„Έμ”! λ¬΄μ—‡μ„ λ„μ™€λ“λ¦΄κΉμ”?\"},\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"λ‹Ήμ‹ μ€ ν”„λ΅κ·Έλλ° μ „λ¬Έκ°€μ…λ‹λ‹¤.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Pythonμ΄λ€?\"},\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"Pythonμ€ 1991λ…„μ— λ°ν‘λ κ³ κΈ‰ ν”„λ΅κ·Έλλ° μ–Έμ–΄μ…λ‹λ‹¤. κ°„κ²°ν•κ³  μ½κΈ° μ‰¬μ΄ λ¬Έλ²•μ΄ νΉμ§•μ…λ‹λ‹¤.\",\n",
        "            },\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"λ‹Ήμ‹ μ€ λ°μ΄ν„° κ³Όν•™ μ „λ¬Έκ°€μ…λ‹λ‹¤.\"},\n",
        "            {\"role\": \"user\", \"content\": \"λ¨Έμ‹ λ¬λ‹μ κΈ°λ³Έ κ°λ…μ„ μ„¤λ…ν•΄μ£Όμ„Έμ”.\"},\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"λ¨Έμ‹ λ¬λ‹μ€ λ°μ΄ν„°λ΅λ¶€ν„° ν¨ν„΄μ„ ν•™μµν•μ—¬ μμΈ΅μ΄λ‚ λ¶„λ¥λ¥Ό μν–‰ν•λ” AI κΈ°μ μ…λ‹λ‹¤. μ§€λ„ ν•™μµ, λΉ„μ§€λ„ ν•™μµ, κ°•ν™” ν•™μµμΌλ΅ λ¶„λ¥λ©λ‹λ‹¤.\",\n",
        "            },\n",
        "        ]\n",
        "    },\n",
        "]\n",
        "\n",
        "print(\"\\nπ“ λ°μ΄ν„°μ…‹ μμ  (JSONL ν•μ‹):\")\n",
        "for i, example in enumerate(dataset_examples, 1):\n",
        "    print(f\"\\n[μμ  {i}]\")\n",
        "    json_str = json.dumps(example, ensure_ascii=False, indent=2)\n",
        "    print(json_str)\n",
        "\n",
        "# JSONL νμΌ μƒμ„± μμ \n",
        "print(\"\\n[JSONL νμΌ μƒμ„± μμ ]\")\n",
        "# import json\n",
        "#\n",
        "# dataset_file = \"fine_tuning_dataset.jsonl\"\n",
        "#\n",
        "# with open(dataset_file, \"w\", encoding=\"utf-8\") as f:\n",
        "#     for example in dataset_examples:\n",
        "#         f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n",
        "#\n",
        "# print(f\"β… λ°μ΄ν„°μ…‹ νμΌ μƒμ„±: {dataset_file}\")\n",
        "\n",
        "print(\"\\nπ’΅ λ°μ΄ν„°μ…‹ μ”κµ¬μ‚¬ν•­:\")\n",
        "print(\"  - JSONL ν•μ‹: κ° μ¤„μ΄ ν•λ‚μ JSON κ°μ²΄\")\n",
        "print(\"  - messages λ°°μ—΄: system, user, assistant λ©”μ‹μ§€\")\n",
        "print(\"  - μµμ† μƒν” μ: 10κ° μ΄μƒ (κ¶μ¥: 50-100κ° μ΄μƒ)\")\n",
        "print(\"  - λ‹¤μ–‘μ„±: λ‹¤μ–‘ν• μ‹λ‚λ¦¬μ¤μ™€ μμ  ν¬ν•¨\")\n",
        "print(\"  - ν’μ§: λ…ν™•ν•κ³  μΌκ΄€λ μ‘λ‹µ\")\n",
        "\n",
        "# ============================================\n",
        "# λ°μ΄ν„°μ…‹ κ²€μ¦\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"λ°μ΄ν„°μ…‹ κ²€μ¦\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "def validate_dataset(dataset):\n",
        "    \"\"\"\n",
        "    λ°μ΄ν„°μ…‹ κ²€μ¦ ν•¨μ\n",
        "\n",
        "    λ°μ΄ν„°μ…‹μ΄ μ¬λ°”λ¥Έ ν•μ‹μΈμ§€ ν™•μΈν•©λ‹λ‹¤.\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    warnings = []\n",
        "\n",
        "    if not dataset:\n",
        "        errors.append(\"λ°μ΄ν„°μ…‹μ΄ λΉ„μ–΄μμµλ‹λ‹¤\")\n",
        "        return errors, warnings\n",
        "\n",
        "    # μµμ† μƒν” μ ν™•μΈ\n",
        "    if len(dataset) < 10:\n",
        "        warnings.append(f\"μƒν” μκ°€ μ μµλ‹λ‹¤ ({len(dataset)}κ°). μµμ† 10κ° μ΄μƒ κ¶μ¥\")\n",
        "\n",
        "    # κ° μƒν” κ²€μ¦\n",
        "    for i, sample in enumerate(dataset):\n",
        "        if \"messages\" not in sample:\n",
        "            errors.append(f\"μƒν” {i+1}: 'messages' ν‚¤κ°€ μ—†μµλ‹λ‹¤\")\n",
        "            continue\n",
        "\n",
        "        messages = sample[\"messages\"]\n",
        "        if not isinstance(messages, list):\n",
        "            errors.append(f\"μƒν” {i+1}: 'messages'κ°€ λ¦¬μ¤νΈκ°€ μ•„λ‹™λ‹λ‹¤\")\n",
        "            continue\n",
        "\n",
        "        if len(messages) < 2:\n",
        "            errors.append(f\"μƒν” {i+1}: μµμ† 2κ°μ λ©”μ‹μ§€κ°€ ν•„μ”ν•©λ‹λ‹¤ (user, assistant)\")\n",
        "            continue\n",
        "\n",
        "        # λ©”μ‹μ§€ ν•μ‹ κ²€μ¦\n",
        "        has_user = False\n",
        "        has_assistant = False\n",
        "\n",
        "        for msg in messages:\n",
        "            if \"role\" not in msg or \"content\" not in msg:\n",
        "                errors.append(f\"μƒν” {i+1}: λ©”μ‹μ§€μ— 'role' λλ” 'content'κ°€ μ—†μµλ‹λ‹¤\")\n",
        "                continue\n",
        "\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                has_user = True\n",
        "            elif msg[\"role\"] == \"assistant\":\n",
        "                has_assistant = True\n",
        "\n",
        "        if not has_user:\n",
        "            errors.append(f\"μƒν” {i+1}: 'user' λ©”μ‹μ§€κ°€ μ—†μµλ‹λ‹¤\")\n",
        "        if not has_assistant:\n",
        "            errors.append(f\"μƒν” {i+1}: 'assistant' λ©”μ‹μ§€κ°€ μ—†μµλ‹λ‹¤\")\n",
        "\n",
        "    return errors, warnings\n",
        "\n",
        "\n",
        "# λ°μ΄ν„°μ…‹ κ²€μ¦ μ‹¤ν–‰\n",
        "print(\"\\n[λ°μ΄ν„°μ…‹ κ²€μ¦ μ‹¤ν–‰]\")\n",
        "errors, warnings = validate_dataset(dataset_examples)\n",
        "\n",
        "if errors:\n",
        "    print(\"\\nβ μ¤λ¥:\")\n",
        "    for error in errors:\n",
        "        print(f\"  - {error}\")\n",
        "else:\n",
        "    print(\"  β… μ¤λ¥ μ—†μ\")\n",
        "\n",
        "if warnings:\n",
        "    print(\"\\nβ οΈ κ²½κ³ :\")\n",
        "    for warning in warnings:\n",
        "        print(f\"  - {warning}\")\n",
        "else:\n",
        "    print(\"  β… κ²½κ³  μ—†μ\")\n",
        "\n",
        "print(\"\\nπ’΅ λ°μ΄ν„°μ…‹ κ²€μ¦ ν:\")\n",
        "print(\"  - νμΈνλ‹ μ „μ— λ°λ“μ‹ κ²€μ¦\")\n",
        "print(\"  - ν•μ‹ μ¤λ¥λ” ν•™μµ μ‹¤ν¨λ΅ μ΄μ–΄μ§ μ μμ\")\n",
        "print(\"  - μƒν” μμ™€ λ‹¤μ–‘μ„± ν™•μΈ\")\n",
        "print(\"  - μ‘λ‹µ ν’μ§ ν™•μΈ\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"β… λ°μ΄ν„°μ…‹ μ¤€λΉ„ ν•™μµ μ™„λ£!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ν•™μµ μ‹¤ν–‰\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ν•™μµ μ‹¤ν–‰\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "async def start_fine_tuning():\n",
        "    \"\"\"\n",
        "    νμΈνλ‹ ν•™μµ μ‹μ‘ μμ \n",
        "\n",
        "    λ°μ΄ν„°μ…‹μ„ μ—…λ΅λ“ν•κ³  ν•™μµμ„ μ‹μ‘ν•©λ‹λ‹¤.\n",
        "    \"\"\"\n",
        "    from beanllm import FineTuner\n",
        "\n",
        "    # FineTuner μƒμ„±\n",
        "    fine_tuner = FineTuner(base_model=\"gpt-3.5-turbo\", provider=\"openai\")  # νμΈνλ‹ κ°€λ¥ν• λ¨λΈ\n",
        "\n",
        "    # 1. λ°μ΄ν„°μ…‹ μ—…λ΅λ“\n",
        "    print(\"\\n[1λ‹¨κ³„] λ°μ΄ν„°μ…‹ μ—…λ΅λ“\")\n",
        "    dataset_file = \"fine_tuning_dataset.jsonl\"\n",
        "    # file_id = await fine_tuner.upload_dataset(dataset_file)\n",
        "    # print(f\"  β… λ°μ΄ν„°μ…‹ μ—…λ΅λ“ μ™„λ£: {file_id}\")\n",
        "\n",
        "    # 2. ν•™μµ μ‘μ—… μ‹μ‘\n",
        "    print(\"\\n[2λ‹¨κ³„] ν•™μµ μ‘μ—… μ‹μ‘\")\n",
        "    # job = await fine_tuner.start_training(\n",
        "    #     training_file=file_id,\n",
        "    #     validation_file=None,  # μ„ νƒμ : κ²€μ¦ λ°μ΄ν„°μ…‹\n",
        "    #     hyperparameters={\n",
        "    #         \"n_epochs\": 3,  # ν•™μµ μ—ν¬ν¬ μ\n",
        "    #     }\n",
        "    # )\n",
        "    #\n",
        "    # print(f\"  β… ν•™μµ μ‘μ—… μ‹μ‘: {job.id}\")\n",
        "    # print(f\"  π“ μƒνƒ: {job.status}\")\n",
        "\n",
        "    # 3. ν•™μµ μ§„ν–‰ μƒν™© λ¨λ‹ν„°λ§\n",
        "    print(\"\\n[3λ‹¨κ³„] ν•™μµ μ§„ν–‰ μƒν™© λ¨λ‹ν„°λ§\")\n",
        "    # while job.status not in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
        "    #     job = await fine_tuner.get_job_status(job.id)\n",
        "    #     print(f\"  μ§„ν–‰ μ¤‘... μƒνƒ: {job.status}\")\n",
        "    #     if hasattr(job, 'progress'):\n",
        "    #         print(f\"  μ§„ν–‰λ¥ : {job.progress}%\")\n",
        "    #     await asyncio.sleep(10)  # 10μ΄λ§λ‹¤ ν™•μΈ\n",
        "\n",
        "    # 4. ν•™μµ μ™„λ£\n",
        "    # if job.status == \"succeeded\":\n",
        "    #     print(f\"\\nβ… ν•™μµ μ™„λ£!\")\n",
        "    #     print(f\"  λ¨λΈ ID: {job.fine_tuned_model}\")\n",
        "    #     print(f\"  ν•™μµ μ‹κ°„: {job.training_duration}μ΄\")\n",
        "    #     return job.fine_tuned_model\n",
        "    # else:\n",
        "    #     print(f\"\\nβ ν•™μµ μ‹¤ν¨: {job.status}\")\n",
        "    #     return None\n",
        "\n",
        "    print(\"\\nπ’΅ ν•™μµ μ‹¤ν–‰ ν:\")\n",
        "    print(\"  - ν•™μµμ€ λΉ„λ™κΈ°λ΅ μ§„ν–‰λ©λ‹λ‹¤\")\n",
        "    print(\"  - μ§„ν–‰ μƒν™©μ„ μ£ΌκΈ°μ μΌλ΅ ν™•μΈ\")\n",
        "    print(\"  - ν•™μµ μ™„λ£κΉμ§€ μ‹κ°„μ΄ κ±Έλ¦΄ μ μμ\")\n",
        "    print(\"  - λΉ„μ©μ„ λ―Έλ¦¬ ν™•μΈν•μ„Έμ”\")\n",
        "\n",
        "\n",
        "# μ‹¤ν–‰ (μ£Όμ„ ν•΄μ )\n",
        "# model_id = await start_fine_tuning()\n",
        "\n",
        "# ============================================\n",
        "# νμΈνλ‹λ λ¨λΈ μ‚¬μ©\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"νμΈνλ‹λ λ¨λΈ μ‚¬μ©\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "async def use_fine_tuned_model():\n",
        "    \"\"\"\n",
        "    νμΈνλ‹λ λ¨λΈ μ‚¬μ© μμ \n",
        "\n",
        "    ν•™μµμ΄ μ™„λ£λ λ¨λΈμ„ μ‚¬μ©ν•©λ‹λ‹¤.\n",
        "    \"\"\"\n",
        "    from beanllm import Client\n",
        "\n",
        "    # νμΈνλ‹λ λ¨λΈ ID (ν•™μµ μ™„λ£ ν›„ λ°›μ€ ID)\n",
        "    fine_tuned_model_id = \"ft:gpt-3.5-turbo:your-org:custom-model:abc123\"\n",
        "\n",
        "    # νμΈνλ‹λ λ¨λΈλ΅ Client μƒμ„±\n",
        "    client = Client(model=fine_tuned_model_id)\n",
        "\n",
        "    # λ¨λΈ μ‚¬μ©\n",
        "    # response = await client.chat(\n",
        "    #     messages=[\n",
        "    #         {\"role\": \"user\", \"content\": \"Pythonμ΄λ€?\"}\n",
        "    #     ]\n",
        "    # )\n",
        "    #\n",
        "    # print(f\"β… νμΈνλ‹λ λ¨λΈ μ‘λ‹µ:\")\n",
        "    # print(f\"  {response.content}\")\n",
        "\n",
        "    print(\"\\nπ’΅ νμΈνλ‹λ λ¨λΈ μ‚¬μ©:\")\n",
        "    print(\"  - μΌλ° λ¨λΈκ³Ό λ™μΌν•κ² μ‚¬μ© κ°€λ¥\")\n",
        "    print(\"  - νμΈνλ‹λ νΉμ„± λ°μ\")\n",
        "    print(\"  - λ” μ •ν™•ν•κ³  μΌκ΄€λ μ‘λ‹µ\")\n",
        "    print(\"  - λ„λ©”μΈ νΉν™” μ‘λ‹µ μƒμ„±\")\n",
        "\n",
        "\n",
        "# μ‹¤ν–‰ (μ£Όμ„ ν•΄μ )\n",
        "# await use_fine_tuned_model()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"β… ν•™μµ μ‹¤ν–‰ ν•™μµ μ™„λ£!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# λ¨λΈ ν‰κ°€\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"λ¨λΈ ν‰κ°€\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "async def evaluate_fine_tuned_model():\n",
        "    \"\"\"\n",
        "    νμΈνλ‹λ λ¨λΈ ν‰κ°€ μμ \n",
        "\n",
        "    ν•™μµλ λ¨λΈμ μ„±λ¥μ„ ν‰κ°€ν•©λ‹λ‹¤.\n",
        "    \"\"\"\n",
        "    from beanllm import Client\n",
        "\n",
        "    # μ›λ³Έ λ¨λΈκ³Ό νμΈνλ‹λ λ¨λΈ\n",
        "    original_model = Client(model=\"gpt-3.5-turbo\")\n",
        "    fine_tuned_model = Client(model=\"ft:gpt-3.5-turbo:your-org:custom-model:abc123\")\n",
        "\n",
        "    # ν…μ¤νΈ μΌ€μ΄μ¤\n",
        "    test_cases = [\"Pythonμ΄λ€?\", \"λ¨Έμ‹ λ¬λ‹μ κΈ°λ³Έ κ°λ…μ€?\", \"λ°μ΄ν„° κ³Όν•™μ΄λ€?\"]\n",
        "\n",
        "    print(\"\\nπ“ ν…μ¤νΈ μΌ€μ΄μ¤:\")\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        print(f\"  {i}. {case}\")\n",
        "\n",
        "    # κ° λ¨λΈλ΅ ν…μ¤νΈ\n",
        "    print(\"\\n[λ¨λΈ λΉ„κµ ν‰κ°€]\")\n",
        "    # for case in test_cases:\n",
        "    #     print(f\"\\n  μ§λ¬Έ: {case}\")\n",
        "    #\n",
        "    #     # μ›λ³Έ λ¨λΈ μ‘λ‹µ\n",
        "    #     original_response = await original_model.chat(\n",
        "    #         messages=[{\"role\": \"user\", \"content\": case}]\n",
        "    #     )\n",
        "    #     print(f\"  μ›λ³Έ λ¨λΈ: {original_response.content[:100]}...\")\n",
        "    #\n",
        "    #     # νμΈνλ‹λ λ¨λΈ μ‘λ‹µ\n",
        "    #     fine_tuned_response = await fine_tuned_model.chat(\n",
        "    #         messages=[{\"role\": \"user\", \"content\": case}]\n",
        "    #     )\n",
        "    #     print(f\"  νμΈνλ‹ λ¨λΈ: {fine_tuned_response.content[:100]}...\")\n",
        "\n",
        "    print(\"\\nπ’΅ λ¨λΈ ν‰κ°€ ν:\")\n",
        "    print(\"  - λ‹¤μ–‘ν• ν…μ¤νΈ μΌ€μ΄μ¤λ΅ ν‰κ°€\")\n",
        "    print(\"  - μ›λ³Έ λ¨λΈκ³Ό λΉ„κµ\")\n",
        "    print(\"  - λ„λ©”μΈ νΉν™” μ„±λ¥ ν™•μΈ\")\n",
        "    print(\"  - μ‹¤μ  μ‚¬μ© μ‚¬λ΅€λ΅ ν…μ¤νΈ\")\n",
        "\n",
        "\n",
        "# μ‹¤ν–‰ (μ£Όμ„ ν•΄μ )\n",
        "# await evaluate_fine_tuned_model()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"β… λ¨λΈ ν‰κ°€ ν•™μµ μ™„λ£!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ν•™μµ μ‹¤ν–‰\n",
        "\n",
        "λ°μ΄ν„°μ…‹μ΄ μ¤€λΉ„λλ©΄ νμΈνλ‹ ν•™μµμ„ μ‹μ‘ν•  μ μμµλ‹λ‹¤.\n",
        "\n",
        "> π’΅ **ν•™μµ ν”„λ΅μ„Έμ¤**:\n",
        "> - λ°μ΄ν„°μ…‹ μ—…λ΅λ“: Providerμ— λ°μ΄ν„°μ…‹ μ—…λ΅λ“\n",
        "> - ν•™μµ μ‘μ—… μ‹μ‘: νμΈνλ‹ μ‘μ—… μƒμ„±\n",
        "> - μ§„ν–‰ μƒν™© λ¨λ‹ν„°λ§: ν•™μµ μ§„ν–‰ μƒν™© μ¶”μ \n",
        "> - μ™„λ£ λ€κΈ°: ν•™μµ μ™„λ£κΉμ§€ λ€κΈ° (μ λ¶„ ~ μ μ‹κ°„)\n",
        "> - λ¨λΈ ID νλ“: μ™„λ£λ λ¨λΈμ ID μ €μ¥\n",
        "\n",
        "> β οΈ **μ£Όμμ‚¬ν•­**:\n",
        "> - ν•™μµμ€ μ‹κ°„μ΄ κ±Έλ¦΄ μ μμµλ‹λ‹¤ (λ°μ΄ν„°μ…‹ ν¬κΈ°μ— λ”°λΌ)\n",
        "> - λΉ„μ©μ΄ λ°μƒν•  μ μμµλ‹λ‹¤ (Providerλ³„λ΅ λ‹¤λ¦„)\n",
        "> - ν•™μµ μ¤‘μ—λ” λ¨λΈμ„ μ‚¬μ©ν•  μ μ—†μµλ‹λ‹¤\n",
        "\n",
        "## 4. λ¨λΈ ν‰κ°€\n",
        "\n",
        "νμΈνλ‹λ λ¨λΈμ μ„±λ¥μ„ ν‰κ°€ν•©λ‹λ‹¤.\n",
        "\n",
        "> π’΅ **ν‰κ°€ λ°©λ²•**:\n",
        "> - **μ •μ„±μ  ν‰κ°€**: μƒν” μ…λ ¥μΌλ΅ μ‘λ‹µ ν’μ§ ν™•μΈ\n",
        "> - **μ •λ‰μ  ν‰κ°€**: ν…μ¤νΈ λ°μ΄ν„°μ…‹μΌλ΅ μ •ν™•λ„ μΈ΅μ •\n",
        "> - **λΉ„κµ ν‰κ°€**: μ›λ³Έ λ¨λΈκ³Ό μ„±λ¥ λΉ„κµ\n",
        "> - **λ„λ©”μΈ νΉν™” ν‰κ°€**: νΉμ • λ„λ©”μΈμ—μ„μ μ„±λ¥ ν‰κ°€\n",
        "\n",
        "Fine-tuningμ„ λ§μ¤ν„°ν–μµλ‹λ‹¤! λ‹¤μ νν† λ¦¬μ–Όλ΅ μ§„ν–‰ν•μ„Έμ”:\n",
        "\n",
        "### π“ μ¶”μ² ν•™μµ μμ„\n",
        "\n",
        "1. **[14_production_features.ipynb](14_production_features.ipynb)** - Production Features\n",
        "   - ν”„λ΅λ•μ… ν™κ²½ μµμ ν™”\n",
        "   - λ¨λ‹ν„°λ§ λ° λ΅κΉ…\n",
        "\n",
        "2. **[15_distributed_architecture.ipynb](15_distributed_architecture.ipynb)** - Distributed Architecture\n",
        "   - λ¶„μ‚° μ‹μ¤ν… κµ¬μ„±\n",
        "   - Redis & Kafka ν™μ©\n",
        "\n",
        "### π”— κ΄€λ ¨ λ¬Έμ„\n",
        "\n",
        "- [API Reference](../API_REFERENCE.md#fine-tuning) - Fine-tuning API μƒμ„Έ λ¬Έμ„\n",
        "- [README.md](../../README.md) - ν”„λ΅μ νΈ κ°μ”\n",
        "\n",
        "---\n",
        "\n",
        "**β… Fine-tuning μ™„λ£! λ‹¤μ λ…ΈνΈλ¶μΌλ΅ μ§„ν–‰ν•μ„Έμ”.**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
