# ìµœì‹  ëª¨ë¸ ë¦¬ì„œì¹˜ (2024-2025)

beanLLMì˜ ê° ë„ë©”ì¸ì— ì ìš© ê°€ëŠ¥í•œ ìµœì‹  ëª¨ë¸ê³¼ í”„ë ˆì„ì›Œí¬ ì¡°ì‚¬ ê²°ê³¼ì…ë‹ˆë‹¤.

---

## 1. OCR (ê´‘í•™ ë¬¸ì ì¸ì‹) âœ… ì™„ë£Œ

### í˜„ì¬ ìƒíƒœ
- **ê¸°ì¡´ ì—”ì§„ (7ê°œ)**: PaddleOCR, EasyOCR, TrOCR, Nougat, Surya, Tesseract, Cloud API
- **ì‹ ê·œ ì¶”ê°€ (3ê°œ)**: Qwen2.5-VL, MiniCPM-o 2.6, DeepSeek-OCR

### ìµœì‹  ëª¨ë¸ (2024-2025)
| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | íŠ¹ì§• | ì„±ëŠ¥ | ìƒíƒœ |
|------|----------|------|------|------|
| MiniCPM-o 2.6 | 8B | OCRBench 1ìœ„, GPT-4o ëŠ¥ê°€ | 96% | âœ… êµ¬í˜„ë¨ |
| Qwen2.5-VL | 2B/7B/72B | ì˜¤í”ˆì†ŒìŠ¤ ìµœê³  ì„±ëŠ¥ | 95% | âœ… êµ¬í˜„ë¨ |
| DeepSeek-OCR | 3B | í† í° ì••ì¶•, ë©”ëª¨ë¦¬ íš¨ìœ¨ | 94% | âœ… êµ¬í˜„ë¨ |
| GOT-OCR 2.0 | - | ê³ ì •ë°€ OCR | - | â³ í–¥í›„ ê³ ë ¤ |

### Sources
- [Northflank - Best STT Models 2025](https://northflank.com/blog/best-open-source-speech-to-text-stt-model-in-2025-benchmarks)
- [OCRBench Rankings](https://huggingface.co/spaces/mteb/leaderboard)

---

## 2. í…ìŠ¤íŠ¸ ì„ë² ë”© (Text Embeddings)

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„ëœ Provider**: OpenAI, Gemini, Voyage, Jina, Mistral, Cohere (ëª¨ë‘ API ê¸°ë°˜)
- **ë¡œì»¬ ëª¨ë¸**: ì—†ìŒ

### ìµœì‹  ëª¨ë¸ (2024-2025)
| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | MTEB ì ìˆ˜ | íŠ¹ì§• | ê¶Œì¥ë„ |
|------|----------|-----------|------|--------|
| NVIDIA NV-Embed | - | 69.32 | MTEB 1ìœ„ (2024) | â­â­â­ |
| SFR-Embedding-Mistral | 7B | - | E5-mistral ê¸°ë°˜, ê³ ì„±ëŠ¥ | â­â­â­ |
| Alibaba-NLP GTE | 1.5B | - | ì»´íŒ©íŠ¸, 1024-d, Matryoshka | â­â­ |
| Google Gemma Embedding | 300M | - | 100+ ì–¸ì–´, ë¦¬ì†ŒìŠ¤ ì œí•œ í™˜ê²½ | â­â­ |

### ê¶Œì¥ ì‚¬í•­
1. **ë¡œì»¬ ëª¨ë¸ ì§€ì› ì¶”ê°€**
   - `NVIDIAEmbedding` í´ë˜ìŠ¤ ì¶”ê°€
   - `HuggingFaceEmbedding` ë²”ìš© í´ë˜ìŠ¤ ì¶”ê°€ (SFR, Alibaba, ë“±)
   - Sentence Transformers í†µí•©

2. **Matryoshka ì„ë² ë”© ì§€ì›**
   - ê°€ë³€ ì°¨ì› ì„ë² ë”© (128d, 256d, 512d, 1024d)

### Sources
- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
- [NVIDIA NV-Embed Blog](https://developer.nvidia.com/blog/nvidia-text-embedding-model-tops-mteb-leaderboard/)
- [Modal - Top MTEB Models](https://modal.com/blog/mteb-leaderboard-article)

---

## 3. ë¹„ì „ ì„ë² ë”© (Vision Embeddings)

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„ëœ ëª¨ë¸**: CLIP (OpenAI)
- **ë©€í‹°ëª¨ë‹¬**: ê¸°ë³¸ MultimodalEmbedding

### ìµœì‹  ëª¨ë¸ (2024-2025)
| ëª¨ë¸ | íŠ¹ì§• | ì„±ëŠ¥ | ê¶Œì¥ë„ |
|------|------|------|--------|
| SigLIP 2 (Google) | ë‹¤êµ­ì–´, self-distillation | CLIP ëŠ¥ê°€ | â­â­â­ |
| MobileCLIP2 (Apple) | ëª¨ë°”ì¼ ìµœì í™”, 2x ê²½ëŸ‰ | SigLIP-SO400M ë™ê¸‰ | â­â­â­ |
| Voyage-Multimodal-3 | í…ìŠ¤íŠ¸+ì´ë¯¸ì§€+ìŠ¤í¬ë¦°ìƒ· | ë²”ìš©ì„± ë†’ìŒ | â­â­ |
| EVA-CLIP | ê³ í•´ìƒë„, ì •ë°€ ê²€ìƒ‰ | ìš°ìˆ˜ | â­â­ |
| AIMv2 | Autoregressive, ë©€í‹°ëª¨ë‹¬ | ìµœì‹  ì•„í‚¤í…ì²˜ | â­ |

### ê¶Œì¥ ì‚¬í•­
1. **SigLIP 2 ì§€ì› ì¶”ê°€**
   - `SigLIPEmbedding` í´ë˜ìŠ¤ ìƒì„±
   - ë‹¤êµ­ì–´ zero-shot ë¶„ë¥˜ ì§€ì›

2. **MobileCLIP2 ì§€ì› ì¶”ê°€**
   - ëª¨ë°”ì¼/ì—£ì§€ ë””ë°”ì´ìŠ¤ìš©
   - `MobileCLIPEmbedding` í´ë˜ìŠ¤

### Sources
- [SigLIP 2 Blog](https://huggingface.co/blog/siglip2)
- [Top Embedding Models 2025](https://artsmart.ai/blog/top-embedding-models-in-2025/)
- [Voyage Multimodal 3](https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/)

---

## 4. ìŒì„± ì¸ì‹ (Speech Recognition / Audio)

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„ ìƒíƒœ**: Type definitionsë§Œ ì¡´ì¬ (ì‹¤ì œ êµ¬í˜„ ì—†ìŒ)
- **WhisperModel enum**: ì •ì˜ë§Œ ìˆìŒ

### ìµœì‹  ëª¨ë¸ (2024-2025)
| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | RTFx | WER | íŠ¹ì§• | ê¶Œì¥ë„ |
|------|----------|------|-----|------|--------|
| Whisper Large V3 Turbo | 809M | - | 7.4% | 6x ë¹ ë¦„, 99+ ì–¸ì–´ | â­â­â­ |
| Distil-Whisper | 756M | - | ~8% | 6x ë¹ ë¦„, ì••ì¶• | â­â­â­ |
| NVIDIA Parakeet TDT | 1.1B | >2000 | - | ì‹¤ì‹œê°„ ìµœì í™” | â­â­â­ |
| Canary-1B | 1B | - | 6.67% | ë‹¤êµ­ì–´, ë²ˆì—­ | â­â­ |
| Canary-1B-Flash | 1B | >1000 | - | ì´ˆê³ ì† ì¶”ë¡  | â­â­ |
| Moonshine | <100M | - | - | ì˜¨ë””ë°”ì´ìŠ¤, ì´ˆê²½ëŸ‰ | â­ |

### ê¶Œì¥ ì‚¬í•­
1. **beanSTT í´ë˜ìŠ¤ êµ¬í˜„** (OCRê³¼ ìœ ì‚¬í•œ êµ¬ì¡°)
   ```python
   from beanllm.domain.audio import beanSTT

   stt = beanSTT(engine="whisper-v3-turbo", language="ko")
   result = stt.transcribe("audio.mp3")
   ```

2. **ì§€ì› ì—”ì§„**
   - `whisper-v3-turbo`: Whisper Large V3 Turbo
   - `distil-whisper`: Distil-Whisper
   - `parakeet`: NVIDIA Parakeet TDT
   - `canary`: Canary-1B
   - `moonshine`: Moonshine (ì˜¨ë””ë°”ì´ìŠ¤)

### Sources
- [Northflank - Best Open-Source STT 2025](https://northflank.com/blog/best-open-source-speech-to-text-stt-model-in-2025-benchmarks)
- [Modal - Open Source STT](https://modal.com/blog/open-source-stt)
- [AssemblyAI - Top 8 STT Options](https://www.assemblyai.com/blog/top-open-source-stt-options-for-voice-applications)

---

## 5. LLM í‰ê°€ (Evaluation)

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„ëœ ë©”íŠ¸ë¦­**: ExactMatch, F1, BLEU, ROUGE, Semantic Similarity, LLMJudge
- **í”„ë ˆì„ì›Œí¬**: ìì²´ êµ¬í˜„ Evaluator

### ìµœì‹  í”„ë ˆì„ì›Œí¬ (2024-2025)
| í”„ë ˆì„ì›Œí¬ | ë‹¤ìš´ë¡œë“œ | íŠ¹ì§• | ê¶Œì¥ë„ |
|------------|----------|------|--------|
| DeepEval | 500K/ì›” | 14+ ë©”íŠ¸ë¦­, RAG/fine-tuning | â­â­â­ |
| LM Evaluation Harness | - | EleutherAI, CI/CD íŒŒì´í”„ë¼ì¸ | â­â­â­ |
| Confident AI | - | ìµœê³  ë©”íŠ¸ë¦­, í”„ë¡œë•ì…˜ | â­â­ |
| Ragas | - | RAG ì „ë¬¸, Faithfulness | â­â­ |
| OpenAI Evals | - | ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ | â­ |

### ì£¼ìš” ë²¤ì¹˜ë§ˆí¬
- **ê¸°ë³¸**: GLUE, SuperGLUE, HellaSwag, MMLU
- **ê³ ê¸‰**: MMLU-Pro (>90% ë„˜ì–´ì„  ë‚œì´ë„)
- **íŠ¹í™”**: MT-Bench (ë‹¤ì¤‘í„´), GPQA-Diamond (ëŒ€í•™ì› ìˆ˜ì¤€), ARC-AGI (ì¶”ë¡ ), GAIA (AGI)

### ê¶Œì¥ ì‚¬í•­
1. **DeepEval í†µí•©**
   - `DeepEvalMetric` í´ë˜ìŠ¤ ì¶”ê°€
   - RAG í‰ê°€ ë©”íŠ¸ë¦­ í™œìš©

2. **LM Evaluation Harness í†µí•©**
   - í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
   - `LMEvalBenchmark` í´ë˜ìŠ¤

3. **ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ìœ í‹¸ë¦¬í‹°**
   ```python
   from beanllm.domain.evaluation import run_benchmark

   result = run_benchmark(model, benchmark="mmlu-pro")
   ```

### Sources
- [Top 5 LLM Evaluation Frameworks](https://dev.to/guybuildingai/-top-5-open-source-llm-evaluation-frameworks-in-2024-98m)
- [5 LLM Evaluation Tools 2025](https://humanloop.com/blog/best-llm-evaluation-tools)
- [LLM Benchmarks 2025](https://llm-stats.com/benchmarks)

---

## 6. íŒŒì¸íŠœë‹ (Fine-tuning)

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„ëœ Provider**: OpenAI API ê¸°ë°˜ë§Œ
- **ë¡œì»¬ íŒŒì¸íŠœë‹**: ì—†ìŒ

### ìµœì‹  í”„ë ˆì„ì›Œí¬ (2024-2025)
| í”„ë ˆì„ì›Œí¬ | íŠ¹ì§• | ê°•ì  | ê¶Œì¥ë„ |
|------------|------|------|--------|
| Axolotl | ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ | ì´ˆë³´ì ì¹œí™”ì , multi-GPU | â­â­â­ |
| Unsloth | ì†ë„ ìµœì í™” | single-GPU ìµœê³  ì†ë„ | â­â­â­ |
| Torchtune | PyTorch ë„¤ì´í‹°ë¸Œ | PyTorch í†µí•©, ë©€í‹°ë…¸ë“œ | â­â­â­ |
| LlamaFactory | ë²”ìš©ì„± | 100+ ëª¨ë¸, config ê¸°ë°˜ | â­â­â­ |
| Hugging Face PEFT | í‘œì¤€ | LoRA/QLoRA í‘œì¤€ | â­â­ |

### PEFT ê¸°ë²•
- **LoRA**: 1-5% íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµ (Adapter)
- **QLoRA**: 4-bit ì–‘ìí™” + LoRA (70Bë¥¼ ë‹¨ì¼ GPUì—ì„œ)
- **Spectrum (2024)**: SNR ë¶„ì„, ìƒìœ„ 30% ë ˆì´ì–´ë§Œ í•™ìŠµ

### ê¶Œì¥ ìŠ¤íƒ (2025)
```
QLoRA / Spectrum
+ FlashAttention-2
+ Liger Kernels
+ Gradient Checkpointing
```

### ê¶Œì¥ ì‚¬í•­
1. **PEFT Provider ì¶”ê°€**
   ```python
   from beanllm.domain.finetuning import PEFTProvider

   provider = PEFTProvider(
       framework="axolotl",
       method="qlora",
       model="meta-llama/Llama-3-8B"
   )
   job = provider.create_job(config)
   ```

2. **ì§€ì› í”„ë ˆì„ì›Œí¬**
   - Axolotl (ì´ˆë³´ì, multi-GPU)
   - Unsloth (single-GPU ìµœì í™”)
   - LlamaFactory (ë²”ìš©)

### Sources
- [LLM Fine-Tuning Tools 2025](https://labelyourdata.com/articles/llm-fine-tuning/top-llm-tools-for-fine-tuning)
- [Fine-Tune LLMs 2025 Guide](https://www.philschmid.de/fine-tune-llms-in-2025)
- [LoRA vs QLoRA Comparison](https://www.index.dev/blog/top-ai-fine-tuning-tools-lora-vs-qlora-vs-full)

---

## 7. ë¬¸ì„œ íŒŒì‹± (Document Parsing / PDF Loaders)

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„**: beanPDFLoader (ê¸°ë³¸)
- **ê¸°ëŠ¥**: í…Œì´ë¸”, ì´ë¯¸ì§€ ì¶”ì¶œ

### ìµœì‹  ëª¨ë¸/íˆ´í‚· (2024-2025)
| ë„êµ¬ | ì œê³µì | íŠ¹ì§• | ê¶Œì¥ë„ |
|------|--------|------|--------|
| PDF-Extract-Kit | OpenDataLab | DocLayout-YOLO, StructTable-InternVL2 | â­â­â­ |
| Docling | IBM | DocLayNet, TableFormer, ê³ ì •ë°€ | â­â­â­ |
| MinerU | - | PDF-Extract-Kit ê¸°ë°˜, OCR+Table | â­â­ |
| DocLayout-YOLO | - | GL-CRM, ë¹ ë¥¸ ë ˆì´ì•„ì›ƒ ê²€ì¶œ | â­â­ |
| LlamaParse | LlamaIndex | ì´ˆê³ ì† (~6s), API ê¸°ë°˜ | â­â­ |

### VLM ê¸°ë°˜ íŒŒì‹±
- GPT-4V, Qwen, InternVL: ë©€í‹°ëª¨ë‹¬ end-to-end
- Nougat, Fox, GOT: ë¬¸ì„œ ì „ë¬¸ VLM

### ê¶Œì¥ ì‚¬í•­
1. **PDF-Extract-Kit í†µí•©**
   - DocLayout-YOLOë¡œ ë ˆì´ì•„ì›ƒ ê²€ì¶œ
   - StructTable-InternVL2ë¡œ í…Œì´ë¸” ì¸ì‹

2. **Docling í†µí•©**
   - ê³ ì •ë°€ íŒŒì‹±
   - `DoclingLoader` í´ë˜ìŠ¤

3. **beanPDFLoader ê³ ë„í™”**
   ```python
   from beanllm.domain.loaders import beanPDFLoader

   loader = beanPDFLoader(
       "document.pdf",
       engine="docling",  # or "pdf-extract-kit"
       extract_tables=True,
       extract_images=True,
       layout_model="doclayout-yolo"
   )
   docs = loader.load()
   ```

### Sources
- [PDF-Extract-Kit GitHub](https://github.com/opendatalab/PDF-Extract-Kit)
- [PDF Parsing Benchmark 2025](https://procycons.com/en/blogs/pdf-data-extraction-benchmark/)
- [Document Parsing Survey 2024](https://arxiv.org/html/2410.21169v4)

---

## 8. ë¹„ì „ ëª¨ë¸ (Object Detection / Segmentation)

### í˜„ì¬ ìƒíƒœ
- **êµ¬í˜„**: CLIP ì„ë² ë”©ë§Œ
- **ê³ ê¸‰ ë¹„ì „ ê¸°ëŠ¥**: ì—†ìŒ

### ìµœì‹  ëª¨ë¸ (2024-2025)
| ëª¨ë¸ | ì œê³µì | íŠ¹ì§• | ê¶Œì¥ë„ |
|------|--------|------|--------|
| SAM 3 (2025) | Meta | í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸, 3D ì¬êµ¬ì„± | â­â­â­ |
| Florence-2 | Microsoft | ë©€í‹°íƒœìŠ¤í¬ VLM, zero-shot | â­â­â­ |
| YOLOv12 | - | ì†ë„+ì •í™•ë„, real-time | â­â­â­ |
| Grounding DINO | - | Open-set ê²€ì¶œ, í…ìŠ¤íŠ¸ ê¸°ë°˜ | â­â­ |
| RF-DETR | - | ê³ ì •ë°€ ê²€ì¶œ | â­â­ |

### ê¶Œì¥ ì‚¬í•­
1. **ë¹„ì „ ë„ë©”ì¸ í™•ì¥**
   - Object Detection: `beanDetector` í´ë˜ìŠ¤
   - Segmentation: `beanSegmenter` í´ë˜ìŠ¤ (SAM 3 ê¸°ë°˜)
   - VLM: `beanVision` ë²”ìš© í´ë˜ìŠ¤ (Florence-2)

2. **ì‚¬ìš© ì˜ˆì‹œ**
   ```python
   from beanllm.domain.vision import beanDetector, beanSegmenter

   # Object Detection
   detector = beanDetector(model="yolov12")
   results = detector.detect("image.jpg")

   # Segmentation (í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸)
   segmenter = beanSegmenter(model="sam3")
   masks = segmenter.segment("image.jpg", prompt="person wearing red shirt")
   ```

### Sources
- [SAM 3 Announcement](https://about.fb.com/news/2025/11/new-sam-models-detect-objects-create-3d-reconstructions/)
- [Florence-2 Overview](https://www.ultralytics.com/blog/florence-2-microsofts-latest-vision-language-model)
- [Object Detection SOTA 2025](https://hiringnet.com/object-detection-state-of-the-art-models-in-2025/)

---

## ìš°ì„ ìˆœìœ„ ê¶Œì¥ ì‚¬í•­

### ğŸ”¥ ì¦‰ì‹œ êµ¬í˜„ ê¶Œì¥ (High Priority)
1. **ìŒì„± ì¸ì‹ (Audio/STT)** - í˜„ì¬ êµ¬í˜„ ì—†ìŒ, ìˆ˜ìš” ë†’ìŒ
   - Whisper V3 Turbo, Distil-Whisper, Parakeet ì§€ì›

2. **ë¹„ì „ ì„ë² ë”© ì—…ë°ì´íŠ¸** - SigLIP 2, MobileCLIP2 ì¶”ê°€
   - CLIP ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ

3. **PDF íŒŒì‹± ê³ ë„í™”** - PDF-Extract-Kit, Docling í†µí•©
   - í…Œì´ë¸”/ë ˆì´ì•„ì›ƒ ê²€ì¶œ ì •í™•ë„ í–¥ìƒ

### â­ ì¤‘ìš” (Medium Priority)
4. **í…ìŠ¤íŠ¸ ì„ë² ë”© ë¡œì»¬ ëª¨ë¸** - NVIDIA NV-Embed, SFR ì§€ì›
   - API ì˜ì¡´ì„± ê°ì†Œ, ë¹„ìš© ì ˆê°

5. **í‰ê°€ í”„ë ˆì„ì›Œí¬ í†µí•©** - DeepEval, LM Eval Harness
   - RAG í‰ê°€, í‘œì¤€ ë²¤ì¹˜ë§ˆí¬

### ğŸ’¡ í–¥í›„ ê³ ë ¤ (Low Priority)
6. **íŒŒì¸íŠœë‹ ë¡œì»¬ ì§€ì›** - Axolotl, Unsloth
   - ë¡œì»¬ íŒŒì¸íŠœë‹ ìˆ˜ìš” ìˆì„ ì‹œ

7. **ë¹„ì „ ëª¨ë¸ í™•ì¥** - SAM 3, Florence-2
   - Object Detection/Segmentation í•„ìš” ì‹œ

---

## êµ¬í˜„ ê°€ì´ë“œ

### 1ë‹¨ê³„: ìŒì„± ì¸ì‹ (beanSTT)
```python
# src/beanllm/domain/audio/bean_stt.py
class beanSTT:
    def __init__(self, engine="whisper-v3-turbo", language="auto"):
        self.engine = engine
        self.language = language

    def transcribe(self, audio_path):
        # Whisper/Parakeet/Canary ì—”ì§„ ì„ íƒ
        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
        # ì „ì‚¬ ì‹¤í–‰
        return TranscriptionResult(...)
```

### 2ë‹¨ê³„: ë¹„ì „ ì„ë² ë”© (SigLIP 2)
```python
# src/beanllm/domain/vision/embeddings/siglip.py
class SigLIPEmbedding(BaseEmbedding):
    def __init__(self, model_name="google/siglip2-so400m-patch14-384"):
        # HuggingFace ëª¨ë¸ ë¡œë“œ
        # Processor ì´ˆê¸°í™”

    def embed(self, images, texts=None):
        # ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì„ë² ë”©
        return embeddings
```

### 3ë‹¨ê³„: PDF íŒŒì‹± (PDF-Extract-Kit)
```python
# src/beanllm/domain/loaders/pdf/engines/pdf_extract_kit.py
class PDFExtractKitEngine:
    def __init__(self):
        # DocLayout-YOLO ë¡œë“œ
        # StructTable-InternVL2 ë¡œë“œ

    def parse(self, pdf_path):
        # ë ˆì´ì•„ì›ƒ ê²€ì¶œ
        # í…Œì´ë¸” ì¶”ì¶œ
        # êµ¬ì¡°í™”ëœ Document ë°˜í™˜
```

---

## ì°¸ê³  ë¬¸í—Œ

### ì¢…í•© ë¦¬ì†ŒìŠ¤
- [Awesome LLM Evaluation](https://alopatenko.github.io/LLMEvaluation/)
- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
- [Open ASR Leaderboard](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard)

### ëª¨ë¸ í—ˆë¸Œ
- [Hugging Face](https://huggingface.co/)
- [Model Scope](https://modelscope.cn/)
- [Papers with Code](https://paperswithcode.com/)

---

**ìƒì„±ì¼**: 2025-12-30
**ì‘ì„±ì**: Claude Code
**ëª©ì **: beanLLM ë„ë©”ì¸ë³„ ìµœì‹  ëª¨ë¸ ë¦¬ì„œì¹˜ ë° ì—…ë°ì´íŠ¸ ê°€ì´ë“œ
