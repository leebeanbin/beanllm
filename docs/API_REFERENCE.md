# ğŸ“š beanllm API Reference

Complete API reference for all beanllm components.

## Table of Contents

### Core Components
- [Client](#client) - Basic LLM client
- [RAGChain](#ragchain) - RAG (Retrieval-Augmented Generation) system
- [Agent](#agent) - AI agent with tools
- [Chain](#chain) - Chain execution

### Document Processing
- [beanPDFLoader](#beanpdfloader) - Advanced PDF processing with 3-layer architecture
- [Document Loaders](#document-loaders) - Text, CSV, and other document loaders
- [Text Splitters](#text-splitters) - Semantic text chunking

### Advanced Features
- [MultiAgentCoordinator](#multiagentcoordinator) - Multi-agent collaboration
- [Graph](#graph) - Graph-based workflows
- [StateGraph](#stategraph) - State-based graph execution
- [Audio](#audio) - Audio processing (speech-to-text, text-to-speech)

### Specialized Features
- [VisionRAG](#visionrag) - Vision + RAG with image understanding
- [WebSearch](#websearch) - Web search integration
- [Evaluator](#evaluator) - LLM evaluation and metrics
- [FineTuningManager](#finetuningmanager) - Model fine-tuning

---

## Installation

```bash
# Basic installation
pip install beanllm

# With all providers
pip install beanllm[all]

# Specific providers
pip install beanllm[openai,anthropic]
```

---

## Quick Start

```python
import asyncio
from beanllm import Client

async def main():
    # Initialize client
    client = Client(model="gpt-4")

    # Simple chat
    response = await client.chat(
        messages=[{"role": "user", "content": "Hello, how are you?"}]
    )
    print(response.content)

asyncio.run(main())
```

---

# API Documentation

## Core Components

### Client

ê¸°ë³¸ LLM í´ë¼ì´ì–¸íŠ¸. ê°€ì¥ ê°„ë‹¨í•œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

#### `__init__(model, provider=None, api_key=None, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `model` (str): ëª¨ë¸ ì´ë¦„ (ì˜ˆ: "gpt-4", "claude-3-opus", "gemini-pro")
- `provider` (str, optional): Provider ì´ë¦„. ìƒëµ ì‹œ ëª¨ë¸ëª…ì—ì„œ ìë™ ê°ì§€
- `api_key` (str, optional): API í‚¤. ìƒëµ ì‹œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
- `**kwargs`: Providerë³„ ì¶”ê°€ ì„¤ì •

**ì˜ˆì œ:**
```python
from beanllm import Client

# OpenAI
client = Client(model="gpt-4")

# Anthropic (provider ìë™ ê°ì§€)
client = Client(model="claude-3-opus-20240229")

# ëª…ì‹œì  provider ì§€ì •
client = Client(model="gpt-4", provider="openai")
```

#### `chat(messages, system=None, temperature=None, max_tokens=None, **kwargs)` (async)

ì±„íŒ… ì™„ë£Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `messages` (List[Dict[str, str]]): ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ `[{"role": "user", "content": "..."}]`
- `system` (str, optional): ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
- `temperature` (float, optional): ìƒ˜í”Œë§ ì˜¨ë„ (0.0-2.0)
- `max_tokens` (int, optional): ìµœëŒ€ ìƒì„± í† í° ìˆ˜
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `ChatResponse`

**ì˜ˆì œ:**
```python
response = await client.chat(
    messages=[{"role": "user", "content": "Hello!"}],
    temperature=0.7,
    max_tokens=1000
)
print(response.content)
```

#### `stream_chat(messages, **kwargs)` (async)

ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì±„íŒ… ì™„ë£Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:** `chat()`ì™€ ë™ì¼

**ë°˜í™˜:** `AsyncIterator[str]`

**ì˜ˆì œ:**
```python
async for chunk in client.stream_chat(messages=[{"role": "user", "content": "Tell me a story"}]):
    print(chunk, end="", flush=True)
```

---

### RAGChain

RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ. ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

#### `from_documents(source, chunk_size=500, chunk_overlap=50, embedding_model="text-embedding-3-small", llm_model="gpt-4o-mini", **kwargs)`

íŒ©í† ë¦¬ ë©”ì„œë“œë¡œ RAG ì‹œìŠ¤í…œì„ ìƒì„±í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `source` (str | List): ë¬¸ì„œ ê²½ë¡œ ë˜ëŠ” ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
- `chunk_size` (int): ì²­í¬ í¬ê¸°
- `chunk_overlap` (int): ì²­í¬ ê²¹ì¹¨
- `embedding_model` (str): ì„ë² ë”© ëª¨ë¸ ì´ë¦„
- `llm_model` (str): LLM ëª¨ë¸ ì´ë¦„
- `**kwargs`: ì¶”ê°€ ì„¤ì •

**ì˜ˆì œ:**
```python
from beanllm import RAGChain

rag = RAGChain.from_documents(
    source="documents.txt",
    chunk_size=500,
    embedding_model="text-embedding-3-small",
    llm_model="gpt-4"
)
```

#### `add_documents(documents)` (async)

ë¬¸ì„œë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `documents` (List[str] | List[Document]): ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

**ì˜ˆì œ:**
```python
documents = [
    "Python is a programming language.",
    "Machine learning is a subset of AI.",
]
await rag.add_documents(documents)
```

#### `query(question, top_k=3, **kwargs)` (async)

ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `question` (str): ì§ˆë¬¸
- `top_k` (int): ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `RAGResponse`

**ì˜ˆì œ:**
```python
response = await rag.query(
    question="What is Python?",
    top_k=3
)
print(response.answer)
print(response.sources)  # ì‚¬ìš©ëœ ë¬¸ì„œë“¤
```

---

### Agent

ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì—ì´ì „íŠ¸.

#### `__init__(model, tools=None, max_iterations=10, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `model` (str): LLM ëª¨ë¸ ì´ë¦„
- `tools` (List[Tool], optional): ì‚¬ìš©í•  ë„êµ¬ ë¦¬ìŠ¤íŠ¸
- `max_iterations` (int): ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
- `**kwargs`: ì¶”ê°€ ì„¤ì •

**ì˜ˆì œ:**
```python
from beanllm import Agent
from beanllm import search_web, calculator

agent = Agent(
    model="gpt-4",
    tools=[search_web, calculator]
)
```

#### `run(task, max_iterations=10, **kwargs)` (async)

ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `task` (str): ìˆ˜í–‰í•  ì‘ì—…
- `max_iterations` (int): ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `AgentResponse`

**ì˜ˆì œ:**
```python
response = await agent.run(
    task="Calculate 123 * 456 and search for the result online",
    max_iterations=5
)
print(response.final_answer)
print(response.steps)  # ì‹¤í–‰ ë‹¨ê³„
```

---

### Chain

ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì²´ì¸.

#### `__init__(client, memory=None, verbose=False)`

**íŒŒë¼ë¯¸í„°:**
- `client` (Client): LLM í´ë¼ì´ì–¸íŠ¸
- `memory` (Memory, optional): ë©”ëª¨ë¦¬ ê°ì²´
- `verbose` (bool): ë””ë²„ê·¸ ì¶œë ¥ ì—¬ë¶€

#### `run(user_input, **kwargs)` (async)

ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `user_input` (str): ì‚¬ìš©ì ì…ë ¥
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `ChainResult`

**ì˜ˆì œ:**
```python
from beanllm import Chain, Client

client = Client(model="gpt-4")
chain = Chain(client=client)

response = await chain.run("Translate 'hello' to French")
print(response.output)
```

---

## Document Processing

### beanPDFLoader

ê³ ê¸‰ PDF ì²˜ë¦¬ë¥¼ ìœ„í•œ 3-Layer ì•„í‚¤í…ì²˜ ë¡œë”.

**3-Layer ì•„í‚¤í…ì²˜:**
- **Fast Layer** (PyMuPDF): ë¹ ë¥¸ ì²˜ë¦¬ (~130 pages/sec), ì´ë¯¸ì§€ ì¶”ì¶œ
- **Accurate Layer** (pdfplumber): ì •í™•í•œ í…Œì´ë¸” ì¶”ì¶œ (~10 pages/sec)
- **ML Layer** (marker-pdf): êµ¬ì¡° ë³´ì¡´ Markdown ë³€í™˜ (98% ì •í™•ë„)

#### `__init__(file_path, strategy="auto", extract_tables=True, extract_images=False, to_markdown=False, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `file_path` (str | Path): PDF íŒŒì¼ ê²½ë¡œ
- `strategy` (str): íŒŒì‹± ì „ëµ
  - `"auto"`: ìë™ ì„ íƒ (ê¸°ë³¸ê°’)
  - `"fast"`: PyMuPDF (ë¹ ë¥¸ ì²˜ë¦¬)
  - `"accurate"`: pdfplumber (ì •í™•í•œ í…Œì´ë¸”)
  - `"ml"`: marker-pdf (ML ê¸°ë°˜, optional)
- `extract_tables` (bool): í…Œì´ë¸” ì¶”ì¶œ ì—¬ë¶€ (ê¸°ë³¸: True)
- `extract_images` (bool): ì´ë¯¸ì§€ ì¶”ì¶œ ì—¬ë¶€ (ê¸°ë³¸: False)
- `to_markdown` (bool): Markdown ë³€í™˜ ì—¬ë¶€ (ê¸°ë³¸: False)
- `enable_ocr` (bool): OCR í™œì„±í™” (í–¥í›„ êµ¬í˜„)
- `layout_analysis` (bool): ë ˆì´ì•„ì›ƒ ë¶„ì„ (í–¥í›„ êµ¬í˜„)
- `max_pages` (int, optional): ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜
- `page_range` (tuple[int, int], optional): ì²˜ë¦¬í•  í˜ì´ì§€ ë²”ìœ„

**ì˜ˆì œ:**
```python
from beanllm.domain.loaders.pdf import beanPDFLoader

# ê¸°ë³¸ ì‚¬ìš© (ìë™ ì „ëµ)
loader = beanPDFLoader("document.pdf")
docs = loader.load()

# í…Œì´ë¸” ì¶”ì¶œ
loader = beanPDFLoader("report.pdf", extract_tables=True)
docs = loader.load()
tables = loader._result["tables"]

# Markdown ë³€í™˜
loader = beanPDFLoader("article.pdf", to_markdown=True)
docs = loader.load()
markdown = loader._result["markdown"]

# ML Layer ì‚¬ìš© (marker-pdf í•„ìš”)
loader = beanPDFLoader("complex.pdf", strategy="ml", to_markdown=True)
docs = loader.load()
```

#### `load()` â†’ `List[Document]`

PDFë¥¼ ë¡œë”©í•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

**ë°˜í™˜ê°’:**
- `List[Document]`: í˜ì´ì§€ë³„ Document ë¦¬ìŠ¤íŠ¸

**ì˜ˆì œ:**
```python
loader = beanPDFLoader("document.pdf")
docs = loader.load()

for doc in docs:
    print(f"Page {doc.metadata['page']}: {doc.content[:100]}...")
```

#### ê³ ê¸‰ ê¸°ëŠ¥

**1. í…Œì´ë¸” ì¶”ì¶œ ë° ë³€í™˜**

```python
from beanllm.domain.loaders.pdf import beanPDFLoader
from beanllm.domain.loaders.pdf.extractors import TableExtractor

# í…Œì´ë¸” ì¶”ì¶œ
loader = beanPDFLoader("report.pdf", extract_tables=True)
docs = loader.load()

# í…Œì´ë¸” ì¡°íšŒ
extractor = TableExtractor(docs)
all_tables = extractor.get_all_tables()
high_quality = extractor.get_high_quality_tables(min_confidence=0.8)

# Markdown ë³€í™˜
markdown_tables = extractor.export_to_markdown()
```

**2. Markdown ë³€í™˜ ë° Layout Analysis**

```python
from beanllm.domain.loaders.pdf import beanPDFLoader
from beanllm.domain.loaders.pdf.utils import LayoutAnalyzer

# Markdown ë³€í™˜
loader = beanPDFLoader("article.pdf", to_markdown=True)
docs = loader.load()
markdown = loader._result["markdown"]

# Layout ë¶„ì„
analyzer = LayoutAnalyzer()
for doc in docs:
    page_data = {"text": doc.content, "width": doc.metadata["width"],
                 "height": doc.metadata["height"], "metadata": doc.metadata}
    layout = analyzer.analyze_layout(page_data)
    print(f"Columns: {layout['columns']}, Multi-column: {layout['is_multi_column']}")
```

**3. MarkerEngine (ML Layer)**

```python
# ML Layer ì‚¬ìš© (marker-pdf ì„¤ì¹˜ í•„ìš”: pip install beanllm[ml])
from beanllm.domain.loaders.pdf.engines import MarkerEngine

engine = MarkerEngine(
    use_gpu=False,      # GPU ì‚¬ìš© ì—¬ë¶€
    enable_cache=True,  # ê²°ê³¼ ìºì‹±
    cache_size=10,      # ìºì‹œ í¬ê¸°
)

# ë‹¨ì¼ PDF ì²˜ë¦¬
result = engine.extract("document.pdf", {
    "to_markdown": True,
    "extract_tables": True,
    "extract_images": True,
})

# Batch ì²˜ë¦¬
results = engine.extract_batch(
    ["doc1.pdf", "doc2.pdf", "doc3.pdf"],
    {"to_markdown": True}
)

# ìºì‹œ í†µê³„
stats = engine.get_cache_stats()
print(f"Cache: {stats['cache_size']}/{stats['cache_limit']}")
```

**4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**

```
Engine       Time(s)    Pages/s    Memory(MB)
------------------------------------------------
PyMuPDF      0.03       129.61     0.20
pdfplumber   0.42       9.59       41.41
marker-pdf   ~10s/100pg (GPU), 98% accuracy
```

---

### Document Loaders

í…ìŠ¤íŠ¸, CSV ë“± ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ ì§€ì›.

```python
from beanllm.domain.loaders import TextLoader, CSVLoader

# Text íŒŒì¼
text_loader = TextLoader("document.txt")
docs = text_loader.load()

# CSV íŒŒì¼
csv_loader = CSVLoader("data.csv")
docs = csv_loader.load()
```

---

### Text Splitters

ì˜ë¯¸ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ë¶„í• .

```python
from beanllm.domain.splitters import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", " "]
)

chunks = splitter.split_documents(docs)
```

---

## Advanced Features

### MultiAgentCoordinator

ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•˜ëŠ” ì‹œìŠ¤í…œ.

#### `__init__(agents, communication_bus=None)`

**íŒŒë¼ë¯¸í„°:**
- `agents` (Dict[str, Agent]): ì—ì´ì „íŠ¸ ë”•ì…”ë„ˆë¦¬ (id: agent)
- `communication_bus` (CommunicationBus, optional): í†µì‹  ë²„ìŠ¤

#### `execute_sequential(task, agent_order, **kwargs)` (async)

ìˆœì°¨ì ìœ¼ë¡œ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `task` (str): ì‘ì—…
- `agent_order` (List[str]): ì—ì´ì „íŠ¸ ì‹¤í–‰ ìˆœì„œ

#### `execute_debate(task, agent_ids=None, rounds=3, **kwargs)` (async)

í† ë¡  ë°©ì‹ìœ¼ë¡œ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

**ì˜ˆì œ:**
```python
from beanllm import MultiAgentCoordinator, Agent

researcher = Agent(model="gpt-4")
writer = Agent(model="gpt-4")

coordinator = MultiAgentCoordinator(
    agents={"researcher": researcher, "writer": writer}
)

result = await coordinator.execute_sequential(
    task="Research AI trends and write a summary",
    agent_order=["researcher", "writer"]
)
```

---

### Graph

ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°.

#### `__init__(enable_cache=True)`

**íŒŒë¼ë¯¸í„°:**
- `enable_cache` (bool): ìºì‹± í™œì„±í™” ì—¬ë¶€

#### `add_node(node)`

ê·¸ë˜í”„ì— ë…¸ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `add_edge(from_node, to_node)`

ë…¸ë“œ ê°„ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `run(initial_state, verbose=False)` (async)

ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

---

### StateGraph

ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ ì‹¤í–‰ ì‹œìŠ¤í…œ.

#### `__init__(state_schema=None, config=None)`

**íŒŒë¼ë¯¸í„°:**
- `state_schema` (Dict, optional): ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì •ì˜
- `config` (GraphConfig, optional): ê·¸ë˜í”„ ì„¤ì •

#### `add_node(name, func)`

ìƒíƒœ ê·¸ë˜í”„ì— ë…¸ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `set_entry_point(node_name)`

ì§„ì…ì ì„ ì„¤ì •í•©ë‹ˆë‹¤.

#### `add_conditional_edge(from_node, condition_func, edge_mapping=None)`

ì¡°ê±´ë¶€ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `invoke(initial_state, execution_id=None)` (async)

ìƒíƒœ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

**ì˜ˆì œ:**
```python
from beanllm import StateGraph

graph = StateGraph(state_schema={"count": 0, "message": ""})

def increment(state):
    state["count"] += 1
    return state

graph.add_node("increment", increment)
graph.set_entry_point("increment")

result = await graph.invoke({"count": 0, "message": "start"})
```

---

### Audio

ìŒì„± ì²˜ë¦¬ (STT, TTS).

#### WhisperSTT - Speech-to-Text

```python
from beanllm import WhisperSTT

stt = WhisperSTT(model="base")
text = stt.transcribe("speech.mp3")
print(text)
```

#### TextToSpeech - Text-to-Speech

```python
from beanllm import TextToSpeech

tts = TextToSpeech(provider="openai", voice="alloy")
audio_bytes = tts.synthesize("Hello, world!")
```

#### AudioRAG - ì˜¤ë””ì˜¤ ê²€ìƒ‰ ë° QA

```python
from beanllm import AudioRAG

audio_rag = AudioRAG()
audio_rag.add_audio("interview.mp3", audio_id="interview_1")
results = audio_rag.search("What did they say about AI?", top_k=3)
```

---

## Specialized Features

### VisionRAG

ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ê¸°ë°˜ RAG.

#### `from_images(source, generate_captions=True, llm_model="gpt-4o", **kwargs)`

ì´ë¯¸ì§€ë¡œë¶€í„° VisionRAGë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `source` (str | List): ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸
- `generate_captions` (bool): ìë™ ìº¡ì…˜ ìƒì„± ì—¬ë¶€
- `llm_model` (str): LLM ëª¨ë¸

**ì˜ˆì œ:**
```python
from beanllm import VisionRAG

vision_rag = VisionRAG.from_images(
    source="images/",
    generate_captions=True,
    llm_model="gpt-4o"
)

# ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ì§ˆì˜
response = vision_rag.query(
    question="What objects are in the images?",
    k=3,
    include_images=True
)
```

---

### WebSearch

ì›¹ ê²€ìƒ‰ í†µí•©.

#### `search(query, engine=None, **kwargs)`

ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `query` (str): ê²€ìƒ‰ ì¿¼ë¦¬
- `engine` (str, optional): ê²€ìƒ‰ ì—”ì§„ ("google", "bing", "duckduckgo")

**ì˜ˆì œ:**
```python
from beanllm import WebSearch

search = WebSearch(default_engine="duckduckgo")
results = search.search("latest AI news")

for result in results:
    print(result.title, result.url)
```

---

### Evaluator

LLM í‰ê°€ ë° ë©”íŠ¸ë¦­.

#### `evaluate(prediction, reference, **kwargs)`

ëª¨ë¸ ì¶œë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `prediction` (str): ì˜ˆì¸¡ ê²°ê³¼
- `reference` (str): ì •ë‹µ ì°¸ì¡°

**ë°˜í™˜:** `EvaluationResult`

**ì˜ˆì œ:**
```python
from beanllm import Evaluator

evaluator = Evaluator(metrics=["bleu", "rouge", "f1"])
result = evaluator.evaluate(
    prediction="The cat sat on the mat",
    reference="A cat was sitting on the mat"
)
print(result.scores)
```

---

### FineTuningManager

ëª¨ë¸ íŒŒì¸íŠœë‹.

#### `prepare_and_upload(examples, output_path, validate=True)`

í›ˆë ¨ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³  ì—…ë¡œë“œí•©ë‹ˆë‹¤.

#### `start_training(model, training_file, validation_file=None, **kwargs)`

íŒŒì¸íŠœë‹ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.

**ì˜ˆì œ:**
```python
from beanllm import FineTuningManager

manager = FineTuningManager(provider="openai")

# ë°ì´í„° ì¤€ë¹„
file_id = manager.prepare_and_upload(
    examples=[...],
    output_path="training.jsonl"
)

# í›ˆë ¨ ì‹œì‘
job = manager.start_training(
    model="gpt-3.5-turbo",
    training_file=file_id
)

# ì§„í–‰ ìƒí™© í™•ì¸
progress = manager.get_training_progress(job.id)
```

---

## Common Types

### Response Objects

All facade methods return specific response objects:

- `ChatResponse` - Chat completion response
- `RAGResponse` - RAG query response
- `AgentResponse` - Agent execution response
- `AudioResponse` - Audio processing response
- `EvaluationResponse` - Evaluation results
- etc.

### Common Parameters

Most facades support these common parameters:

- `model` (str): Model name (e.g., "gpt-4", "claude-3-opus")
- `temperature` (float): Sampling temperature (0.0 - 2.0)
- `max_tokens` (int): Maximum tokens to generate
- `stream` (bool): Enable streaming responses

---

## Error Handling

```python
import asyncio
from beanllm import Client
from beanllm.utils.exceptions import LLMKitError

async def main():
    try:
        client = Client(model="gpt-4")
        response = await client.chat(
            messages=[{"role": "user", "content": "Hello"}]
        )
        print(response.content)
    except LLMKitError as e:
        print(f"Error: {e}")

asyncio.run(main())
```

---

## Environment Variables

beanllm uses environment variables for API keys:

```bash
# OpenAI
export OPENAI_API_KEY="your-key"

# Anthropic
export ANTHROPIC_API_KEY="your-key"

# Google
export GOOGLE_API_KEY="your-key"

# Or use .env file
```

---

## Additional Resources

- [GitHub Repository](https://github.com/leebeanbin/beanllm)
- [PyPI Package](https://pypi.org/project/beanllm/)
- [Examples](../examples/)
- [Architecture Guide](../ARCHITECTURE.md)

---

**Last Updated:** 2025-12-28
**Version:** 0.1.1
