# ğŸ“š beanllm API Reference

Complete API reference for all beanllm components.

## Table of Contents

### Core Components
- [ClientFacade](#clientfacade) - Basic LLM client
- [RAGFacade](#ragfacade) - RAG (Retrieval-Augmented Generation) system
- [AgentFacade](#agentfacade) - AI agent with tools
- [ChainFacade](#chainfacade) - Chain execution

### Advanced Features
- [MultiAgentFacade](#multiagentfacade) - Multi-agent collaboration
- [GraphFacade](#graphfacade) - Graph-based workflows
- [StateGraphFacade](#stategraphfacade) - State-based graph execution
- [AudioFacade](#audiofacade) - Audio processing (speech-to-text, text-to-speech)

### Specialized Features
- [VisionRAGFacade](#visionragfacade) - Vision + RAG with image understanding
- [WebSearchFacade](#websearchfacade) - Web search integration
- [EvaluationFacade](#evaluationfacade) - LLM evaluation and metrics
- [FinetuningFacade](#finetuningfacade) - Model fine-tuning

---

## Installation

```bash
# Basic installation
pip install beanllm

# With all providers
pip install beanllm[all]

# Specific providers
pip install beanllm[openai,anthropic]
```

---

## Quick Start

```python
from beanllm import ClientFacade

# Initialize client
client = ClientFacade(model="gpt-4")

# Simple chat
response = client.chat("Hello, how are you?")
print(response.content)
```

---

# API Documentation

## Core Components

### ClientFacade

ê¸°ë³¸ LLM í´ë¼ì´ì–¸íŠ¸. ê°€ì¥ ê°„ë‹¨í•œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

#### `__init__(model, provider=None, api_key=None, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `model` (str): ëª¨ë¸ ì´ë¦„ (ì˜ˆ: "gpt-4", "claude-3-opus", "gemini-pro")
- `provider` (str, optional): Provider ì´ë¦„. ìƒëµ ì‹œ ëª¨ë¸ëª…ì—ì„œ ìë™ ê°ì§€
- `api_key` (str, optional): API í‚¤. ìƒëµ ì‹œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
- `**kwargs`: Providerë³„ ì¶”ê°€ ì„¤ì •

**ì˜ˆì œ:**
```python
from beanllm import ClientFacade

# OpenAI
client = ClientFacade(model="gpt-4")

# Anthropic (provider ìë™ ê°ì§€)
client = ClientFacade(model="claude-3-opus-20240229")

# ëª…ì‹œì  provider ì§€ì •
client = ClientFacade(model="gpt-4", provider="openai")
```

#### `chat(messages, system=None, temperature=None, max_tokens=None, **kwargs)` (async)

ì±„íŒ… ì™„ë£Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `messages` (List[Dict[str, str]]): ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ `[{"role": "user", "content": "..."}]`
- `system` (str, optional): ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
- `temperature` (float, optional): ìƒ˜í”Œë§ ì˜¨ë„ (0.0-2.0)
- `max_tokens` (int, optional): ìµœëŒ€ ìƒì„± í† í° ìˆ˜
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `ChatResponse`

**ì˜ˆì œ:**
```python
response = await client.chat(
    messages=[{"role": "user", "content": "Hello!"}],
    temperature=0.7,
    max_tokens=1000
)
print(response.content)
```

#### `stream(messages, **kwargs)` (async)

ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì±„íŒ… ì™„ë£Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:** `chat()`ì™€ ë™ì¼

**ë°˜í™˜:** `AsyncIterator[str]`

**ì˜ˆì œ:**
```python
async for chunk in client.stream(messages=[{"role": "user", "content": "Tell me a story"}]):
    print(chunk, end="", flush=True)
```

---

### RAGFacade

RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ. ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

#### `__init__(model, vector_store=None, embedding_model=None, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `model` (str): LLM ëª¨ë¸ ì´ë¦„
- `vector_store` (str, optional): ë²¡í„° ì €ì¥ì†Œ ("chroma", "faiss", "pinecone" ë“±)
- `embedding_model` (str, optional): ì„ë² ë”© ëª¨ë¸ ì´ë¦„
- `**kwargs`: ì¶”ê°€ ì„¤ì •

**ì˜ˆì œ:**
```python
from beanllm import RAGFacade

rag = RAGFacade(
    model="gpt-4",
    vector_store="chroma",
    embedding_model="text-embedding-3-small"
)
```

#### `add_documents(documents)` (async)

ë¬¸ì„œë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `documents` (List[str] | List[Document]): ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

**ì˜ˆì œ:**
```python
documents = [
    "Python is a programming language.",
    "Machine learning is a subset of AI.",
]
await rag.add_documents(documents)
```

#### `query(question, top_k=3, **kwargs)` (async)

ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `question` (str): ì§ˆë¬¸
- `top_k` (int): ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `RAGResponse`

**ì˜ˆì œ:**
```python
response = await rag.query(
    question="What is Python?",
    top_k=3
)
print(response.answer)
print(response.sources)  # ì‚¬ìš©ëœ ë¬¸ì„œë“¤
```

---

### AgentFacade

ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì—ì´ì „íŠ¸.

#### `__init__(model, tools=None, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `model` (str): LLM ëª¨ë¸ ì´ë¦„
- `tools` (List[Tool], optional): ì‚¬ìš©í•  ë„êµ¬ ë¦¬ìŠ¤íŠ¸
- `**kwargs`: ì¶”ê°€ ì„¤ì •

**ì˜ˆì œ:**
```python
from beanllm import AgentFacade
from beanllm.domain.tools import Calculator, WebSearch

agent = AgentFacade(
    model="gpt-4",
    tools=[Calculator(), WebSearch()]
)
```

#### `run(task, max_iterations=10, **kwargs)` (async)

ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `task` (str): ìˆ˜í–‰í•  ì‘ì—…
- `max_iterations` (int): ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `AgentResponse`

**ì˜ˆì œ:**
```python
response = await agent.run(
    task="Calculate 123 * 456 and search for the result online",
    max_iterations=5
)
print(response.final_answer)
print(response.steps)  # ì‹¤í–‰ ë‹¨ê³„
```

---

### ChainFacade

ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì²´ì¸.

#### `__init__(steps=None, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `steps` (List[Callable], optional): ì‹¤í–‰í•  ë‹¨ê³„ë“¤
- `**kwargs`: ì¶”ê°€ ì„¤ì •

#### `add_step(step, name=None)`

ì²´ì¸ì— ë‹¨ê³„ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `step` (Callable): ì‹¤í–‰í•  í•¨ìˆ˜
- `name` (str, optional): ë‹¨ê³„ ì´ë¦„

#### `run(input_data, **kwargs)` (async)

ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `input_data` (Any): ì…ë ¥ ë°ì´í„°
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `ChainResponse`

**ì˜ˆì œ:**
```python
from beanllm import ChainFacade

chain = ChainFacade()
chain.add_step(lambda x: x.upper(), name="uppercase")
chain.add_step(lambda x: x + "!", name="add_exclamation")

response = await chain.run("hello")
print(response.result)  # "HELLO!"
```

---

## Advanced Features

### MultiAgentFacade

ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•˜ëŠ” ì‹œìŠ¤í…œ.

#### `__init__(agents=None, strategy="sequential", **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `agents` (List[Agent], optional): ì—ì´ì „íŠ¸ ë¦¬ìŠ¤íŠ¸
- `strategy` (str): í˜‘ì—… ì „ëµ ("sequential", "parallel", "debate")
- `**kwargs`: ì¶”ê°€ ì„¤ì •

#### `run(task, **kwargs)` (async)

ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

**ë°˜í™˜:** `MultiAgentResponse`

**ì˜ˆì œ:**
```python
from beanllm import MultiAgentFacade, AgentFacade

researcher = AgentFacade(model="gpt-4", name="Researcher")
writer = AgentFacade(model="gpt-4", name="Writer")

multi_agent = MultiAgentFacade(
    agents=[researcher, writer],
    strategy="sequential"
)

response = await multi_agent.run("Research AI trends and write a summary")
```

---

### GraphFacade

ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°.

#### `add_node(node, name)`

ê·¸ë˜í”„ì— ë…¸ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `add_edge(from_node, to_node, condition=None)`

ë…¸ë“œ ê°„ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `run(initial_state, **kwargs)` (async)

ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

---

### StateGraphFacade

ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ ì‹¤í–‰ ì‹œìŠ¤í…œ.

#### `__init__(state_schema=None, **kwargs)`

**íŒŒë¼ë¯¸í„°:**
- `state_schema` (Dict, optional): ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì •ì˜

#### `add_node(name, function)`

ìƒíƒœ ê·¸ë˜í”„ì— ë…¸ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `set_entry_point(node_name)`

ì§„ì…ì ì„ ì„¤ì •í•©ë‹ˆë‹¤.

#### `add_conditional_edges(source, condition_fn, mapping)`

ì¡°ê±´ë¶€ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

#### `run(initial_state, **kwargs)` (async)

ìƒíƒœ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

**ì˜ˆì œ:**
```python
from beanllm import StateGraphFacade

graph = StateGraphFacade(state_schema={"count": 0, "message": ""})

def increment(state):
    state["count"] += 1
    return state

graph.add_node("increment", increment)
graph.set_entry_point("increment")

result = await graph.run({"count": 0, "message": "start"})
```

---

### AudioFacade

ìŒì„± ì²˜ë¦¬ (STT, TTS).

#### `transcribe(audio_file, **kwargs)` (async)

ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (Speech-to-Text).

**íŒŒë¼ë¯¸í„°:**
- `audio_file` (str | bytes): ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë°”ì´íŠ¸
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** `AudioResponse`

**ì˜ˆì œ:**
```python
from beanllm import AudioFacade

audio = AudioFacade(model="whisper-1")
response = await audio.transcribe("speech.mp3")
print(response.text)
```

#### `synthesize(text, voice="alloy", **kwargs)` (async)

í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (Text-to-Speech).

**íŒŒë¼ë¯¸í„°:**
- `text` (str): ë³€í™˜í•  í…ìŠ¤íŠ¸
- `voice` (str): ìŒì„± ì¢…ë¥˜
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

**ë°˜í™˜:** ì˜¤ë””ì˜¤ ë°”ì´íŠ¸

---

## Specialized Features

### VisionRAGFacade

ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ê¸°ë°˜ RAG.

#### `add_images(image_paths)` (async)

ì´ë¯¸ì§€ë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€í•©ë‹ˆë‹¤.

#### `query(question, image_context=True, **kwargs)` (async)

ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ì§ˆì˜í•©ë‹ˆë‹¤.

---

### WebSearchFacade

ì›¹ ê²€ìƒ‰ í†µí•©.

#### `search(query, num_results=5, **kwargs)` (async)

ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `query` (str): ê²€ìƒ‰ ì¿¼ë¦¬
- `num_results` (int): ê²°ê³¼ ìˆ˜

**ì˜ˆì œ:**
```python
from beanllm import WebSearchFacade

search = WebSearchFacade(engine="google")
results = await search.search("latest AI news", num_results=5)
```

---

### EvaluationFacade

LLM í‰ê°€ ë° ë©”íŠ¸ë¦­.

#### `evaluate(predictions, references, metrics=None, **kwargs)` (async)

ëª¨ë¸ ì¶œë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `predictions` (List[str]): ì˜ˆì¸¡ ê²°ê³¼
- `references` (List[str]): ì •ë‹µ ì°¸ì¡°
- `metrics` (List[str], optional): ì‚¬ìš©í•  ë©”íŠ¸ë¦­ ("bleu", "rouge", etc.)

**ë°˜í™˜:** `EvaluationResponse`

**ì˜ˆì œ:**
```python
from beanllm import EvaluationFacade

evaluator = EvaluationFacade()
results = await evaluator.evaluate(
    predictions=["The cat sat on the mat"],
    references=["A cat was sitting on the mat"],
    metrics=["bleu", "rouge"]
)
print(results.scores)
```

---

### FinetuningFacade

ëª¨ë¸ íŒŒì¸íŠœë‹.

#### `create_job(training_data, model, **kwargs)` (async)

íŒŒì¸íŠœë‹ ì‘ì—…ì„ ìƒì„±í•©ë‹ˆë‹¤.

**íŒŒë¼ë¯¸í„°:**
- `training_data` (str | List): í›ˆë ¨ ë°ì´í„° íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë°ì´í„°
- `model` (str): ê¸°ë³¸ ëª¨ë¸
- `**kwargs`: ì¶”ê°€ íŒŒë¼ë¯¸í„°

#### `check_status(job_id)` (async)

íŒŒì¸íŠœë‹ ì‘ì—… ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

**ì˜ˆì œ:**
```python
from beanllm import FinetuningFacade

finetuner = FinetuningFacade(provider="openai")
job = await finetuner.create_job(
    training_data="training.jsonl",
    model="gpt-3.5-turbo"
)
status = await finetuner.check_status(job.id)
```

---

## Common Types

### Response Objects

All facade methods return specific response objects:

- `ChatResponse` - Chat completion response
- `RAGResponse` - RAG query response
- `AgentResponse` - Agent execution response
- `AudioResponse` - Audio processing response
- `EvaluationResponse` - Evaluation results
- etc.

### Common Parameters

Most facades support these common parameters:

- `model` (str): Model name (e.g., "gpt-4", "claude-3-opus")
- `temperature` (float): Sampling temperature (0.0 - 2.0)
- `max_tokens` (int): Maximum tokens to generate
- `stream` (bool): Enable streaming responses

---

## Error Handling

```python
from beanllm import ClientFacade
from beanllm.utils.exceptions import BeanLLMError

try:
    client = ClientFacade(model="gpt-4")
    response = client.chat("Hello")
except BeanLLMError as e:
    print(f"Error: {e}")
```

---

## Environment Variables

beanllm uses environment variables for API keys:

```bash
# OpenAI
export OPENAI_API_KEY="your-key"

# Anthropic
export ANTHROPIC_API_KEY="your-key"

# Google
export GOOGLE_API_KEY="your-key"

# Or use .env file
```

---

## Additional Resources

- [GitHub Repository](https://github.com/leebeanbin/beanllm)
- [PyPI Package](https://pypi.org/project/beanllm/)
- [Examples](../examples/)
- [Architecture Guide](../ARCHITECTURE.md)

---

**Last Updated:** 2025-12-28
**Version:** 0.1.1
