# /test-gen - Test Generation

**íŠ¸ë¦¬ê±°**: `/test-gen`
**ëª¨ë¸**: sonnet
**ì„¤ëª…**: TDD ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ìë™ ìƒì„±

## Command Description

ì½”ë“œì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸, E2E í…ŒìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. 80% ì»¤ë²„ë¦¬ì§€ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

## Usage

```
/test-gen
/test-gen --path src/beanllm/facade/core/client_facade.py
/test-gen --type unit
/test-gen --coverage-goal 90
```

## Options

- `--path`: í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: í˜„ì¬ íŒŒì¼)
- `--type`: í…ŒìŠ¤íŠ¸ íƒ€ì… (`unit`, `integration`, `e2e`, `all`) (ê¸°ë³¸: `unit`)
- `--coverage-goal`: ëª©í‘œ ì»¤ë²„ë¦¬ì§€ (ê¸°ë³¸: 80%)
- `--fixtures`: pytest fixtures ìë™ ìƒì„±

## Execution Steps

### 1. ì½”ë“œ ë¶„ì„

```python
import ast
from pathlib import Path

def analyze_code(file_path: str):
    """ì½”ë“œì—ì„œ í…ŒìŠ¤íŠ¸í•  í•¨ìˆ˜/ë©”ì„œë“œ ì¶”ì¶œ"""
    with open(file_path) as f:
        tree = ast.parse(f.read())

    functions = []
    classes = []

    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            functions.append({
                "name": node.name,
                "args": [arg.arg for arg in node.args.args],
                "returns": ast.unparse(node.returns) if node.returns else None,
                "is_async": False,
            })
        elif isinstance(node, ast.AsyncFunctionDef):
            functions.append({
                "name": node.name,
                "args": [arg.arg for arg in node.args.args],
                "returns": ast.unparse(node.returns) if node.returns else None,
                "is_async": True,
            })
        elif isinstance(node, ast.ClassDef):
            classes.append({
                "name": node.name,
                "methods": [m.name for m in node.body if isinstance(m, (ast.FunctionDef, ast.AsyncFunctionDef))],
            })

    return {"functions": functions, "classes": classes}

# ì‹¤í–‰
result = analyze_code("src/beanllm/facade/core/client_facade.py")
print(f"Found {len(result['functions'])} functions, {len(result['classes'])} classes")
```

### 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±

```python
# ì˜ˆ: Client.chat() ë©”ì„œë“œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ìƒì„±

# Before ë¶„ì„
class Client:
    async def chat(
        self,
        messages: List[Dict[str, str]],
        model: str = "gpt-4o",
        temperature: float = 0.7
    ) -> ChatResponse:
        """LLMê³¼ ëŒ€í™”í•©ë‹ˆë‹¤."""
        if not messages:
            raise ValueError("messagesëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        return await self._handler.handle_chat(...)

# After í…ŒìŠ¤íŠ¸ ìƒì„±
import pytest
from unittest.mock import AsyncMock, Mock
from beanllm import Client
from beanllm.dto.response.core.chat_response import ChatResponse

class TestClient:
    """Client í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    async def client(self):
        """Client ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        client = Client(model="gpt-4o")
        yield client
        await client.close()

    @pytest.fixture
    def chat_messages(self):
        """í…ŒìŠ¤íŠ¸ìš© ë©”ì‹œì§€"""
        return [{"role": "user", "content": "Hello"}]

    # 1. ì •ìƒ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
    @pytest.mark.asyncio
    async def test_chat_returns_valid_response_when_given_valid_messages(
        self, client, chat_messages
    ):
        """ìœ íš¨í•œ ë©”ì‹œì§€ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤"""
        # Arrange
        # (fixturesë¡œ ì´ë¯¸ ì¤€ë¹„ë¨)

        # Act
        response = await client.chat(messages=chat_messages)

        # Assert
        assert isinstance(response, ChatResponse)
        assert response.content is not None
        assert len(response.content) > 0
        assert response.model == "gpt-4o"
        assert response.usage is not None

    # 2. ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
    @pytest.mark.asyncio
    async def test_chat_raises_value_error_when_messages_empty(self, client):
        """ë¹ˆ ë©”ì‹œì§€ ëª©ë¡ì´ ì£¼ì–´ì¡Œì„ ë•Œ ValueErrorë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤"""
        with pytest.raises(ValueError, match="messagesëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"):
            await client.chat(messages=[])

    # 3. íŒŒë¼ë¯¸í„° ë³€í˜• í…ŒìŠ¤íŠ¸
    @pytest.mark.asyncio
    @pytest.mark.parametrize("temperature", [0.0, 0.5, 1.0, 2.0])
    async def test_chat_accepts_various_temperatures(
        self, client, chat_messages, temperature
    ):
        """ë‹¤ì–‘í•œ temperature ê°’ì„ í—ˆìš©í•©ë‹ˆë‹¤"""
        response = await client.chat(
            messages=chat_messages,
            temperature=temperature
        )
        assert isinstance(response, ChatResponse)

    # 4. ëª¨ë¸ ë³€í˜• í…ŒìŠ¤íŠ¸
    @pytest.mark.asyncio
    @pytest.mark.parametrize("model", [
        "gpt-4o",
        "claude-sonnet-4-20250514",
        "gemini-2.5-pro",
    ])
    async def test_chat_works_with_different_models(
        self, chat_messages, model
    ):
        """ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤"""
        client = Client(model=model)
        response = await client.chat(messages=chat_messages)
        assert response.model == model
        await client.close()

    # 5. ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    @pytest.mark.asyncio
    async def test_chat_handles_api_error_gracefully(self, client, chat_messages):
        """API ì—ëŸ¬ê°€ ë°œìƒí–ˆì„ ë•Œ ì ì ˆíˆ ì²˜ë¦¬í•©ë‹ˆë‹¤"""
        # Mock handler to raise API error
        client._handler.handle_chat = AsyncMock(
            side_effect=APIError("Rate limit exceeded")
        )

        with pytest.raises(APIError, match="Rate limit exceeded"):
            await client.chat(messages=chat_messages)

    # 6. ì¬ì‹œë„ í…ŒìŠ¤íŠ¸
    @pytest.mark.asyncio
    async def test_chat_retries_on_rate_limit_error(self, client, chat_messages):
        """Rate limit ì—ëŸ¬ ì‹œ ì¬ì‹œë„í•©ë‹ˆë‹¤"""
        # First call: rate limit error
        # Second call: success
        client._handler.handle_chat = AsyncMock(
            side_effect=[
                RateLimitError("Rate limit exceeded"),
                ChatResponse(content="Hello!", model="gpt-4o")
            ]
        )

        response = await client.chat(messages=chat_messages)
        assert response.content == "Hello!"
        assert client._handler.handle_chat.call_count == 2
```

### 3. í†µí•© í…ŒìŠ¤íŠ¸ ìƒì„±

```python
# Integration Tests
@pytest.mark.integration
class TestClientIntegration:
    """Client í†µí•© í…ŒìŠ¤íŠ¸ (ì‹¤ì œ Provider ì‚¬ìš©)"""

    @pytest.mark.asyncio
    async def test_chat_with_ollama(self):
        """Ollama Providerì™€ í†µí•© í…ŒìŠ¤íŠ¸"""
        # Ollamaê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨
        client = Client(model="qwen2.5:0.5b")
        response = await client.chat([
            {"role": "user", "content": "Hello"}
        ])

        assert response.content is not None
        assert len(response.content) > 0
        await client.close()

    @pytest.mark.asyncio
    @pytest.mark.requires_api_key
    async def test_chat_with_openai(self):
        """OpenAI Providerì™€ í†µí•© í…ŒìŠ¤íŠ¸"""
        client = Client(model="gpt-4o-mini")
        response = await client.chat([
            {"role": "user", "content": "Say 'test' only"}
        ])

        assert "test" in response.content.lower()
        await client.close()
```

### 4. E2E í…ŒìŠ¤íŠ¸ ìƒì„±

```python
# End-to-End Tests
@pytest.mark.e2e
class TestClientE2E:
    """Client E2E í…ŒìŠ¤íŠ¸ (ì „ì²´ í”Œë¡œìš°)"""

    @pytest.mark.asyncio
    async def test_full_conversation_flow(self):
        """ì „ì²´ ëŒ€í™” í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        client = Client(model="qwen2.5:0.5b")

        # 1. ì²« ë²ˆì§¸ ë©”ì‹œì§€
        response1 = await client.chat([
            {"role": "user", "content": "My name is Alice"}
        ])
        assert response1.content is not None

        # 2. ëŒ€í™” ì´ì–´ê°€ê¸°
        response2 = await client.chat([
            {"role": "user", "content": "My name is Alice"},
            {"role": "assistant", "content": response1.content},
            {"role": "user", "content": "What is my name?"}
        ])
        assert "alice" in response2.content.lower()

        await client.close()
```

## Output Format

```
=================================================
ğŸ§ª Test Generation Report
=================================================

ğŸ“‹ Summary:
  Target file: src/beanllm/facade/core/client_facade.py
  Classes found: 1 (Client)
  Methods found: 8 (chat, stream_chat, ...)
  Tests generated: 42
  Coverage estimate: 87%

=================================================
ğŸ“ Generated Test Files
=================================================

1. tests/facade/core/test_client_facade.py
   - Unit tests: 24
   - Integration tests: 12
   - E2E tests: 6
   - Fixtures: 5

2. tests/conftest.py (updated)
   - Added fixtures: 3

=================================================
âœ… Test Cases Generated
=================================================

Unit Tests (24):
  âœ… test_chat_returns_valid_response_when_given_valid_messages
  âœ… test_chat_raises_value_error_when_messages_empty
  âœ… test_chat_accepts_various_temperatures
  âœ… test_chat_works_with_different_models
  âœ… test_chat_handles_api_error_gracefully
  âœ… test_chat_retries_on_rate_limit_error
  ...

Integration Tests (12):
  âœ… test_chat_with_ollama
  âœ… test_chat_with_openai
  âœ… test_chat_with_anthropic
  ...

E2E Tests (6):
  âœ… test_full_conversation_flow
  âœ… test_multimodal_chat_with_images
  ...

=================================================
ğŸ“Š Coverage Analysis
=================================================

Current coverage: 61%
After adding tests: 87% (estimated)
Goal: 80%

Status: âœ… GOAL ACHIEVED

Uncovered lines:
  - src/beanllm/facade/core/client_facade.py:156-162 (error handling)
  - src/beanllm/facade/core/client_facade.py:203-208 (cleanup)

Recommendation:
  Add tests for error handling and cleanup logic to reach 90%

=================================================
ğŸš€ Next Steps
=================================================

1. Review generated tests: tests/facade/core/test_client_facade.py
2. Run tests: pytest tests/facade/core/test_client_facade.py -v
3. Check coverage: pytest --cov=src/beanllm/facade/core/client_facade.py
4. Add missing tests for uncovered lines
5. Update documentation if needed
```

## Pytest Commands

```bash
# ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/facade/core/test_client_facade.py -v

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
pytest tests/facade/core/test_client_facade.py \
  --cov=src/beanllm/facade/core/client_facade.py \
  --cov-report=html

# íŠ¹ì • ë§ˆì»¤ë§Œ ì‹¤í–‰
pytest -m unit  # Unit tests only
pytest -m "integration and not requires_api_key"
```

## Related Commands

- `/tdd` - TDD ì›Œí¬í”Œë¡œìš° ì‹œì‘
- `/test-run` - í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ì»¤ë²„ë¦¬ì§€ í™•ì¸

## Related Documents

- `.claude/rules/testing.md` - í…ŒìŠ¤íŠ¸ ê·œì¹™
- `pyproject.toml` - pytest ì„¤ì •
- `CLAUDE.md` - í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸
