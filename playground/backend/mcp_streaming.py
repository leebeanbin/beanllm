"""
Chat Streaming with Tool Calls - SSE endpoint for real-time progress

ê¸°ì¡´ beanllm ì½”ë“œë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ Tool Call ì§„í–‰ ìƒí™©ì„ SSEë¡œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
MCP Serverê°€ ì•„ë‹Œ beanllm Facade/Handlerë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
"""
import asyncio
import json
import logging
from typing import AsyncGenerator, Dict, Any, List, Optional
from pathlib import Path
from fastapi import HTTPException
from pydantic import BaseModel

# âœ… ê¸°ì¡´ beanllm ì½”ë“œ ì§ì ‘ ì‚¬ìš© (MCP Server íŒ¨í„´ê³¼ ë™ì¼)
from beanllm.facade.core import Client, RAGChain
from beanllm.domain.loaders import DirectoryLoader, PDFLoader, TextLoader, CSVLoader
from beanllm.handler.core import ChatHandler, RAGHandler, AgentHandler
from beanllm.handler.advanced import MultiAgentHandler

# âœ… Kafka ì´ë²¤íŠ¸ ë¡œê±° (ë¶„ì‚° ëª¨ë‹ˆí„°ë§)
try:
    from beanllm.infrastructure.distributed import get_event_logger
    event_logger = get_event_logger()
except ImportError:
    event_logger = None

# âœ… Redis ìºì‹œ (ë¶„ì‚° ìºì‹±)
try:
    from beanllm.infrastructure.distributed.redis.client import get_redis_client
    redis_client = get_redis_client()
except ImportError:
    redis_client = None

logger = logging.getLogger(__name__)

# âœ… RAG ì¸ìŠ¤í„´ìŠ¤ ìºì‹œ (MCP Server íŒ¨í„´ê³¼ ë™ì¼)
_rag_instances: Dict[str, RAGChain] = {}


class MCPChatRequest(BaseModel):
    """MCP Chat ìš”ì²­"""
    messages: List[Dict[str, str]]
    model: str = "qwen2.5:0.5b"
    temperature: float = 0.7
    max_tokens: int = 1000


class MCPStreamingClient:
    """MCP ì„œë²„ì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, mcp_server_url: str = "http://localhost:8765"):
        self.mcp_server_url = mcp_server_url

    async def detect_and_call_tools(
        self,
        query: str,
        context: Dict[str, Any]
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ì‚¬ìš©ì ì§ˆì˜ì—ì„œ Tool Callì„ ê°ì§€í•˜ê³  ì‹¤í–‰

        Args:
            query: ì‚¬ìš©ì ì§ˆì˜
            context: ì»¨í…ìŠ¤íŠ¸ (ëª¨ë¸, íŒŒë¼ë¯¸í„° ë“±)

        Yields:
            Dict: SSE ì´ë²¤íŠ¸ ë°ì´í„°
                - type: "tool_call", "tool_progress", "tool_result", "text", "done"
                - data: ì´ë²¤íŠ¸ ë°ì´í„°
        """
        # 1. ì§ˆì˜ì—ì„œ Tool Call ê°ì§€ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        tool_calls = await self._detect_tools(query)

        if not tool_calls:
            # Tool Call ì—†ìœ¼ë©´ ì¼ë°˜ chat ì‘ë‹µ
            yield {
                "type": "text",
                "data": {
                    "content": "Tool callì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë°˜ ì±„íŒ… ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤."
                }
            }
            return

        # 2. ê°ì§€ëœ Tool Call ì‹¤í–‰
        for tool_call in tool_calls:
            # Tool call ì‹œì‘ ì•Œë¦¼
            yield {
                "type": "tool_call",
                "data": {
                    "tool": tool_call["name"],
                    "arguments": tool_call["arguments"],
                    "status": "started"
                }
            }

            # Tool ì‹¤í–‰ (ì‹¤ì œë¡œëŠ” MCP ì„œë²„ì™€ í†µì‹ )
            try:
                async for progress in self._execute_tool(tool_call):
                    yield progress

                # Tool call ì™„ë£Œ
                yield {
                    "type": "tool_result",
                    "data": {
                        "tool": tool_call["name"],
                        "result": progress.get("data", {}),
                        "status": "completed"
                    }
                }

            except Exception as e:
                logger.error(f"Tool execution failed: {e}")
                yield {
                    "type": "tool_result",
                    "data": {
                        "tool": tool_call["name"],
                        "error": str(e),
                        "status": "failed"
                    }
                }

        # 3. ì™„ë£Œ
        yield {
            "type": "done",
            "data": {
                "message": "All tools executed"
            }
        }

    async def _detect_tools(self, query: str) -> List[Dict[str, Any]]:
        """
        ì§ˆì˜ì—ì„œ Tool Call ê°ì§€ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)

        ë‚˜ì¤‘ì—ëŠ” LLMì´ íŒë‹¨í•˜ë„ë¡ ê°œì„ í•  ìˆ˜ ìˆìŒ
        """
        query_lower = query.lower()
        tool_calls = []

        # RAG ê´€ë ¨ í‚¤ì›Œë“œ
        if any(keyword in query_lower for keyword in ["rag", "ê²€ìƒ‰", "ë¬¸ì„œ", "pdf"]):
            # RAG ì‹œìŠ¤í…œ êµ¬ì¶• ê°ì§€
            if any(keyword in query_lower for keyword in ["ë§Œë“¤", "êµ¬ì¶•", "ìƒì„±", "build"]):
                # ë¬¸ì„œ ê²½ë¡œ ì¶”ì¶œ (ê°„ë‹¨í•œ ì •ê·œí‘œí˜„ì‹)
                import re
                path_match = re.search(r'(/[\w/.-]+)', query)
                doc_path = path_match.group(1) if path_match else "./docs"

                tool_calls.append({
                    "name": "build_rag_system",
                    "arguments": {
                        "documents_path": doc_path,
                        "collection_name": "default"
                    }
                })

            # RAG ì§ˆì˜ ê°ì§€
            elif any(keyword in query_lower for keyword in ["ë­", "ë¬´ì—‡", "ì•Œë ¤", "ì„¤ëª…", "?", "?"]):
                tool_calls.append({
                    "name": "query_rag_system",
                    "arguments": {
                        "query": query,
                        "collection_name": "default"
                    }
                })

        # Multi-Agent ê´€ë ¨ í‚¤ì›Œë“œ
        elif any(keyword in query_lower for keyword in ["ì—ì´ì „íŠ¸", "í† ë¡ ", "í˜‘ì—…", "agent", "debate"]):
            # í† ë¡  ì£¼ì œ ì¶”ì¶œ
            import re
            topic_match = re.search(r'["\'](.+?)["\']', query)
            topic = topic_match.group(1) if topic_match else query

            tool_calls.append({
                "name": "create_multiagent_system",
                "arguments": {
                    "system_name": "debate_team",
                    "agent_configs": [
                        {"name": "researcher", "role": "Research specialist"},
                        {"name": "writer", "role": "Writing specialist"},
                        {"name": "critic", "role": "Critical reviewer"}
                    ],
                    "strategy": "debate"
                }
            })

            tool_calls.append({
                "name": "run_multiagent_task",
                "arguments": {
                    "system_name": "debate_team",
                    "task": topic
                }
            })

        # Knowledge Graph ê´€ë ¨ í‚¤ì›Œë“œ
        elif any(keyword in query_lower for keyword in ["ì§€ì‹ ê·¸ë˜í”„", "knowledge graph", "kg", "ê·¸ë˜í”„"]):
            import re
            path_match = re.search(r'(/[\w/.-]+)', query)
            doc_path = path_match.group(1) if path_match else "./docs"

            tool_calls.append({
                "name": "build_knowledge_graph",
                "arguments": {
                    "documents_path": doc_path,
                    "graph_name": "default"
                }
            })

        # Audio ê´€ë ¨ í‚¤ì›Œë“œ
        elif any(keyword in query_lower for keyword in ["ìŒì„±", "ì „ì‚¬", "audio", "transcribe"]):
            import re
            path_match = re.search(r'(/[\w/.-]+\.(?:mp3|wav|m4a))', query)
            audio_path = path_match.group(1) if path_match else "./audio.mp3"

            tool_calls.append({
                "name": "transcribe_audio",
                "arguments": {
                    "audio_path": audio_path,
                    "engine": "whisper"
                }
            })

        # OCR ê´€ë ¨ í‚¤ì›Œë“œ
        elif any(keyword in query_lower for keyword in ["ocr", "í…ìŠ¤íŠ¸ ì¶”ì¶œ", "ì´ë¯¸ì§€", "ì¸ì‹"]):
            import re
            path_match = re.search(r'(/[\w/.-]+\.(?:png|jpg|jpeg))', query)
            image_path = path_match.group(1) if path_match else "./image.png"

            tool_calls.append({
                "name": "recognize_text_ocr",
                "arguments": {
                    "image_path": image_path,
                    "engine": "tesseract"
                }
            })

        return tool_calls

    async def _execute_tool(
        self,
        tool_call: Dict[str, Any]
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        Tool ì‹¤í–‰ (âœ… ê¸°ì¡´ beanllm ì½”ë“œ ì§ì ‘ ì‚¬ìš©)

        MCP Serverê°€ ì•„ë‹Œ beanllm Facade/Handlerë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
        """
        tool_name = tool_call["name"]
        arguments = tool_call["arguments"]

        # âœ… ì‹¤ì œ beanllm ì½”ë“œ ì‹¤í–‰
        if tool_name == "build_rag_system":
            # âœ… Kafka ì´ë²¤íŠ¸ ë°œí–‰ (Tool Call ì‹œì‘)
            if event_logger:
                await event_logger.log_event(
                    event_type="tool_call.started",
                    event_data={
                        "tool": tool_name,
                        "arguments": arguments,
                        "timestamp": asyncio.get_event_loop().time(),
                    }
                )

            # ì§„í–‰ ìƒí™©: ë¬¸ì„œ ë¡œë“œ
            yield {
                "type": "tool_progress",
                "data": {
                    "tool": tool_name,
                    "step": "loading_documents",
                    "message": "ë¬¸ì„œ ë¡œë“œ ì¤‘...",
                    "progress": 0.2
                }
            }

            # ğŸ¯ ê¸°ì¡´ beanllm ì½”ë“œ ì‚¬ìš© (MCP Server íŒ¨í„´ê³¼ ë™ì¼)
            try:
                collection_name = arguments.get("collection_name", "default")

                # âœ… Redis ìºì‹œ í™•ì¸ (ì´ë¯¸ êµ¬ì¶•ëœ ì»¬ë ‰ì…˜ì¸ì§€ í™•ì¸)
                if redis_client:
                    cache_key = f"rag:collection:{collection_name}"
                    cached = await asyncio.to_thread(redis_client.get, cache_key)
                    if cached and collection_name in _rag_instances:
                        logger.info(f"âœ… RAG collection '{collection_name}' already exists (Redis cache hit)")
                        # ì´ë¯¸ êµ¬ì¶•ëœ ì»¬ë ‰ì…˜ì´ë©´ ìºì‹œëœ ë©”íƒ€ë°ì´í„° ë°˜í™˜
                        import json
                        cached_data = json.loads(cached)
                        yield {
                            "type": "tool_result",
                            "data": {
                                "tool": tool_name,
                                "result": {
                                    **cached_data,
                                    "cached": True,
                                },
                                "status": "completed"
                            }
                        }
                        return

                path = Path(arguments["documents_path"])

                # 1. ë¬¸ì„œ ë¡œë“œ
                if path.is_dir():
                    loader = DirectoryLoader(str(path))
                elif path.suffix == ".pdf":
                    loader = PDFLoader(str(path))
                elif path.suffix in [".txt", ".md"]:
                    loader = TextLoader(str(path))
                elif path.suffix == ".csv":
                    loader = CSVLoader(str(path))
                else:
                    raise ValueError(f"Unsupported file type: {path.suffix}")

                documents = await asyncio.to_thread(loader.load)

                # ì§„í–‰ ìƒí™©: ì„ë² ë”© ìƒì„±
                yield {
                    "type": "tool_progress",
                    "data": {
                        "tool": tool_name,
                        "step": "creating_embeddings",
                        "message": f"ì„ë² ë”© ìƒì„± ì¤‘... ({len(documents)}ê°œ ë¬¸ì„œ)",
                        "progress": 0.5
                    }
                }

                # 2. RAG êµ¬ì¶•
                rag = await asyncio.to_thread(
                    RAGChain.from_documents,
                    documents=documents,
                    collection_name=arguments.get("collection_name", "default"),
                    chunk_size=arguments.get("chunk_size", 1000),
                    chunk_overlap=arguments.get("chunk_overlap", 200),
                    embedding_model=arguments.get("embedding_model", "mxbai-embed-large:335m"),
                )

                # ì§„í–‰ ìƒí™©: ì¸ë±ìŠ¤ êµ¬ì¶•
                yield {
                    "type": "tool_progress",
                    "data": {
                        "tool": tool_name,
                        "step": "building_index",
                        "message": "ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...",
                        "progress": 0.8
                    }
                }

                # 3. ìºì‹œì— ì €ì¥ (ë©”ëª¨ë¦¬ + Redis)
                _rag_instances[collection_name] = rag

                # 4. ì²­í¬ ìˆ˜ ê³„ì‚°
                chunk_count = len(rag._vector_store._collection.get()["ids"])

                result_data = {
                    "success": True,
                    "collection_name": collection_name,
                    "document_count": len(documents),
                    "chunk_count": chunk_count,
                    "embedding_model": arguments.get("embedding_model", "mxbai-embed-large:335m"),
                }

                # âœ… Redisì— ë©”íƒ€ë°ì´í„° ì €ì¥ (ë¶„ì‚° ìºì‹±)
                if redis_client:
                    import json
                    cache_key = f"rag:collection:{collection_name}"
                    await asyncio.to_thread(
                        redis_client.setex,
                        cache_key,
                        3600,  # TTL: 1ì‹œê°„
                        json.dumps(result_data)
                    )
                    logger.info(f"âœ… Saved RAG collection '{collection_name}' to Redis cache")

                # âœ… Kafka ì´ë²¤íŠ¸ ë°œí–‰ (Tool Call ì™„ë£Œ)
                if event_logger:
                    await event_logger.log_event(
                        event_type="tool_call.completed",
                        event_data={
                            "tool": tool_name,
                            "result": result_data,
                            "timestamp": asyncio.get_event_loop().time(),
                        }
                    )

                # ìµœì¢… ê²°ê³¼
                yield {
                    "type": "tool_result",
                    "data": {
                        "tool": tool_name,
                        "result": result_data,
                        "status": "completed"
                    }
                }

            except Exception as e:
                logger.error(f"RAG build failed: {e}")

                # âœ… Kafka ì´ë²¤íŠ¸ ë°œí–‰ (Tool Call ì‹¤íŒ¨)
                if event_logger:
                    await event_logger.log_event(
                        event_type="tool_call.failed",
                        event_data={
                            "tool": tool_name,
                            "error": str(e),
                            "timestamp": asyncio.get_event_loop().time(),
                        }
                    )

                yield {
                    "type": "tool_result",
                    "data": {
                        "tool": tool_name,
                        "error": str(e),
                        "status": "failed"
                    }
                }

        elif tool_name == "query_rag_system":
            # ì§„í–‰ ìƒí™©: ë²¡í„° ê²€ìƒ‰
            yield {
                "type": "tool_progress",
                "data": {
                    "tool": tool_name,
                    "step": "searching",
                    "message": "ë²¡í„° ê²€ìƒ‰ ì¤‘...",
                    "progress": 0.3
                }
            }

            # ğŸ¯ ê¸°ì¡´ beanllm RAGChain ì‚¬ìš©
            try:
                collection_name = arguments.get("collection_name", "default")
                query = arguments.get("query", "")
                top_k = arguments.get("top_k", 5)

                # âœ… ìºì‹œëœ RAG ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                if collection_name not in _rag_instances:
                    raise ValueError(f"RAG collection '{collection_name}' not found. Build it first with build_rag_system.")

                rag = _rag_instances[collection_name]

                # ì§„í–‰ ìƒí™©: ë‹µë³€ ìƒì„±
                yield {
                    "type": "tool_progress",
                    "data": {
                        "tool": tool_name,
                        "step": "generating_answer",
                        "message": "ë‹µë³€ ìƒì„± ì¤‘...",
                        "progress": 0.7
                    }
                }

                # âœ… ì‹¤ì œ RAG ì§ˆì˜ ì‹¤í–‰
                response = await asyncio.to_thread(
                    rag.query,
                    query=query,
                    k=top_k
                )

                # ì†ŒìŠ¤ ë¬¸ì„œ í¬ë§·íŒ…
                sources = [
                    {
                        "rank": i + 1,
                        "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                        "metadata": doc.metadata,
                    }
                    for i, doc in enumerate(response.get("source_documents", []))
                ]

                result = {
                    "success": True,
                    "answer": response.get("answer", ""),
                    "query": query,
                    "collection": collection_name,
                    "sources": sources,
                    "source_count": len(sources),
                }

                # ìµœì¢… ê²°ê³¼
                yield {
                    "type": "tool_result",
                    "data": {
                        "tool": tool_name,
                        "result": result,
                        "status": "completed"
                    }
                }

            except Exception as e:
                logger.error(f"RAG query failed: {e}")
                yield {
                    "type": "tool_result",
                    "data": {
                        "tool": tool_name,
                        "error": str(e),
                        "status": "failed"
                    }
                }

        elif tool_name in ["create_multiagent_system", "run_multiagent_task"]:
            yield {
                "type": "tool_progress",
                "data": {
                    "tool": tool_name,
                    "step": "initializing",
                    "message": "ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘...",
                    "progress": 0.2
                }
            }
            await asyncio.sleep(0.5)

            if tool_name == "run_multiagent_task":
                yield {
                    "type": "tool_progress",
                    "data": {
                        "tool": tool_name,
                        "step": "round_1",
                        "message": "ë¼ìš´ë“œ 1: ê° ì—ì´ì „íŠ¸ ì˜ê²¬ ìˆ˜ì§‘ ì¤‘...",
                        "progress": 0.5
                    }
                }
                await asyncio.sleep(1.0)

                yield {
                    "type": "tool_progress",
                    "data": {
                        "tool": tool_name,
                        "step": "round_2",
                        "message": "ë¼ìš´ë“œ 2: í† ë¡  ì§„í–‰ ì¤‘...",
                        "progress": 0.8
                    }
                }
                await asyncio.sleep(1.0)

        # ê¸°íƒ€ Toolë„ ìœ ì‚¬í•˜ê²Œ êµ¬í˜„...


async def stream_mcp_chat(request: MCPChatRequest) -> AsyncGenerator[str, None]:
    """
    MCP Chat SSE streaming

    Args:
        request: Chat ìš”ì²­

    Yields:
        str: SSE í˜•ì‹ ë¬¸ìì—´ ("data: {...}\n\n")
    """
    client = MCPStreamingClient()

    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
    user_messages = [msg for msg in request.messages if msg["role"] == "user"]
    if not user_messages:
        yield f"data: {json.dumps({'type': 'error', 'data': {'message': 'No user message found'}})}\n\n"
        return

    last_user_message = user_messages[-1]["content"]

    # Tool Call ê°ì§€ ë° ì‹¤í–‰
    try:
        async for event in client.detect_and_call_tools(
            query=last_user_message,
            context={"model": request.model, "temperature": request.temperature}
        ):
            yield f"data: {json.dumps(event)}\n\n"

    except Exception as e:
        logger.error(f"MCP streaming error: {e}")
        yield f"data: {json.dumps({'type': 'error', 'data': {'message': str(e)}})}\n\n"
