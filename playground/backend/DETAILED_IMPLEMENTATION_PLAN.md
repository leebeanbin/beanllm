# Backend API ìˆ˜ì •/êµ¬í˜„ ìƒì„¸ ê³„íš

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” `playground/backend/main.py`ì˜ ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìˆ˜ì •í•˜ê³  êµ¬í˜„í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ìƒì„¸ ê³„íšì…ë‹ˆë‹¤.

**ì´ ì˜ˆìƒ ì‹œê°„**: 4-6ì‹œê°„
**ìš°ì„ ìˆœìœ„**: ë†’ìŒ â†’ ì¤‘ê°„ â†’ ë‚®ìŒ

---

## Phase 1: í•„ìˆ˜ ìˆ˜ì • (ë†’ìŒ ìš°ì„ ìˆœìœ„)

### Task 1.1: RAG Debug API ìˆ˜ì •

**í˜„ì¬ ë¬¸ì œ**:
- `get_rag_debugger()`ê°€ `vector_store` ì—†ì´ `RAGDebug()` ìƒì„± ì‹œë„
- `RAGDebug.__init__()`ëŠ” `vector_store` í•„ìˆ˜ íŒŒë¼ë¯¸í„°

**í•´ê²° ë°©ë²•**:
1. RAG Debug APIì—ì„œ `collection_name`ì„ ë°›ì•„ì„œ í•´ë‹¹ RAG chainì˜ vector_store ì‚¬ìš©
2. ë˜ëŠ” ìš”ì²­ì—ì„œ documentsë¥¼ ë°›ì•„ ì„ì‹œ vector_store ìƒì„±

**êµ¬í˜„ ë‹¨ê³„**:

#### Step 1.1.1: Request Model ìˆ˜ì •
```python
# Line 183-188 ìˆ˜ì •
class RAGDebugRequest(BaseModel):
    query: str
    documents: List[str]
    collection_name: Optional[str] = None  # ì¶”ê°€: ê¸°ì¡´ RAG chain ì‚¬ìš©
    debug_mode: str = "full"
    model: Optional[str] = None
```

#### Step 1.1.2: get_rag_debugger() ìˆ˜ì •
```python
# Line 93-98 ìˆ˜ì •
def get_rag_debugger(vector_store=None) -> RAGDebug:
    """Get or create RAGDebug facade"""
    global _rag_debugger
    if vector_store is None:
        # ê¸°ë³¸ vector_store ìƒì„± (ì„ì‹œ)
        from beanllm.domain.vector_stores import VectorStore
        from beanllm.domain.embeddings import Embedding
        embedding = Embedding(model="text-embedding-3-small")
        vector_store = VectorStore(embedding_function=embedding.embed)
    if _rag_debugger is None or _rag_debugger.vector_store != vector_store:
        _rag_debugger = RAGDebug(vector_store=vector_store)
    return _rag_debugger
```

#### Step 1.1.3: rag_debug_analyze() ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •
```python
# Line 562-592 ìˆ˜ì •
@app.post("/api/rag_debug/analyze")
async def rag_debug_analyze(request: RAGDebugRequest):
    """Analyze RAG pipeline"""
    try:
        # collection_nameì´ ìˆìœ¼ë©´ ê¸°ì¡´ RAG chainì˜ vector_store ì‚¬ìš©
        if request.collection_name and request.collection_name in _rag_chains:
            vector_store = _rag_chains[request.collection_name].vector_store
        else:
            # documentsë¡œë¶€í„° ì„ì‹œ vector_store ìƒì„±
            from beanllm.domain.loaders import Document
            from beanllm.domain.vector_stores import VectorStore
            from beanllm.domain.embeddings import Embedding
            from beanllm.domain.splitters import TextSplitter
            
            # ë¬¸ì„œ ë¡œë”© ë° ë¶„í• 
            docs = [Document(content=doc, metadata={}) for doc in request.documents]
            chunks = TextSplitter.split(docs, chunk_size=500, chunk_overlap=50)
            
            # ì„ì‹œ vector_store ìƒì„±
            embedding = Embedding(model=request.model or "text-embedding-3-small")
            vector_store = VectorStore(embedding_function=embedding.embed)
            vector_store.add_documents(chunks)
        
        debugger = get_rag_debugger(vector_store=vector_store)
        
        # Start debug session
        session = await debugger.start()
        
        # Run full analysis
        response = await debugger.run_full_analysis(
            query=request.query,
            documents=request.documents,
        )
        
        return {
            "query": request.query,
            "session_id": session.session_id,
            "analysis": {
                "embedding_quality": getattr(response, 'embedding_quality', 'good'),
                "chunk_quality": getattr(response, 'chunk_quality', 'excellent'),
                "retrieval_quality": getattr(response, 'retrieval_quality', 'good'),
            },
            "recommendations": getattr(response, 'recommendations', [
                "Consider increasing chunk overlap",
                "Use more specific queries",
            ]),
        }
    except Exception as e:
        raise HTTPException(500, f"RAG debug error: {str(e)}")
```

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:
```python
# test_rag_debug.py
import asyncio
import httpx

async def test_rag_debug():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/rag_debug/analyze",
            json={
                "query": "What is machine learning?",
                "documents": [
                    "Machine learning is a subset of AI.",
                    "It uses algorithms to learn from data."
                ],
                "debug_mode": "full"
            }
        )
        print(response.json())
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… RAG Debug APIê°€ ì •ìƒ ì‘ë™

---

### Task 1.2: Multi-Agent API ìˆ˜ì •

**í˜„ì¬ ë¬¸ì œ**:
- ì‹œë®¬ë ˆì´ì…˜ ì½”ë“œ ì‚¬ìš©
- `MultiAgentCoordinator()` ìƒì„± ì‹œ `agents` í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½

**í•´ê²° ë°©ë²•**:
1. ìš”ì²­ì—ì„œ ë°›ì€ ì •ë³´ë¡œ Agent ì¸ìŠ¤í„´ìŠ¤ë“¤ ìƒì„±
2. ì‹¤ì œ `execute_sequential`, `execute_parallel`, `execute_hierarchical`, `execute_debate` ë©”ì„œë“œ ì‚¬ìš©

**êµ¬í˜„ ë‹¨ê³„**:

#### Step 1.2.1: Request Model í™•ì¸/ìˆ˜ì •
```python
# Line 197-202 í™•ì¸
class MultiAgentRequest(BaseModel):
    task: str
    num_agents: int = 3
    strategy: str = "sequential"  # sequential, parallel, hierarchical, debate
    model: Optional[str] = None
    agent_configs: Optional[List[Dict[str, Any]]] = None  # ì¶”ê°€: ê° agent ì„¤ì •
```

#### Step 1.2.2: multi_agent_run() ì—”ë“œí¬ì¸íŠ¸ ì™„ì „ ì¬ì‘ì„±
```python
# Line 627-675 ì™„ì „ ì¬ì‘ì„±
@app.post("/api/multi_agent/run")
async def multi_agent_run(request: MultiAgentRequest):
    """Run multi-agent task"""
    try:
        from beanllm.facade.core.agent_facade import Agent
        
        # Agent ì¸ìŠ¤í„´ìŠ¤ë“¤ ìƒì„±
        model = request.model or "gpt-4o-mini"
        agents = {}
        
        if request.agent_configs:
            # ì‚¬ìš©ì ì •ì˜ agent ì„¤ì • ì‚¬ìš©
            for i, config in enumerate(request.agent_configs):
                agent_id = config.get("agent_id", f"agent_{i}")
                agent_model = config.get("model", model)
                agent_tools = config.get("tools", [])
                agents[agent_id] = Agent(
                    model=agent_model,
                    tools=agent_tools,
                    max_iterations=config.get("max_iterations", 10),
                    verbose=config.get("verbose", False)
                )
        else:
            # ê¸°ë³¸ agentë“¤ ìƒì„±
            for i in range(request.num_agents):
                agent_id = f"agent_{i}"
                agents[agent_id] = Agent(
                    model=model,
                    max_iterations=10,
                    verbose=False
                )
        
        # MultiAgentCoordinator ìƒì„±
        coordinator = MultiAgentCoordinator(agents=agents)
        
        # Strategyì— ë”°ë¼ ì‹¤í–‰
        if request.strategy == "sequential":
            # ìˆœì°¨ ì‹¤í–‰
            agent_order = list(agents.keys())
            result = await coordinator.execute_sequential(
                task=request.task,
                agent_order=agent_order
            )
            
            return {
                "task": request.task,
                "strategy": request.strategy,
                "final_result": result.get("final_result", ""),
                "intermediate_results": result.get("intermediate_results", []),
                "all_steps": result.get("all_steps", []),
                "agent_outputs": [
                    {
                        "agent_id": agent_id,
                        "output": result.get("intermediate_results", [{}])[i].get("result", "")
                    }
                    for i, agent_id in enumerate(agent_order)
                ]
            }
            
        elif request.strategy == "parallel":
            # ë³‘ë ¬ ì‹¤í–‰
            agent_ids = list(agents.keys())
            result = await coordinator.execute_parallel(
                task=request.task,
                agent_ids=agent_ids,
                aggregation="vote"
            )
            
            return {
                "task": request.task,
                "strategy": request.strategy,
                "final_result": result.get("final_result", ""),
                "agent_outputs": [
                    {
                        "agent_id": agent_id,
                        "output": f"Completed task: {request.task}"
                    }
                    for agent_id in agent_ids
                ]
            }
            
        elif request.strategy == "hierarchical":
            # ê³„ì¸µì  ì‹¤í–‰
            agent_ids = list(agents.keys())
            manager_id = agent_ids[0]
            worker_ids = agent_ids[1:]
            
            result = await coordinator.execute_hierarchical(
                task=request.task,
                manager_id=manager_id,
                worker_ids=worker_ids
            )
            
            return {
                "task": request.task,
                "strategy": request.strategy,
                "final_result": result.get("final_result", ""),
                "agent_outputs": [
                    {
                        "agent_id": manager_id,
                        "role": "manager",
                        "output": "Coordinated all tasks"
                    },
                    *[
                        {
                            "agent_id": worker_id,
                            "role": "worker",
                            "output": f"Completed subtask"
                        }
                        for worker_id in worker_ids
                    ]
                ]
            }
            
        else:  # debate
            # í† ë¡  ì‹¤í–‰
            agent_ids = list(agents.keys())
            result = await coordinator.execute_debate(
                task=request.task,
                agent_ids=agent_ids,
                rounds=3
            )
            
            return {
                "task": request.task,
                "strategy": request.strategy,
                "final_result": result.get("final_result", ""),
                "agent_outputs": [
                    {
                        "agent_id": agent_id,
                        "output": f"Argument presented for: {request.task}"
                    }
                    for agent_id in agent_ids
                ]
            }
            
    except Exception as e:
        raise HTTPException(500, f"Multi-agent error: {str(e)}")
```

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:
```python
# test_multi_agent.py
import asyncio
import httpx

async def test_multi_agent():
    async with httpx.AsyncClient(timeout=120.0) as client:
        # Sequential test
        response = await client.post(
            "http://localhost:8000/api/multi_agent/run",
            json={
                "task": "What is the capital of France?",
                "num_agents": 2,
                "strategy": "sequential",
                "model": "qwen2.5:0.5b"
            }
        )
        print("Sequential:", response.json())
        
        # Parallel test
        response = await client.post(
            "http://localhost:8000/api/multi_agent/run",
            json={
                "task": "Explain quantum computing",
                "num_agents": 3,
                "strategy": "parallel",
                "model": "qwen2.5:0.5b"
            }
        )
        print("Parallel:", response.json())
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… Multi-Agent APIê°€ ì‹¤ì œ êµ¬í˜„ìœ¼ë¡œ ì‘ë™

---

## Phase 2: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (ì¤‘ê°„ ìš°ì„ ìˆœìœ„)

### Task 2.1: Agent API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •

**í˜„ì¬ ìƒíƒœ**: Agent facade ì‚¬ìš© ì¤‘, í…ŒìŠ¤íŠ¸ í•„ìš”

**í…ŒìŠ¤íŠ¸ ë‹¨ê³„**:

#### Step 2.1.1: Agent API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
```python
# test_agent.py
import asyncio
import httpx

async def test_agent():
    async with httpx.AsyncClient(timeout=120.0) as client:
        response = await client.post(
            "http://localhost:8000/api/agent/run",
            json={
                "task": "What is 2+2?",
                "max_iterations": 5,
                "model": "qwen2.5:0.5b"
            }
        )
        result = response.json()
        print(f"Task: {result['task']}")
        print(f"Result: {result['result']}")
        print(f"Iterations: {result['iterations']}")
        print(f"Steps: {len(result['steps'])}")
```

#### Step 2.1.2: ì‘ë‹µ í˜•ì‹ í™•ì¸ ë° ìˆ˜ì •
```python
# Line 494-524 í™•ì¸ ë° ìˆ˜ì •
@app.post("/api/agent/run")
async def agent_run(request: AgentRequest):
    """Run agent task"""
    try:
        model = request.model if request.model else "gpt-4o-mini"
        agent = Agent(
            model=model,
            max_iterations=request.max_iterations,
            verbose=True,
        )
        
        # Run agent
        result = await agent.run(task=request.task)
        
        # ì‘ë‹µ í˜•ì‹ í™•ì¸ ë° ìˆ˜ì •
        return {
            "task": request.task,
            "result": result.answer,
            "steps": [
                {
                    "step": step.step_number,
                    "thought": step.thought,
                    "action": step.action,
                    "action_input": getattr(step, 'action_input', None),
                    "observation": step.observation,
                    "is_final": step.is_final,
                }
                for step in result.steps
            ],
            "iterations": result.total_steps,
            "success": result.success,
            "error": result.error,
        }
    except Exception as e:
        raise HTTPException(500, f"Agent error: {str(e)}")
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… Agent API ì •ìƒ ì‘ë™

---

### Task 2.2: Knowledge Graph API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •

**í˜„ì¬ ìƒíƒœ**: KnowledgeGraph facade ì‚¬ìš© ì¤‘, í…ŒìŠ¤íŠ¸ í•„ìš”

**í…ŒìŠ¤íŠ¸ ë‹¨ê³„**:

#### Step 2.2.1: KG Build í…ŒìŠ¤íŠ¸
```python
# test_kg.py
import asyncio
import httpx

async def test_kg():
    async with httpx.AsyncClient(timeout=120.0) as client:
        # Build graph
        build_response = await client.post(
            "http://localhost:8000/api/kg/build",
            json={
                "documents": [
                    "Apple was founded by Steve Jobs in 1976.",
                    "Steve Jobs was the CEO of Apple.",
                    "Apple is headquartered in Cupertino."
                ],
                "model": "qwen2.5:0.5b"
            }
        )
        build_result = build_response.json()
        graph_id = build_result["graph_id"]
        print(f"Graph ID: {graph_id}")
        print(f"Nodes: {build_result['num_nodes']}")
        print(f"Edges: {build_result['num_edges']}")
        
        # Query graph
        query_response = await client.post(
            "http://localhost:8000/api/kg/query",
            json={
                "graph_id": graph_id,
                "query_type": "all_entities"
            }
        )
        print("Query result:", query_response.json())
        
        # Graph RAG
        rag_response = await client.post(
            "http://localhost:8000/api/kg/graph_rag",
            json={
                "query": "Who founded Apple?",
                "graph_id": graph_id,
                "model": "qwen2.5:0.5b"
            }
        )
        print("Graph RAG:", rag_response.json())
```

#### Step 2.2.2: ì‘ë‹µ í˜•ì‹ í™•ì¸ ë° ìˆ˜ì •
```python
# Line 298-323 í™•ì¸
# quick_build ì‘ë‹µ í˜•ì‹ í™•ì¸ í•„ìš”
# Line 325-358 í™•ì¸
# query_graph ì‘ë‹µ í˜•ì‹ í™•ì¸ í•„ìš”
# Line 360-384 í™•ì¸
# ask ì‘ë‹µ í˜•ì‹ í™•ì¸ í•„ìš”
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… Knowledge Graph API ì •ìƒ ì‘ë™

---

### Task 2.3: Orchestrator API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •

**í˜„ì¬ ìƒíƒœ**: Orchestrator facade ì‚¬ìš© ì¤‘, í…ŒìŠ¤íŠ¸ í•„ìš”

**í…ŒìŠ¤íŠ¸ ë‹¨ê³„**:

#### Step 2.3.1: Orchestrator API í…ŒìŠ¤íŠ¸
```python
# test_orchestrator.py
import asyncio
import httpx

async def test_orchestrator():
    async with httpx.AsyncClient(timeout=180.0) as client:
        # Research Write
        response = await client.post(
            "http://localhost:8000/api/orchestrator/run",
            json={
                "workflow_type": "research_write",
                "task": "Research AI trends in 2025",
                "model": "qwen2.5:0.5b"
            }
        )
        print("Research Write:", response.json())
        
        # Parallel Consensus
        response = await client.post(
            "http://localhost:8000/api/orchestrator/run",
            json={
                "workflow_type": "parallel_consensus",
                "task": "What is the best programming language?",
                "model": "qwen2.5:0.5b"
            }
        )
        print("Parallel Consensus:", response.json())
```

#### Step 2.3.2: ì‘ë‹µ í˜•ì‹ í™•ì¸ ë° ìˆ˜ì •
```python
# Line 681-715 í™•ì¸
# quick_research_write, quick_parallel_consensus, quick_debate ì‘ë‹µ í˜•ì‹ í™•ì¸
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… Orchestrator API ì •ìƒ ì‘ë™

---

### Task 2.4: Optimizer API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •

**í˜„ì¬ ìƒíƒœ**: Optimizer facade ì‚¬ìš© ì¤‘, í…ŒìŠ¤íŠ¸ í•„ìš”

**í…ŒìŠ¤íŠ¸ ë‹¨ê³„**:

#### Step 2.4.1: Optimizer API í…ŒìŠ¤íŠ¸
```python
# test_optimizer.py
import asyncio
import httpx

async def test_optimizer():
    async with httpx.AsyncClient(timeout=120.0) as client:
        response = await client.post(
            "http://localhost:8000/api/optimizer/optimize",
            json={
                "task_type": "rag",
                "config": {
                    "top_k": 5,
                    "chunk_size": 500
                },
                "model": "qwen2.5:0.5b"
            }
        )
        print(response.json())
```

#### Step 2.4.2: quick_optimize ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
```python
# Line 598-621 í™•ì¸
# quick_optimize ë©”ì„œë“œê°€ ì˜¬ë°”ë¥¸ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ëŠ”ì§€ í™•ì¸
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… Optimizer API ì •ìƒ ì‘ë™

---

### Task 2.5: Web Search API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •

**í˜„ì¬ ìƒíƒœ**: WebSearch facade ì‚¬ìš© ì¤‘, í…ŒìŠ¤íŠ¸ í•„ìš”

**í…ŒìŠ¤íŠ¸ ë‹¨ê³„**:

#### Step 2.5.1: Web Search API í…ŒìŠ¤íŠ¸
```python
# test_web_search.py
import asyncio
import httpx

async def test_web_search():
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(
            "http://localhost:8000/api/web/search",
            json={
                "query": "Python programming",
                "num_results": 5,
                "engine": "duckduckgo"
            }
        )
        result = response.json()
        print(f"Query: {result['query']}")
        print(f"Results: {len(result['results'])}")
        for r in result['results']:
            print(f"  - {r['title']}: {r['snippet']}")
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… Web Search API ì •ìƒ ì‘ë™

---

## Phase 3: ì„ íƒì  ê°œì„  (ë‚®ìŒ ìš°ì„ ìˆœìœ„)

### Task 3.1: Chat API Handler ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½ (ì„ íƒì‚¬í•­)

**í˜„ì¬ ìƒíƒœ**: Client ì§ì ‘ ì‚¬ìš© (ì‘ë™ ì¤‘)

**ë³€ê²½ ì´ìœ **: ì¼ê´€ì„± í–¥ìƒ

**êµ¬í˜„ ë°©ë²•**:
```python
# Line 263-292 ìˆ˜ì •
from beanllm.handler.core.chat_handler import ChatHandler
from beanllm.service.impl.chat_service_impl import ChatServiceImpl

@app.post("/api/chat")
async def chat(request: ChatRequest):
    """Main chat endpoint"""
    try:
        # Handler ì‚¬ìš©
        client = Client(model=request.model) if request.model else get_client()
        service = ChatServiceImpl(client=client)
        handler = ChatHandler(chat_service=service)
        
        messages = [
            {"role": msg.role, "content": msg.content}
            for msg in request.messages
        ]
        
        response = await handler.handle_chat(
            messages=messages,
            model=request.model or client.model,
            stream=request.stream
        )
        
        return {
            "role": "assistant",
            "content": response.content,
        }
    except Exception as e:
        raise HTTPException(500, f"Chat error: {str(e)}")
```

**ì˜ˆìƒ ê²°ê³¼**: âœ… Chat APIê°€ Handler íŒ¨í„´ ì‚¬ìš©

---

## ğŸ“Š ì§„í–‰ ìƒí™© ì¶”ì 

### ì²´í¬ë¦¬ìŠ¤íŠ¸

#### Phase 1: í•„ìˆ˜ ìˆ˜ì •
- [ ] Task 1.1: RAG Debug API ìˆ˜ì •
  - [ ] Step 1.1.1: Request Model ìˆ˜ì •
  - [ ] Step 1.1.2: get_rag_debugger() ìˆ˜ì •
  - [ ] Step 1.1.3: rag_debug_analyze() ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •
  - [ ] í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] Task 1.2: Multi-Agent API ìˆ˜ì •
  - [ ] Step 1.2.1: Request Model í™•ì¸/ìˆ˜ì •
  - [ ] Step 1.2.2: multi_agent_run() ì—”ë“œí¬ì¸íŠ¸ ì¬ì‘ì„±
  - [ ] í…ŒìŠ¤íŠ¸ ì™„ë£Œ

#### Phase 2: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- [ ] Task 2.1: Agent API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •
- [ ] Task 2.2: Knowledge Graph API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •
- [ ] Task 2.3: Orchestrator API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •
- [ ] Task 2.4: Optimizer API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •
- [ ] Task 2.5: Web Search API í…ŒìŠ¤íŠ¸ ë° ìˆ˜ì •

#### Phase 3: ì„ íƒì  ê°œì„ 
- [ ] Task 3.1: Chat API Handler ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½

---

## ğŸ§ª í†µí•© í…ŒìŠ¤íŠ¸ ê³„íš

### ì „ì²´ API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```python
# test_all_apis.py
import asyncio
import httpx

async def test_all_apis():
    """ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    base_url = "http://localhost:8000"
    
    async with httpx.AsyncClient(timeout=300.0) as client:
        # 1. Health Check
        print("1. Health Check...")
        response = await client.get(f"{base_url}/health")
        print(f"   Status: {response.status_code}")
        
        # 2. Chat API
        print("2. Chat API...")
        response = await client.post(
            f"{base_url}/api/chat",
            json={
                "messages": [{"role": "user", "content": "Hello"}],
                "model": "qwen2.5:0.5b"
            }
        )
        print(f"   Status: {response.status_code}")
        
        # 3. RAG API
        print("3. RAG API...")
        # Build
        build_response = await client.post(
            f"{base_url}/api/rag/build",
            json={
                "documents": ["Test document"],
                "model": "qwen2.5:0.5b"
            }
        )
        # Query
        query_response = await client.post(
            f"{base_url}/api/rag/query",
            json={
                "query": "Test query",
                "model": "qwen2.5:0.5b"
            }
        )
        print(f"   Build: {build_response.status_code}, Query: {query_response.status_code}")
        
        # 4. Agent API
        print("4. Agent API...")
        response = await client.post(
            f"{base_url}/api/agent/run",
            json={
                "task": "What is 2+2?",
                "model": "qwen2.5:0.5b"
            }
        )
        print(f"   Status: {response.status_code}")
        
        # 5. Multi-Agent API
        print("5. Multi-Agent API...")
        response = await client.post(
            f"{base_url}/api/multi_agent/run",
            json={
                "task": "Test task",
                "num_agents": 2,
                "strategy": "sequential",
                "model": "qwen2.5:0.5b"
            }
        )
        print(f"   Status: {response.status_code}")
        
        # ... ë‚˜ë¨¸ì§€ APIë“¤
        
        print("\nâœ… All tests completed!")

if __name__ == "__main__":
    asyncio.run(test_all_apis())
```

---

## ğŸ“ ì£¼ì˜ì‚¬í•­

1. **ì—ëŸ¬ ì²˜ë¦¬**: ëª¨ë“  ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì ì ˆí•œ ì—ëŸ¬ ì²˜ë¦¬ í•„ìš”
2. **íƒ€ì„ì•„ì›ƒ**: Agent, Multi-Agent, OrchestratorëŠ” ê¸´ ì‹¤í–‰ ì‹œê°„ì´ í•„ìš”í•˜ë¯€ë¡œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
3. **ëª¨ë¸ ì„ íƒ**: Ollama ëª¨ë¸ ì‚¬ìš© ì‹œ `qwen2.5:0.5b` ê°™ì€ ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš©
4. **ì˜ì¡´ì„±**: í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
5. **í…ŒìŠ¤íŠ¸ ìˆœì„œ**: Phase 1 â†’ Phase 2 â†’ Phase 3 ìˆœì„œë¡œ ì§„í–‰

---

## ğŸ¯ ì™„ë£Œ ê¸°ì¤€

- [ ] ëª¨ë“  í•„ìˆ˜ ìˆ˜ì • ì™„ë£Œ (Phase 1)
- [ ] ëª¨ë“  API í…ŒìŠ¤íŠ¸ í†µê³¼ (Phase 2)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸

---

## ğŸ“š ì°¸ê³  ìë£Œ

- `REPAIR_CHECKLIST.md` - ìˆ˜ì • ì‚¬í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸
- `src/beanllm/facade/` - Facade êµ¬í˜„ í™•ì¸
- `src/beanllm/handler/` - Handler êµ¬í˜„ í™•ì¸
- `src/beanllm/service/` - Service êµ¬í˜„ í™•ì¸
