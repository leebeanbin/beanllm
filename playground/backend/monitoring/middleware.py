"""
ë¶„ì‚° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

Kafka + Redis + ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œë¥¼ í™œìš©í•œ ìƒì„¸ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
Â§0 ë©”ì‹œì§• ì²˜ë¦¬ ì ê·¹ í™œìš©: RECORD_METRICS_FOR_ALL_API=true ì‹œ ì „ì²´ /api/* ë©”íŠ¸ë¦­ ê¸°ë¡
"""

import json
import logging
import os
import time
import uuid
from datetime import datetime
from typing import Optional

from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware

try:
    from beanllm.infrastructure.distributed import get_event_logger
    from beanllm.infrastructure.distributed.messaging import RequestMonitor
    from beanllm.utils.logging import get_logger
except ImportError:
    import logging

    def get_logger(name: str):
        return logging.getLogger(name)

    def get_event_logger():
        return None

    def RequestMonitor():
        return None


logger = get_logger(__name__)


def _is_chat_api_path(path: str) -> bool:
    """ì±„íŒ… API ê²½ë¡œ ì—¬ë¶€. ëŒ€ì‹œë³´ë“œ ì§‘ê³„ëŠ” ì±„íŒ… ì „ìš©."""
    return path == "/api/chat" or path.startswith("/api/chat/")


# ë©”íŠ¸ë¦­ì— ì ˆëŒ€ ë„£ì§€ ì•Šì„ ê²½ë¡œ(ëŒ€ì‹œë³´ë“œ ë¦¬í”„ë ˆì‹œÂ·í—¬ìŠ¤Â·ì„¤ì • ì¡°íšŒ ë“±)
_METRICS_EXCLUDED_PREFIXES = ("/api/monitoring", "/health", "/api/config", "/api/models", "/")


def _should_record_metrics(path: str) -> bool:
    """
    ì´ ìš”ì²­ì— ëŒ€í•´ Redis ë©”íŠ¸ë¦­(requests/errors/response_time/endpoint)ì„ ê¸°ë¡í• ì§€ ì—¬ë¶€.
    - ëŒ€ì‹œë³´ë“œ/ëª¨ë‹ˆí„°ë§Â·í—¬ìŠ¤Â·ì„¤ì • ì¡°íšŒëŠ” í•­ìƒ ì œì™¸(ë¦¬í”„ë ˆì‹œê°€ total requestsì— ì¡íˆì§€ ì•Šë„ë¡).
    - ì±„íŒ… API(/api/chat, /api/chat/*)ë§Œ ê¸°ë¡. RECORD_METRICS_FOR_ALL_API=trueì—¬ë„ ì œì™¸ ê²½ë¡œëŠ” ì•ˆ ë„£ìŒ.
    """
    if not path or path == "/":
        return False
    for prefix in _METRICS_EXCLUDED_PREFIXES:
        if path == prefix or (len(prefix) > 1 and path.startswith(prefix)):
            return False
    if _is_chat_api_path(path):
        return True
    if os.getenv("RECORD_METRICS_FOR_ALL_API", "false").lower() == "true":
        return path.startswith("/api/")
    return False


class MonitoringMiddleware(BaseHTTPMiddleware):
    """
    ìƒì„¸ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´

    - Request ID ìƒì„± ë° ì „íŒŒ
    - ìš”ì²­/ì‘ë‹µ ë¡œê¹…
    - ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    - Kafkaë¥¼ í†µí•œ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
    - Redisë¥¼ í†µí•œ ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì €ì¥
    """

    def __init__(self, app, enable_kafka: bool = True, enable_redis: bool = True):
        super().__init__(app)
        self.enable_kafka = enable_kafka
        self.enable_redis = enable_redis
        self.event_logger = None
        self.request_monitor = None

        # ì´ë²¤íŠ¸ ë¡œê±° ì´ˆê¸°í™”
        if self.enable_kafka:
            try:
                self.event_logger = get_event_logger()
            except Exception as e:
                logger.warning(f"Failed to initialize event logger: {e}")
                self.enable_kafka = False

        # Request Monitor ì´ˆê¸°í™”
        if self.enable_redis:
            try:
                # ì§ì ‘ get_redis_clientë¥¼ í˜¸ì¶œí•´ì„œ í…ŒìŠ¤íŠ¸
                try:
                    from beanllm.infrastructure.distributed.redis.client import get_redis_client

                    logger.info("ğŸ” Testing Redis client creation...")
                    test_redis = get_redis_client()
                    if test_redis:
                        logger.info(f"âœ… Redis client created successfully: {type(test_redis)}")
                    else:
                        logger.error("âŒ get_redis_client() returned None")
                        self.enable_redis = False
                except ImportError as e:
                    logger.error(f"âŒ Failed to import Redis client module: {e}", exc_info=True)
                    self.enable_redis = False
                except Exception as e:
                    logger.error(f"âŒ Failed to create Redis client: {e}", exc_info=True)
                    logger.error("   This might be a connection issue or import error")
                    self.enable_redis = False

                # RequestMonitor ì´ˆê¸°í™”
                if self.enable_redis:
                    try:
                        logger.info("ğŸ” Initializing RequestMonitor...")
                        self.request_monitor = RequestMonitor()
                        if self.request_monitor and self.request_monitor.redis:
                            logger.info("âœ… Redis monitoring initialized successfully")
                            logger.info(f"   Redis client type: {type(self.request_monitor.redis)}")
                        else:
                            logger.error("âŒ RequestMonitor.redis is None after initialization")
                            logger.error("   RequestMonitor.__init__() completed but redis is None")
                            logger.error(
                                "   This means get_redis_client() failed silently in RequestMonitor"
                            )
                            logger.error(
                                "   Check RequestMonitor.__init__() logs (DEBUG level) for details"
                            )
                            self.enable_redis = False
                    except Exception as e:
                        logger.error(f"âŒ Failed to initialize RequestMonitor: {e}", exc_info=True)
                        logger.error("   Redis monitoring will be disabled.")
                        self.enable_redis = False
            except Exception as e:
                logger.error(
                    f"âŒ Unexpected error during Redis monitoring setup: {e}", exc_info=True
                )
                self.enable_redis = False

    async def dispatch(self, request: Request, call_next):
        """ìš”ì²­ ì²˜ë¦¬ ë° ëª¨ë‹ˆí„°ë§"""
        # Request ID ìƒì„± (í—¤ë”ì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„±)
        request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())

        # ì‹œì‘ ì‹œê°„
        start_time = time.time()

        # ìš”ì²­ ì •ë³´ ìˆ˜ì§‘
        request_info = {
            "request_id": request_id,
            "method": request.method,
            "path": str(request.url.path),
            "query_params": dict(request.query_params),
            "client_host": request.client.host if request.client else None,
            "user_agent": request.headers.get("user-agent"),
            "timestamp": datetime.now().isoformat(),
        }

        # ìš”ì²­ ë³¸ë¬¸ ì½ê¸° (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            if request.method in ["POST", "PUT", "PATCH"]:
                body = await request.body()
                if body:
                    try:
                        request_info["body"] = json.loads(body.decode())
                    except:
                        request_info["body_size"] = len(body)
        except Exception as e:
            logger.debug(f"Failed to read request body: {e}")

        # ìš”ì²­ ë¡œê¹…
        logger.info(
            f"[REQUEST] {request.method} {request.url.path}",
            extra={
                "request_id": request_id,
                "request_info": request_info,
            },
        )

        # Kafka ì´ë²¤íŠ¸ ë°œí–‰ (ìš”ì²­ ì‹œì‘)
        if self.enable_kafka and self.event_logger:
            try:
                await self.event_logger.log_event(
                    "api.request.started",
                    {
                        **request_info,
                        "event_type": "request_started",
                    },
                )
            except Exception as e:
                logger.debug(f"Failed to publish request event: {e}")

        # Redisì— ìš”ì²­ ìƒíƒœ ì €ì¥
        if self.enable_redis and self.request_monitor and self.request_monitor.redis:
            try:
                status_data = {
                    "request_id": request_id,
                    "status": "processing",
                    "started_at": start_time,
                    "path": str(request.url.path),
                    "method": request.method,
                }
                await self.request_monitor.redis.setex(
                    f"request:status:{request_id}",
                    3600,
                    json.dumps(status_data),  # 1ì‹œê°„ TTL
                )
                logger.debug(f"âœ… Saved request status to Redis: {request_id}")
            except Exception as e:
                logger.warning(f"âŒ Failed to save request status to Redis: {e}", exc_info=True)
        elif self.enable_redis:
            # Redisê°€ í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ ì—°ê²°ì´ ì•ˆ ëœ ê²½ìš° (ì²« ìš”ì²­ì—ì„œë§Œ ë¡œê·¸)
            if not hasattr(self, "_redis_warning_logged"):
                if not self.request_monitor:
                    logger.error("âŒ RequestMonitor not initialized - Redis monitoring disabled")
                elif not self.request_monitor.redis:
                    logger.error("âŒ RequestMonitor.redis is None - Redis connection failed")
                    logger.error("   Check Redis server and connection settings")
                self._redis_warning_logged = True

        # ìš”ì²­ ì²˜ë¦¬
        error_occurred = False
        error_message = None
        status_code = 200
        response = None

        try:
            response = await call_next(request)
            status_code = response.status_code
        except Exception as e:
            error_occurred = True
            error_message = str(e)
            status_code = 500
            logger.error(
                f"[ERROR] {request.method} {request.url.path}",
                exc_info=True,
                extra={
                    "request_id": request_id,
                    "error": error_message,
                },
            )
            raise
        finally:
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            duration_ms = (time.time() - start_time) * 1000

            # ì‘ë‹µ ì •ë³´ ìˆ˜ì§‘
            response_info = {
                "request_id": request_id,
                "status_code": status_code,
                "duration_ms": duration_ms,
                "timestamp": datetime.now().isoformat(),
                "error": error_message if error_occurred else None,
            }

            # ì‘ë‹µ ë¡œê¹…
            log_level = (
                "error"
                if error_occurred or status_code >= 500
                else "warning"
                if status_code >= 400
                else "info"
            )
            logger.log(
                getattr(logging, log_level.upper()),
                f"[RESPONSE] {request.method} {request.url.path} - {status_code} ({duration_ms:.2f}ms)",
                extra={
                    "request_id": request_id,
                    "response_info": response_info,
                },
            )

            # Kafka ì´ë²¤íŠ¸ ë°œí–‰ (ìš”ì²­ ì™„ë£Œ)
            if self.enable_kafka and self.event_logger:
                try:
                    await self.event_logger.log_event(
                        "api.request.completed",
                        {
                            **request_info,
                            **response_info,
                            "event_type": "request_completed",
                        },
                        level="error" if error_occurred else "info",
                    )
                except Exception as e:
                    logger.debug(f"Failed to publish response event: {e}")

            # Redisì— ì‘ë‹µ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ë©”íŠ¸ë¦­ ì €ì¥
            if self.enable_redis and self.request_monitor and self.request_monitor.redis:
                try:
                    logger.debug(f"Saving metrics to Redis for request {request_id}")
                    # ìƒíƒœ ì—…ë°ì´íŠ¸
                    status_data = {
                        "request_id": request_id,
                        "status": "completed" if not error_occurred else "error",
                        "started_at": start_time,
                        "completed_at": time.time(),
                        "duration_ms": duration_ms,
                        "status_code": status_code,
                        "path": str(request.url.path),
                        "method": request.method,
                    }
                    await self.request_monitor.redis.setex(
                        f"request:status:{request_id}", 3600, json.dumps(status_data)
                    )

                    # ì¶”ì  ë©”íŠ¸ë¦­ ê¸°ì¤€: docs/CACHE_AND_METRICS_POLICY.md Â§2 â€” requests/errors/response_time/endpointë§Œ ìˆ˜ì§‘
                    # ëŒ€ìƒ ê²½ë¡œ: ì±„íŒ… ë˜ëŠ” RECORD_METRICS_FOR_ALL_API ì‹œ /api/*
                    path = str(request.url.path)
                    if _should_record_metrics(path):
                        # 1. ì‘ë‹µ ì‹œê°„ ë©”íŠ¸ë¦­
                        await self.request_monitor.redis.zadd(
                            "metrics:response_time", {request_id: duration_ms}
                        )
                        await self.request_monitor.redis.expire("metrics:response_time", 3600)
                        # 2. ìš”ì²­ ìˆ˜ ì¹´ìš´í„° (ì‹œê°„ëŒ€ë³„)
                        minute_key = f"metrics:requests:{int(time.time() // 60)}"
                        await self.request_monitor.redis.incr(minute_key)
                        await self.request_monitor.redis.expire(minute_key, 3600)
                        # 3. ì—ëŸ¬ ì¹´ìš´í„°
                        if error_occurred or status_code >= 500:
                            error_key = f"metrics:errors:{int(time.time() // 60)}"
                            await self.request_monitor.redis.incr(error_key)
                            await self.request_monitor.redis.expire(error_key, 3600)
                        # 4. ì—”ë“œí¬ì¸íŠ¸ë³„ í†µê³„
                        endpoint_key = f"metrics:endpoint:{request.method}:{path}"
                        await self.request_monitor.redis.hincrby(endpoint_key, "count", 1)
                        await self.request_monitor.redis.hincrby(
                            endpoint_key, "total_time_ms", int(duration_ms)
                        )
                        if error_occurred or status_code >= 500:
                            await self.request_monitor.redis.hincrby(endpoint_key, "errors", 1)
                        await self.request_monitor.redis.expire(endpoint_key, 3600)

                except Exception as e:
                    logger.warning(f"Failed to update metrics in Redis: {e}", exc_info=True)

            # Response í—¤ë”ì— Request ID ì¶”ê°€ (ì˜ˆì™¸ ì‹œ responseê°€ ì—†ìœ¼ë¯€ë¡œ ìƒëµ)
            if response is not None:
                response.headers["X-Request-ID"] = request_id
                response.headers["X-Response-Time"] = f"{duration_ms:.2f}ms"

        return response


class ChatMonitoringMixin:
    """
    Chat API ì „ìš© ëª¨ë‹ˆí„°ë§ ë¯¹ìŠ¤ì¸

    LLM í˜¸ì¶œì— ëŒ€í•œ ìƒì„¸ ë¡œê¹…
    """

    @staticmethod
    def _chat_request_preview(messages: list, max_len: int = 100) -> str:
        """ë§ˆì§€ë§‰ user ë©”ì‹œì§€ ì¼ë¶€ë§Œ ì¶”ì¶œ. CHAT_HISTORY_MASK_PREVIEW=trueë©´ ê³ ì •ë¬¸."""
        if os.getenv("CHAT_HISTORY_MASK_PREVIEW", "false").lower() == "true":
            return "(ë§ˆìŠ¤í‚¹)"
        if not messages:
            return ""
        for m in reversed(messages):
            if m.get("role") == "user":
                c = m.get("content", "")
                if isinstance(c, list):
                    for part in c:
                        if isinstance(part, dict) and part.get("type") == "text":
                            return (part.get("text") or "")[:max_len]
                    return ""
                return (c or "")[:max_len]
        return ""

    @staticmethod
    async def log_chat_request(
        request_id: str,
        model: str,
        messages: list,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
    ):
        """Chat ìš”ì²­ ë¡œê¹…"""
        event_logger = None
        try:
            event_logger = get_event_logger()
        except:
            pass

        if event_logger:
            try:
                await event_logger.log_event(
                    "chat.request",
                    {
                        "request_id": request_id,
                        "model": model,
                        "message_count": len(messages),
                        "temperature": temperature,
                        "max_tokens": max_tokens,
                        "first_message_preview": (
                            messages[0].get("content", "")[:100] if messages else ""
                        ),
                    },
                )
            except Exception as e:
                logger.debug(f"Failed to log chat request: {e}")

        # ì±— ìƒì„¸ ì´ë ¥: ìƒì‹œ ìˆ˜ì§‘ (env ì—†ìŒ, CHAT_HISTORY_METRICS.md)
        try:
            monitor = RequestMonitor()
            if not (monitor and monitor.redis):
                return
            now = time.time()
            at_minute = int(now // 60)
            preview = ChatMonitoringMixin._chat_request_preview(messages)
            await monitor.redis.hset(
                f"chat:record:{request_id}",
                mapping={
                    "model": model,
                    "at_ts": str(int(now)),
                    "at_minute": str(at_minute),
                    "request_preview": preview[:500],
                },
            )
            await monitor.redis.expire(f"chat:record:{request_id}", 86400)
            await monitor.redis.zadd("chat:history", {request_id: now})
            await monitor.redis.expire("chat:history", 86400)
        except Exception as e:
            logger.debug(f"Failed to write chat history (request): {e}")

    @staticmethod
    async def log_chat_response(
        request_id: str,
        model: str,
        response_content: str,
        input_tokens: Optional[int] = None,
        output_tokens: Optional[int] = None,
        duration_ms: Optional[float] = None,
    ):
        """Chat ì‘ë‹µ ë¡œê¹…"""
        event_logger = None
        try:
            event_logger = get_event_logger()
        except:
            pass

        if event_logger:
            try:
                await event_logger.log_event(
                    "chat.response",
                    {
                        "request_id": request_id,
                        "model": model,
                        "response_length": len(response_content),
                        "response_preview": response_content[:200],
                        "input_tokens": input_tokens,
                        "output_tokens": output_tokens,
                        "total_tokens": (input_tokens or 0) + (output_tokens or 0),
                        "duration_ms": duration_ms,
                    },
                )
            except Exception as e:
                logger.debug(f"Failed to log chat response: {e}")

        # Redisì— í† í° ì‚¬ìš©ëŸ‰ ì €ì¥
        request_monitor = None
        try:
            request_monitor = RequestMonitor()
        except:
            pass

        if request_monitor and request_monitor.redis:
            try:
                if input_tokens and output_tokens:
                    token_key = f"metrics:tokens:{model}"
                    await request_monitor.redis.hincrby(token_key, "input_tokens", input_tokens)
                    await request_monitor.redis.hincrby(token_key, "output_tokens", output_tokens)
                    await request_monitor.redis.hincrby(
                        token_key, "total_tokens", input_tokens + output_tokens
                    )
                    await request_monitor.redis.hincrby(token_key, "request_count", 1)
                    await request_monitor.redis.expire(token_key, 86400)  # 24ì‹œê°„
            except Exception as e:
                logger.debug(f"Failed to save token metrics: {e}")

        # ì±— ìƒì„¸ ì´ë ¥: chat:record ê°±ì‹ , ìƒì‹œ ìˆ˜ì§‘ (CHAT_HISTORY_METRICS.md)
        if request_monitor and request_monitor.redis:
            try:
                now = time.time()
                at_minute = int(now // 60)
                total = (input_tokens or 0) + (output_tokens or 0)
                resp_preview = (
                    "(ë§ˆìŠ¤í‚¹)"
                    if os.getenv("CHAT_HISTORY_MASK_PREVIEW", "false").lower() == "true"
                    else (response_content or "")[:200]
                )
                await request_monitor.redis.hset(
                    f"chat:record:{request_id}",
                    mapping={
                        "response_preview": resp_preview[:500],
                        "input_tokens": str(input_tokens or 0),
                        "output_tokens": str(output_tokens or 0),
                        "total_tokens": str(total),
                        "duration_ms": str(int(duration_ms or 0)),
                        "at_ts": str(int(now)),
                        "at_minute": str(at_minute),
                    },
                )
                await request_monitor.redis.expire(f"chat:record:{request_id}", 86400)
                await request_monitor.redis.zadd("chat:history", {request_id: now})
                await request_monitor.redis.expire("chat:history", 86400)
            except Exception as e:
                logger.debug(f"Failed to write chat history (response): {e}")
